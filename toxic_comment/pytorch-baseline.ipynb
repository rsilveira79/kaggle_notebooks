{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Torch imports\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## Sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "## NLP Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-baseline.ipynb     test.csv\r\n",
      "pytorch-gru-word2vec.ipynb train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95846</th>\n",
       "      <td>999977655955</td>\n",
       "      <td>\"\\nI have discussed it, unlike most of those w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95847</th>\n",
       "      <td>999982426659</td>\n",
       "      <td>ps. Almost forgot, Paine don't reply back to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95848</th>\n",
       "      <td>999982764066</td>\n",
       "      <td>Mamoun Darkazanli\\nFor some reason I am unable...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>999986890563</td>\n",
       "      <td>Salafi would be a better term. It is more poli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>999988164717</td>\n",
       "      <td>making wikipedia a better and more inviting pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "95846  999977655955  \"\\nI have discussed it, unlike most of those w...      0   \n",
       "95847  999982426659  ps. Almost forgot, Paine don't reply back to t...      1   \n",
       "95848  999982764066  Mamoun Darkazanli\\nFor some reason I am unable...      0   \n",
       "95849  999986890563  Salafi would be a better term. It is more poli...      0   \n",
       "95850  999988164717  making wikipedia a better and more inviting pl...      0   \n",
       "\n",
       "       severe_toxic  obscene  threat  insult  identity_hate  \n",
       "95846             0        0       0       0              0  \n",
       "95847             0        1       0       0              0  \n",
       "95848             0        0       0       0              0  \n",
       "95849             0        0       0       0              0  \n",
       "95850             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', delimiter=\",\")\n",
    "print(\"Train size: {}\".format(len(train)))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 226998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226993</th>\n",
       "      <td>999966872214</td>\n",
       "      <td>*{Persondata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226994</th>\n",
       "      <td>999968525410</td>\n",
       "      <td>'' —  is wishing you a [WIKI_LINK: Mary Poppin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226995</th>\n",
       "      <td>999980053494</td>\n",
       "      <td>==Fair use rationale for [WIKI_LINK: Image:D.R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226996</th>\n",
       "      <td>999980680364</td>\n",
       "      <td>== Employment Practices at Majestic ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226997</th>\n",
       "      <td>999997819802</td>\n",
       "      <td>Welcome to Wikipedia. Although everyone is wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text\n",
       "226993  999966872214                                       *{Persondata\n",
       "226994  999968525410  '' —  is wishing you a [WIKI_LINK: Mary Poppin...\n",
       "226995  999980053494  ==Fair use rationale for [WIKI_LINK: Image:D.R...\n",
       "226996  999980680364             == Employment Practices at Majestic ==\n",
       "226997  999997819802  Welcome to Wikipedia. Although everyone is wel..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', delimiter=\",\")\n",
    "print(\"Test size: {}\".format(len(test)))\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, do_stop=False):\n",
    "    text = str(text)\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)  # Strip all the numerics\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text) # Removing non ASCII chars\n",
    "    text = text.replace(\"\\n\",\"\") # Removing line breaks\n",
    "    text = text.replace(\"=\",\"\") # Removing =\n",
    "    text = text.replace(\":\",\"\") # Removing :\n",
    "    text = text.replace(\"#\",\"\") # Removing #\n",
    "    text = text.replace(\"%\",\"\") # Removing #\n",
    "    text = text.replace(\"&\",\"\") # Removing #\n",
    "    text = text.replace('\"',\"\") # Removing #\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)# Strip multiple whitespaces\n",
    "\n",
    "    text = text.lower()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    text = \" \".join(filtered_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?? that is not cool'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"\\n ##?? %&that is not cool\"\n",
    "clean_text(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95846</th>\n",
       "      <td>999977655955</td>\n",
       "      <td>\"\\nI have discussed it, unlike most of those w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discussed it, unlike revert (heonsi pure sockp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95847</th>\n",
       "      <td>999982426659</td>\n",
       "      <td>ps. Almost forgot, Paine don't reply back to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ps. almost forgot, paine reply back shit, want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95848</th>\n",
       "      <td>999982764066</td>\n",
       "      <td>Mamoun Darkazanli\\nFor some reason I am unable...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mamoun darkazanlifor reason unable fix bold fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>999986890563</td>\n",
       "      <td>Salafi would be a better term. It is more poli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salafi would better term. politically correct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>999988164717</td>\n",
       "      <td>making wikipedia a better and more inviting pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>making wikipedia better inviting place.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "95846  999977655955  \"\\nI have discussed it, unlike most of those w...      0   \n",
       "95847  999982426659  ps. Almost forgot, Paine don't reply back to t...      1   \n",
       "95848  999982764066  Mamoun Darkazanli\\nFor some reason I am unable...      0   \n",
       "95849  999986890563  Salafi would be a better term. It is more poli...      0   \n",
       "95850  999988164717  making wikipedia a better and more inviting pl...      0   \n",
       "\n",
       "       severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "95846             0        0       0       0              0   \n",
       "95847             0        1       0       0              0   \n",
       "95848             0        0       0       0              0   \n",
       "95849             0        0       0       0              0   \n",
       "95850             0        0       0       0              0   \n",
       "\n",
       "                                         cleaned_comment  \n",
       "95846  discussed it, unlike revert (heonsi pure sockp...  \n",
       "95847  ps. almost forgot, paine reply back shit, want...  \n",
       "95848  mamoun darkazanlifor reason unable fix bold fo...  \n",
       "95849  salafi would better term. politically correct ...  \n",
       "95850            making wikipedia better inviting place.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleaned_comment']=train['comment_text'].apply(lambda x:clean_text(x, do_stop=True))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>==Orphaned non-free media (Image:41cD1jboEvL. ...</td>\n",
       "      <td>orphaned non-free media (imagecdjboevl. ss .jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>::Kentuckiana is colloquial.  Even though the ...</td>\n",
       "      <td>kentuckiana colloquial. even though area often...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>Hello fellow Wikipedians,\\nI have just modifie...</td>\n",
       "      <td>hello fellow wikipedians,i modified [wiki_link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>AKC Suspensions \\nThe Morning Call - Feb 24, 2...</td>\n",
       "      <td>akc suspensions morning call - feb , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>== [WIKI_LINK: Talk:Celts] ==</td>\n",
       "      <td>[wiki_link talkcelts]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  \\\n",
       "0   6044863  ==Orphaned non-free media (Image:41cD1jboEvL. ...   \n",
       "1   6102620  ::Kentuckiana is colloquial.  Even though the ...   \n",
       "2  14563293  Hello fellow Wikipedians,\\nI have just modifie...   \n",
       "3  21086297  AKC Suspensions \\nThe Morning Call - Feb 24, 2...   \n",
       "4  22982444                      == [WIKI_LINK: Talk:Celts] ==   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0   orphaned non-free media (imagecdjboevl. ss .jpg)  \n",
       "1  kentuckiana colloquial. even though area often...  \n",
       "2  hello fellow wikipedians,i modified [wiki_link...  \n",
       "3           akc suspensions morning call - feb , ...  \n",
       "4                              [wiki_link talkcelts]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['cleaned_comment']=test['comment_text'].apply(lambda x:clean_text(x, do_stop=True))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing classes, inbalance, most command words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toxic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic=train[train['toxic']==1].reset_index(drop=True)\n",
    "toxic.drop(labels=['severe_toxic','obscene','threat','insult','identity_hate'], axis=1, inplace=True)\n",
    "print(len(toxic))\n",
    "toxic.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severe Toxic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severe_toxic=train[train['severe_toxic']==1].reset_index(drop=True)\n",
    "severe_toxic.drop(labels=['toxic','obscene','threat','insult','identity_hate'], axis=1, inplace=True)\n",
    "print(len(severe_toxic))\n",
    "severe_toxic[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene=train[train['obscene']==1].reset_index(drop=True)\n",
    "obscene.drop(labels=['toxic','severe_toxic','threat','insult','identity_hate'], axis=1, inplace=True)\n",
    "print(len(obscene))\n",
    "obscene[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat=train[train['threat']==1].reset_index(drop=True)\n",
    "threat.drop(labels=['toxic','severe_toxic','obscene','insult','identity_hate'], axis=1, inplace=True)\n",
    "print(len(threat))\n",
    "threat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult=train[train['insult']==1].reset_index(drop=True)\n",
    "insult.drop(labels=['toxic','severe_toxic','obscene','threat','identity_hate'], axis=1, inplace=True)\n",
    "print(len(insult))\n",
    "insult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_hate=train[train['identity_hate']==1].reset_index(drop=True)\n",
    "identity_hate.drop(labels=['toxic','severe_toxic','obscene','threat','insult'], axis=1, inplace=True)\n",
    "print(len(identity_hate))\n",
    "identity_hate[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train['cleaned_comment'],\n",
    "                                                    list(zip(train['toxic'], train['severe_toxic'],\n",
    "                                                             train['obscene'], train['threat'],\n",
    "                                                             train['insult'], train['identity_hate'])),\n",
    "                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test['cleaned_comment'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=list(zip(x_train,y_train))\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data=list(zip(x_valid,y_valid))\n",
    "valid_data[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Vocabulary\n",
    "word_to_ix = {}\n",
    "for (sent) in list(x_train) + list(x_valid)+list(x_test):\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 6\n",
    "VOCAB_SIZE,NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - BoW Classifier with Handcrafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        \n",
    "        ## Defining parameters for linear model\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "    \n",
    "    def forward(self, bow_vec):\n",
    "        ## do the foward pass and implement non-linearity\n",
    "        return F.log_softmax(self.linear(bow_vec),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence.split():\n",
    "        if word in word_to_ix:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label):\n",
    "    return torch.FloatTensor(label).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "sample_phrase=make_bow_vector(train_data[n][0],word_to_ix)\n",
    "print(\">> SENTENCE: {}\".format(train_data[n][0]))\n",
    "#$print(\">> SENTIMENT: {}\".format(y_train[n]))\n",
    "print(\">> INPUT SIZE: {}\".format(sample_phrase.size()))\n",
    "print(\">> INPUT FORMAT: {}\".format(type(sample_phrase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple forward to see if its working\n",
    "out=model(Variable(sample_phrase).cuda())\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_target(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_iters = 5000000\n",
    "num_epochs = n_iters/(len(x_train))/batch_size\n",
    "num_epochs=int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vec = Variable(make_bow_vector(train_data[0][0],word_to_ix)).cuda()\n",
    "bow_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Variable(make_target(train_data[0][1])).cuda()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(bow_vec)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_function(output, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for (sent,label) in train_data:\n",
    "        # Step 1 - clear the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        ## Step 2- Prepare input and label\n",
    "        bow_vec = Variable(make_bow_vector(sent,word_to_ix)).cuda()\n",
    "        target = Variable(make_target(label)).cuda()\n",
    "        \n",
    "        # Step 3 - Run forward pass\n",
    "        output = model(bow_vec)\n",
    "        \n",
    "        # Step 4 - Compute loss, gradients, update parameters\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1      \n",
    "        ## Calculate final accuracy\n",
    "        if iter % 2000 ==0:\n",
    "            print(\"I'm validating now!\")\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            i=0\n",
    "            for (sent,label) in valid_data:\n",
    "                i+=1\n",
    "                bow_vec = Variable(make_bow_vector(sent,word_to_ix)).cuda()\n",
    "                target = Variable(make_target(label)).cuda()\n",
    "                output = model(bow_vec)\n",
    "                #_,predicted = torch.max(output.data,1)\n",
    "                #total += target.size(0)\n",
    "                #correct += (predicted[0] == make_target(label)).sum()\n",
    "            #accuracy = 100 * correct/total\n",
    "            print('Iterations: {}. Loss: {}'.format(iter,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
