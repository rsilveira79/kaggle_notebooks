{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotting Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## NLP Libraries\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "spacy_en = spacy.load('en')\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "8387  id11749         All this is now the fitter for my purpose.\n",
       "8388  id10526                 I fixed myself on a wide solitude.\n",
       "8389  id13477  It is easily understood that what might improv...\n",
       "8390  id13761  Be this as it may, I now began to feel the ins...\n",
       "8391  id04282  Long winded, statistical, and drearily genealo..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking dataset unbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>id03325</td>\n",
       "      <td>But these and other difficulties attending res...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19572  id03325  But these and other difficulties attending res...    EAP\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAP = train[train['author']=='EAP']\n",
    "EAP_size = len(EAP)\n",
    "print(EAP_size)\n",
    "EAP.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>id07976</td>\n",
       "      <td>They admitted they had been drunk, but both vo...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>id18823</td>\n",
       "      <td>When a fumbling came in the nearer casements h...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>id08678</td>\n",
       "      <td>Average people in society and business New Eng...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>id14420</td>\n",
       "      <td>My watch was still going, and told me that the...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19554  id07976  They admitted they had been drunk, but both vo...    HPL\n",
       "19559  id18823  When a fumbling came in the nearer casements h...    HPL\n",
       "19561  id08678  Average people in society and business New Eng...    HPL\n",
       "19571  id14420  My watch was still going, and told me that the...    HPL\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPL = train[train['author']=='HPL']\n",
    "HPL_size = len(HPL)\n",
    "print(HPL_size)\n",
    "HPL.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>id10563</td>\n",
       "      <td>Yet from whom has not that rude hand rent away...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>id00832</td>\n",
       "      <td>These reflections made our legislators pause, ...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>id26790</td>\n",
       "      <td>Once my fancy was soothed with dreams of virtu...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>id14263</td>\n",
       "      <td>Nay, you may have met with another whom you ma...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>id07567</td>\n",
       "      <td>Stress of weather drove us up the Adriatic Gul...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19563  id10563  Yet from whom has not that rude hand rent away...    MWS\n",
       "19566  id00832  These reflections made our legislators pause, ...    MWS\n",
       "19569  id26790  Once my fancy was soothed with dreams of virtu...    MWS\n",
       "19570  id14263  Nay, you may have met with another whom you ma...    MWS\n",
       "19573  id07567  Stress of weather drove us up the Adriatic Gul...    MWS"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWS = train[train['author']=='MWS']\n",
    "MWS_size = len(MWS)\n",
    "print(MWS_size)\n",
    "MWS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7900, 6044, 5635]), array([1, 2, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([EAP_size,MWS_size,HPL_size])\n",
    "y=np.arange(1,4)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0877d56c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax1 = plt.subplots(1, 1, figsize=(8, 6), sharex=True)\n",
    "sns.barplot(x, y, palette=\"RdBu_r\", ax=ax1)\n",
    "plt.setp(f.axes,yticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    \n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "\n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=2)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was gold snuff box from which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  this process however afforded me no means of a...  \n",
       "1  it never once occurred to me that the fumbling...  \n",
       "2  in his left hand was gold snuff box from which...  \n",
       "3  how lovely is spring as we looked from windsor...  \n",
       "4  finding nothing else not even gold the superin...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['phrase_preprocessed']=train['text'].apply(lambda x: transformText(x,do_stop=False, do_stem=False))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>still as urged our leaving ireland with such i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>if fire wanted fanning it could readily be fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>and when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>while was thinking how should possibly manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>am not sure to what limit his knowledge may ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1  id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2  id00134  And when they had broken down the frail door t...   \n",
       "3  id27757  While I was thinking how I should possibly man...   \n",
       "4  id04081  I am not sure to what limit his knowledge may ...   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  still as urged our leaving ireland with such i...  \n",
       "1  if fire wanted fanning it could readily be fan...  \n",
       "2  and when they had broken down the frail door t...  \n",
       "3  while was thinking how should possibly manage ...  \n",
       "4  am not sure to what limit his knowledge may ex...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['phrase_preprocessed']=test['text'].apply(lambda x: transformText(x,do_stop=False, do_stem=False))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test split, Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train['phrase_preprocessed'],\n",
    "                                                      train['author'], \n",
    "                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'still as urged our leaving ireland with such inquietude and impatience my father thought it best to yield ',\n",
       "       'if fire wanted fanning it could readily be fanned with newspaper and as the government grew weaker have no doubt that leather and iron acquired durability in proportion for in very short time there was not pair of bellows in all rotterdam that ever stood in need of stitch or required the assistance of hammer ',\n",
       "       'and when they had broken down the frail door they found only this two cleanly picked human skeletons on the earthen floor and number of singular beetles crawling in the shadowy corners ',\n",
       "       ...,\n",
       "       'it is easily understood that what might improve closely scrutinized detail may at the same time injure general or more distantly observed effect ',\n",
       "       'be this as it may now began to feel the inspiration of burning hope and at length nurtured in my secret thoughts stern and desperate resolution that would submit no longer to be enslaved ',\n",
       "       'long winded statistical and drearily genealogical as some of the matter was there ran through it continuous thread of brooding tenacious horror and preternatural malevolence which impressed me even more than it had impressed the good doctor '], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test['phrase_preprocessed'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in list(x_train) + list(x_valid) + list(x_test):\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28307\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = { \"EAP\": 0, \"MWS\": 1, \"HPL\": 2 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28307, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about midway in the short vista which my dreamy vision took in one small circular island profusely verdured reposed upon the bosom of the stream ',\n",
       "  'EAP'),\n",
       " (' o aira city of marble and beryl how many are thy beauties how loved the warm and fragrant groves across the hyaline nithra and the falls of the tiny kra that flowed through the verdant valley in those groves and in that vale the children wove wreaths for one another and at dusk dreamed strange dreams under the yath trees on the mountain as saw below me the lights of the city and the curving nithra reflecting ribbon of stars ',\n",
       "  'HPL'),\n",
       " ('instances of desertion became more frequent and even murders which made the hearer sick with horror where the fear of contagion had armed those nearest in blood against each other ',\n",
       "  'MWS'),\n",
       " ('generation after generation lived and felt and died there and in days when people weren t afraid to live and feel and die ',\n",
       "  'HPL'),\n",
       " ('would you also create for yourself and the world demoniacal enemy ', 'MWS')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=list(zip(x_train,y_train))\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the first horrible incident of our acquaintance was the greatest shock ever experienced and it is only with reluctance that repeat it ',\n",
       "  'HPL'),\n",
       " ('mr the student swooned ', 'EAP'),\n",
       " ('could only think of the bourne of my travels and the work which was to occupy me whilst they endured ',\n",
       "  'MWS'),\n",
       " ('packed up my chemical instruments and the materials had collected resolving to finish my labours in some obscure nook in the northern highlands of scotland ',\n",
       "  'MWS'),\n",
       " ('the fits grow successively more and more distinctive and endure each for longer term than the preceding ',\n",
       "  'EAP')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data=list(zip(x_valid,y_valid))\n",
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq.split()]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_idx):\n",
    "    return torch.LongTensor([label_to_idx[label]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model - LSTM Classifier with Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.42B.300d.txt   GoogleNews-vectors-negative300.bin\r\n",
      "glove.840B.300d.txt  wiki.en.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../vectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format('../../vectors/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_DIM = 300\n",
    "## standard deviation to use\n",
    "sd = 1/np.sqrt(W2V_DIM)\n",
    "## Random initialization\n",
    "weights = np.random.normal(0, scale=sd, size=[VOCAB_SIZE, W2V_DIM])\n",
    "weights = weights.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_to_ix:\n",
    "    id = word_to_ix.get(word,None)\n",
    "    if id is not None:\n",
    "        try:\n",
    "            weights[id]=w2v.wv.word_vec(word)\n",
    "        except:\n",
    "            weights[id]=np.random.normal(0, scale=sd, size=[1, W2V_DIM]) ## If word not present, initialize randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 0,\n",
       " 'midway': 1,\n",
       " 'in': 2,\n",
       " 'the': 3,\n",
       " 'short': 4,\n",
       " 'vista': 5,\n",
       " 'which': 6,\n",
       " 'my': 7,\n",
       " 'dreamy': 8,\n",
       " 'vision': 9,\n",
       " 'took': 10,\n",
       " 'one': 11,\n",
       " 'small': 12,\n",
       " 'circular': 13,\n",
       " 'island': 14,\n",
       " 'profusely': 15,\n",
       " 'verdured': 16,\n",
       " 'reposed': 17,\n",
       " 'upon': 18,\n",
       " 'bosom': 19,\n",
       " 'of': 20,\n",
       " 'stream': 21,\n",
       " 'o': 22,\n",
       " 'aira': 23,\n",
       " 'city': 24,\n",
       " 'marble': 25,\n",
       " 'and': 26,\n",
       " 'beryl': 27,\n",
       " 'how': 28,\n",
       " 'many': 29,\n",
       " 'are': 30,\n",
       " 'thy': 31,\n",
       " 'beauties': 32,\n",
       " 'loved': 33,\n",
       " 'warm': 34,\n",
       " 'fragrant': 35,\n",
       " 'groves': 36,\n",
       " 'across': 37,\n",
       " 'hyaline': 38,\n",
       " 'nithra': 39,\n",
       " 'falls': 40,\n",
       " 'tiny': 41,\n",
       " 'kra': 42,\n",
       " 'that': 43,\n",
       " 'flowed': 44,\n",
       " 'through': 45,\n",
       " 'verdant': 46,\n",
       " 'valley': 47,\n",
       " 'those': 48,\n",
       " 'vale': 49,\n",
       " 'children': 50,\n",
       " 'wove': 51,\n",
       " 'wreaths': 52,\n",
       " 'for': 53,\n",
       " 'another': 54,\n",
       " 'at': 55,\n",
       " 'dusk': 56,\n",
       " 'dreamed': 57,\n",
       " 'strange': 58,\n",
       " 'dreams': 59,\n",
       " 'under': 60,\n",
       " 'yath': 61,\n",
       " 'trees': 62,\n",
       " 'on': 63,\n",
       " 'mountain': 64,\n",
       " 'as': 65,\n",
       " 'saw': 66,\n",
       " 'below': 67,\n",
       " 'me': 68,\n",
       " 'lights': 69,\n",
       " 'curving': 70,\n",
       " 'reflecting': 71,\n",
       " 'ribbon': 72,\n",
       " 'stars': 73,\n",
       " 'instances': 74,\n",
       " 'desertion': 75,\n",
       " 'became': 76,\n",
       " 'more': 77,\n",
       " 'frequent': 78,\n",
       " 'even': 79,\n",
       " 'murders': 80,\n",
       " 'made': 81,\n",
       " 'hearer': 82,\n",
       " 'sick': 83,\n",
       " 'with': 84,\n",
       " 'horror': 85,\n",
       " 'where': 86,\n",
       " 'fear': 87,\n",
       " 'contagion': 88,\n",
       " 'had': 89,\n",
       " 'armed': 90,\n",
       " 'nearest': 91,\n",
       " 'blood': 92,\n",
       " 'against': 93,\n",
       " 'each': 94,\n",
       " 'other': 95,\n",
       " 'generation': 96,\n",
       " 'after': 97,\n",
       " 'lived': 98,\n",
       " 'felt': 99,\n",
       " 'died': 100,\n",
       " 'there': 101,\n",
       " 'days': 102,\n",
       " 'when': 103,\n",
       " 'people': 104,\n",
       " 'weren': 105,\n",
       " 't': 106,\n",
       " 'afraid': 107,\n",
       " 'to': 108,\n",
       " 'live': 109,\n",
       " 'feel': 110,\n",
       " 'die': 111,\n",
       " 'would': 112,\n",
       " 'you': 113,\n",
       " 'also': 114,\n",
       " 'create': 115,\n",
       " 'yourself': 116,\n",
       " 'world': 117,\n",
       " 'demoniacal': 118,\n",
       " 'enemy': 119,\n",
       " 'it': 120,\n",
       " 'was': 121,\n",
       " 'horned': 122,\n",
       " 'waning': 123,\n",
       " 'moon': 124,\n",
       " 'first': 125,\n",
       " 'time': 126,\n",
       " 'he': 127,\n",
       " 'have': 128,\n",
       " 'been': 129,\n",
       " 'too': 130,\n",
       " 'great': 131,\n",
       " 'haste': 132,\n",
       " 'such': 133,\n",
       " 'things': 134,\n",
       " 'securing': 135,\n",
       " 'boat': 136,\n",
       " 'but': 137,\n",
       " 'what': 138,\n",
       " 'mainly': 139,\n",
       " 'disturbed': 140,\n",
       " 'idea': 141,\n",
       " 'perceptibly': 142,\n",
       " 'descended': 143,\n",
       " 'very': 144,\n",
       " 'memory': 145,\n",
       " 'half': 146,\n",
       " 'unmans': 147,\n",
       " 'demanded': 148,\n",
       " 'hand': 149,\n",
       " 'morrow': 150,\n",
       " 'feelings': 151,\n",
       " 'revenge': 152,\n",
       " 'hatred': 153,\n",
       " 'filled': 154,\n",
       " 'did': 155,\n",
       " 'not': 156,\n",
       " 'strive': 157,\n",
       " 'control': 158,\n",
       " 'them': 159,\n",
       " 'allowing': 160,\n",
       " 'myself': 161,\n",
       " 'be': 162,\n",
       " 'borne': 163,\n",
       " 'away': 164,\n",
       " 'by': 165,\n",
       " 'bent': 166,\n",
       " 'mind': 167,\n",
       " 'towards': 168,\n",
       " 'injury': 169,\n",
       " 'death': 170,\n",
       " 'yet': 171,\n",
       " 'is': 172,\n",
       " 'human': 173,\n",
       " 'nature': 174,\n",
       " 'excitement': 175,\n",
       " 'dear': 176,\n",
       " 'imagination': 177,\n",
       " 'painter': 178,\n",
       " 'tempest': 179,\n",
       " 'earthquake': 180,\n",
       " 'or': 181,\n",
       " 'worse': 182,\n",
       " 'stormy': 183,\n",
       " 'ruin': 184,\n",
       " 'fraught': 185,\n",
       " 'passions': 186,\n",
       " 'man': 187,\n",
       " 'softened': 188,\n",
       " 'real': 189,\n",
       " 'sorrows': 190,\n",
       " 'endless': 191,\n",
       " 'regrets': 192,\n",
       " 'clothing': 193,\n",
       " 'these': 194,\n",
       " 'fictitious': 195,\n",
       " 'ones': 196,\n",
       " 'ideality': 197,\n",
       " 'takes': 198,\n",
       " 'mortal': 199,\n",
       " 'sting': 200,\n",
       " 'from': 201,\n",
       " 'pain': 202,\n",
       " 'immemorial': 203,\n",
       " 'figure': 204,\n",
       " 'deputy': 205,\n",
       " 'messenger': 206,\n",
       " 'hidden': 207,\n",
       " 'terrible': 208,\n",
       " 'powers': 209,\n",
       " 'black': 210,\n",
       " 'witch': 211,\n",
       " 'cult': 212,\n",
       " 'nyarlathotep': 213,\n",
       " 'necronomicon': 214,\n",
       " 'thus': 215,\n",
       " 'promised': 216,\n",
       " 'journied': 217,\n",
       " 'destination': 218,\n",
       " 'roused': 219,\n",
       " 'ardent': 220,\n",
       " 'expectation': 221,\n",
       " 'fulfilment': 222,\n",
       " 'all': 223,\n",
       " 'boyhood': 224,\n",
       " 'we': 225,\n",
       " 'promise': 226,\n",
       " 'ourselves': 227,\n",
       " 'power': 228,\n",
       " 'enjoyment': 229,\n",
       " 'maturity': 230,\n",
       " 'resources': 231,\n",
       " 'his': 232,\n",
       " 'this': 233,\n",
       " 'occasion': 234,\n",
       " 'were': 235,\n",
       " 'truly': 236,\n",
       " 'astonishing': 237,\n",
       " 'conversation': 238,\n",
       " 'full': 239,\n",
       " 'often': 240,\n",
       " 'imitation': 241,\n",
       " 'persian': 242,\n",
       " 'arabic': 243,\n",
       " 'writers': 244,\n",
       " 'invented': 245,\n",
       " 'tales': 246,\n",
       " 'wonderful': 247,\n",
       " 'fancy': 248,\n",
       " 'passion': 249,\n",
       " 'devil': 250,\n",
       " 's': 251,\n",
       " 'matter': 252,\n",
       " 'now': 253,\n",
       " 'said': 254,\n",
       " 'second': 255,\n",
       " 'possible': 256,\n",
       " 'adduce': 257,\n",
       " 'fifty': 258,\n",
       " 'instead': 259,\n",
       " 'five': 260,\n",
       " 'examples': 261,\n",
       " 'bodies': 262,\n",
       " 'found': 263,\n",
       " 'floating': 264,\n",
       " 'end': 265,\n",
       " 'two': 266,\n",
       " 'three': 267,\n",
       " 'could': 268,\n",
       " 'still': 269,\n",
       " 'properly': 270,\n",
       " 'regarded': 271,\n",
       " 'only': 272,\n",
       " 'exceptions': 273,\n",
       " 'l': 274,\n",
       " 'etoile': 275,\n",
       " 'rule': 276,\n",
       " 'until': 277,\n",
       " 'itself': 278,\n",
       " 'should': 279,\n",
       " 'confuted': 280,\n",
       " 'left': 281,\n",
       " 'no': 282,\n",
       " 'shadow': 283,\n",
       " 'clew': 284,\n",
       " 'convict': 285,\n",
       " 'suspect': 286,\n",
       " 'crime': 287,\n",
       " 'will': 288,\n",
       " 'therefore': 289,\n",
       " 'please': 290,\n",
       " 'your': 291,\n",
       " 'majesty': 292,\n",
       " 'so': 293,\n",
       " 'good': 294,\n",
       " 'take': 295,\n",
       " 'deed': 296,\n",
       " 'manner': 297,\n",
       " 'means': 298,\n",
       " 'either': 299,\n",
       " 'can': 300,\n",
       " 'swallow': 301,\n",
       " 'drop': 302,\n",
       " 'least': 303,\n",
       " 'villainous': 304,\n",
       " 'bilge': 305,\n",
       " 'water': 306,\n",
       " 'answers': 307,\n",
       " 'hall': 308,\n",
       " 'strap': 309,\n",
       " 'must': 310,\n",
       " 'own': 311,\n",
       " 'little': 312,\n",
       " 'proud': 313,\n",
       " 'captain': 314,\n",
       " 'offered': 315,\n",
       " 'dignity': 316,\n",
       " 'vessel': 317,\n",
       " 'entreated': 318,\n",
       " 'remain': 319,\n",
       " 'greatest': 320,\n",
       " 'earnestness': 321,\n",
       " 'valuable': 322,\n",
       " 'consider': 323,\n",
       " 'services': 324,\n",
       " 'father': 325,\n",
       " 'narrow': 326,\n",
       " 'minded': 327,\n",
       " 'trader': 328,\n",
       " 'idleness': 329,\n",
       " 'aspirations': 330,\n",
       " 'ambition': 331,\n",
       " 'son': 332,\n",
       " 'do': 333,\n",
       " 'desert': 334,\n",
       " 'hour': 335,\n",
       " 'trial': 336,\n",
       " 'god': 337,\n",
       " 'exclaimed': 338,\n",
       " 'old': 339,\n",
       " 'exceedingly': 340,\n",
       " 'surprised': 341,\n",
       " 'receiving': 342,\n",
       " 'rude': 343,\n",
       " 'an': 344,\n",
       " 'answer': 345,\n",
       " 'stranger': 346,\n",
       " 'disconcerted': 347,\n",
       " 'perceiving': 348,\n",
       " 'frowning': 349,\n",
       " 'angry': 350,\n",
       " 'countenances': 351,\n",
       " 'companions': 352,\n",
       " 'finds': 353,\n",
       " 'difficult': 354,\n",
       " 'conceive': 355,\n",
       " 'vast': 356,\n",
       " 'masses': 357,\n",
       " 'handle': 358,\n",
       " 'easily': 359,\n",
       " 'light': 360,\n",
       " 'our': 361,\n",
       " 'reason': 362,\n",
       " 'tells': 363,\n",
       " 'us': 364,\n",
       " 'they': 365,\n",
       " 'actually': 366,\n",
       " 'every': 367,\n",
       " 'request': 368,\n",
       " 'positive': 369,\n",
       " 'immediate': 370,\n",
       " 'long': 371,\n",
       " 'few': 372,\n",
       " 'requests': 373,\n",
       " 'refused': 374,\n",
       " 'indeed': 375,\n",
       " 'went': 376,\n",
       " 'far': 377,\n",
       " 'hint': 378,\n",
       " 'faint': 379,\n",
       " 'beating': 380,\n",
       " 'wings': 381,\n",
       " 'glimpse': 382,\n",
       " 'shining': 383,\n",
       " 'eyes': 384,\n",
       " 'mountainous': 385,\n",
       " 'white': 386,\n",
       " 'bulk': 387,\n",
       " 'beyond': 388,\n",
       " 'remotest': 389,\n",
       " 'suppose': 390,\n",
       " 'hearing': 391,\n",
       " 'much': 392,\n",
       " 'native': 393,\n",
       " 'superstition': 394,\n",
       " 'liked': 395,\n",
       " 'doctors': 396,\n",
       " 'broad': 397,\n",
       " 'lent': 398,\n",
       " 'their': 399,\n",
       " 'influence': 400,\n",
       " 'obtaining': 401,\n",
       " 'carefully': 402,\n",
       " 'sheltered': 403,\n",
       " 'copy': 404,\n",
       " 'alhazred': 405,\n",
       " 'objectionable': 406,\n",
       " 'library': 407,\n",
       " 'miskatonic': 408,\n",
       " 'university': 409,\n",
       " 'initiating': 410,\n",
       " 'scene': 411,\n",
       " 'english': 412,\n",
       " 'politics': 413,\n",
       " 'society': 414,\n",
       " 'soon': 415,\n",
       " 'become': 416,\n",
       " 'part': 417,\n",
       " 'narrated': 418,\n",
       " 'number': 419,\n",
       " 'anecdotes': 420,\n",
       " 'sketched': 421,\n",
       " 'characters': 422,\n",
       " 'discourse': 423,\n",
       " 'rich': 424,\n",
       " 'varied': 425,\n",
       " 'pervading': 426,\n",
       " 'senses': 427,\n",
       " 'pleasure': 428,\n",
       " 'town': 429,\n",
       " 'windsor': 430,\n",
       " 'survivors': 431,\n",
       " 'neighbouring': 432,\n",
       " 'counties': 433,\n",
       " 'chiefly': 434,\n",
       " 'assembled': 435,\n",
       " 'wore': 436,\n",
       " 'melancholy': 437,\n",
       " 'aspect': 438,\n",
       " 'dream': 439,\n",
       " 'soul': 440,\n",
       " 'inhabiting': 441,\n",
       " 'inferior': 442,\n",
       " 'body': 443,\n",
       " 'desperately': 444,\n",
       " 'struggling': 445,\n",
       " 'speak': 446,\n",
       " 'simple': 447,\n",
       " 'halting': 448,\n",
       " 'tongue': 449,\n",
       " 'dulness': 450,\n",
       " 'utter': 451,\n",
       " 'moved': 452,\n",
       " 'feeling': 453,\n",
       " 'wonder': 454,\n",
       " 'awe': 455,\n",
       " 'picture': 456,\n",
       " 'omnipotent': 457,\n",
       " 'warring': 458,\n",
       " 'creatures': 459,\n",
       " 'capable': 460,\n",
       " 'exciting': 461,\n",
       " 'virtuous': 462,\n",
       " 'appeared': 463,\n",
       " 'highest': 464,\n",
       " 'honour': 465,\n",
       " 'befall': 466,\n",
       " 'sensitive': 467,\n",
       " 'being': 468,\n",
       " 'base': 469,\n",
       " 'vicious': 470,\n",
       " 'record': 471,\n",
       " 'lowest': 472,\n",
       " 'degradation': 473,\n",
       " 'condition': 474,\n",
       " 'abject': 475,\n",
       " 'than': 476,\n",
       " 'blind': 477,\n",
       " 'mole': 478,\n",
       " 'harmless': 479,\n",
       " 'worm': 480,\n",
       " 'mad': 481,\n",
       " 'believe': 482,\n",
       " 'assertion': 483,\n",
       " 'intellect': 484,\n",
       " 'employed': 485,\n",
       " 'among': 486,\n",
       " 'worldly': 487,\n",
       " 'considerations': 488,\n",
       " 'any': 489,\n",
       " 'grasp': 490,\n",
       " 'somehow': 491,\n",
       " 'brief': 492,\n",
       " 'avoid': 493,\n",
       " 'inconvenience': 494,\n",
       " 'making': 495,\n",
       " 'total': 496,\n",
       " 'vacuum': 497,\n",
       " 'moment': 498,\n",
       " 'within': 499,\n",
       " 'chamber': 500,\n",
       " 'purification': 501,\n",
       " 'never': 502,\n",
       " 'accomplished': 503,\n",
       " 'once': 504,\n",
       " 'gradual': 505,\n",
       " 'valve': 506,\n",
       " 'opened': 507,\n",
       " 'seconds': 508,\n",
       " 'then': 509,\n",
       " 'closed': 510,\n",
       " 'again': 511,\n",
       " 'strokes': 512,\n",
       " 'pump': 513,\n",
       " 'condenser': 514,\n",
       " 'supplied': 515,\n",
       " 'place': 516,\n",
       " 'atmosphere': 517,\n",
       " 'ejected': 518,\n",
       " 'engaged': 519,\n",
       " 'attention': 520,\n",
       " 'suddenly': 521,\n",
       " 'grew': 522,\n",
       " 'despicable': 523,\n",
       " 'thing': 524,\n",
       " 'curious': 525,\n",
       " 'citizens': 526,\n",
       " 'talked': 527,\n",
       " 'affair': 528,\n",
       " 'marvelled': 529,\n",
       " 'unexampled': 530,\n",
       " 'loveliness': 531,\n",
       " 'flower': 532,\n",
       " 'clad': 533,\n",
       " 'earth': 534,\n",
       " 'genial': 535,\n",
       " 'sunshine': 536,\n",
       " 'grateful': 537,\n",
       " 'shade': 538,\n",
       " 'melody': 539,\n",
       " 'birds': 540,\n",
       " 'woods': 541,\n",
       " 'splendour': 542,\n",
       " 'ruins': 543,\n",
       " 'clear': 544,\n",
       " 'effulgence': 545,\n",
       " 'night': 546,\n",
       " 'combination': 547,\n",
       " 'voluptuous': 548,\n",
       " 'transcending': 549,\n",
       " 'land': 550,\n",
       " 'inspiring': 551,\n",
       " 'quicker': 552,\n",
       " 'spirit': 553,\n",
       " 'life': 554,\n",
       " 'added': 555,\n",
       " 'sensitiveness': 556,\n",
       " 'articulation': 557,\n",
       " 'her': 558,\n",
       " 'frame': 559,\n",
       " 'gave': 560,\n",
       " 'edge': 561,\n",
       " 'poignancy': 562,\n",
       " 'grief': 563,\n",
       " 'question': 564,\n",
       " 'explicitly': 565,\n",
       " 'maelzel': 566,\n",
       " 'automaton': 567,\n",
       " 'pure': 568,\n",
       " 'machine': 569,\n",
       " 'reply': 570,\n",
       " 'invariably': 571,\n",
       " 'same': 572,\n",
       " 'i': 573,\n",
       " 'say': 574,\n",
       " 'nothing': 575,\n",
       " 'fled': 576,\n",
       " 'knew': 577,\n",
       " 'whither': 578,\n",
       " 'greater': 579,\n",
       " 'dread': 580,\n",
       " 'convulsion': 581,\n",
       " 'shook': 582,\n",
       " 'lions': 583,\n",
       " 'into': 584,\n",
       " 'civil': 585,\n",
       " 'streets': 586,\n",
       " 'strong': 587,\n",
       " 'winged': 588,\n",
       " 'eagles': 589,\n",
       " 'blinded': 590,\n",
       " 'fell': 591,\n",
       " 'market': 592,\n",
       " 'places': 593,\n",
       " 'while': 594,\n",
       " 'owls': 595,\n",
       " 'bats': 596,\n",
       " 'shewed': 597,\n",
       " 'themselves': 598,\n",
       " 'welcoming': 599,\n",
       " 'early': 600,\n",
       " 'walking': 601,\n",
       " 'riding': 602,\n",
       " 'common': 603,\n",
       " 'occupations': 604,\n",
       " 'overcame': 605,\n",
       " 'him': 606,\n",
       " 'seemed': 607,\n",
       " 'tremble': 608,\n",
       " 'ever': 609,\n",
       " 'verge': 610,\n",
       " 'annihilation': 611,\n",
       " 'merciful': 612,\n",
       " 'return': 613,\n",
       " 'therefrom': 614,\n",
       " 'who': 615,\n",
       " 'has': 616,\n",
       " 'come': 617,\n",
       " 'back': 618,\n",
       " 'out': 619,\n",
       " 'nethermost': 620,\n",
       " 'chambers': 621,\n",
       " 'haggard': 622,\n",
       " 'knowing': 623,\n",
       " 'peace': 624,\n",
       " 'rests': 625,\n",
       " 'nevermore': 626,\n",
       " 'besides': 627,\n",
       " 'quantity': 628,\n",
       " 'solid': 629,\n",
       " 'gold': 630,\n",
       " 'ornaments': 631,\n",
       " 'nearly': 632,\n",
       " 'hundred': 633,\n",
       " 'massive': 634,\n",
       " 'finger': 635,\n",
       " 'earrings': 636,\n",
       " 'chains': 637,\n",
       " 'thirty': 638,\n",
       " 'if': 639,\n",
       " 'remember': 640,\n",
       " 'eighty': 641,\n",
       " 'large': 642,\n",
       " 'heavy': 643,\n",
       " 'crucifixes': 644,\n",
       " 'censers': 645,\n",
       " 'value': 646,\n",
       " 'prodigious': 647,\n",
       " 'golden': 648,\n",
       " 'punch': 649,\n",
       " 'bowl': 650,\n",
       " 'ornamented': 651,\n",
       " 'richly': 652,\n",
       " 'chased': 653,\n",
       " 'vine': 654,\n",
       " 'leaves': 655,\n",
       " 'bacchanalian': 656,\n",
       " 'figures': 657,\n",
       " 'sword': 658,\n",
       " 'handles': 659,\n",
       " 'exquisitely': 660,\n",
       " 'embossed': 661,\n",
       " 'smaller': 662,\n",
       " 'articles': 663,\n",
       " 'cannot': 664,\n",
       " 'recollect': 665,\n",
       " 'sometimes': 666,\n",
       " 'wished': 667,\n",
       " 'express': 668,\n",
       " 'sensations': 669,\n",
       " 'mode': 670,\n",
       " 'uncouth': 671,\n",
       " 'inarticulate': 672,\n",
       " 'sounds': 673,\n",
       " 'broke': 674,\n",
       " 'frightened': 675,\n",
       " 'silence': 676,\n",
       " 'diamond': 677,\n",
       " 'like': 678,\n",
       " 'scarcely': 679,\n",
       " 'admitted': 680,\n",
       " 'sufficient': 681,\n",
       " 'intensity': 682,\n",
       " 'evidently': 683,\n",
       " 'thought': 684,\n",
       " 'brilliancy': 685,\n",
       " 'oil': 686,\n",
       " 'bob': 687,\n",
       " 'unmistakably': 688,\n",
       " 'akin': 689,\n",
       " 'sculpture': 690,\n",
       " 'young': 691,\n",
       " 'wilcox': 692,\n",
       " 'lips': 693,\n",
       " 'heard': 694,\n",
       " 'voice': 695,\n",
       " 'kindness': 696,\n",
       " 'directed': 697,\n",
       " 'shall': 698,\n",
       " 'forever': 699,\n",
       " 'present': 700,\n",
       " 'humanity': 701,\n",
       " 'assures': 702,\n",
       " 'success': 703,\n",
       " 'friends': 704,\n",
       " 'whom': 705,\n",
       " 'am': 706,\n",
       " 'point': 707,\n",
       " 'meeting': 708,\n",
       " 'may': 709,\n",
       " 'know': 710,\n",
       " 'names': 711,\n",
       " 'residence': 712,\n",
       " 'paused': 713,\n",
       " 'box': 714,\n",
       " 'held': 715,\n",
       " 'queer': 716,\n",
       " 'parchment': 717,\n",
       " 'whose': 718,\n",
       " 'linguist': 719,\n",
       " 'palaeographer': 720,\n",
       " 'able': 721,\n",
       " 'decipher': 722,\n",
       " 'identify': 723,\n",
       " 'came': 724,\n",
       " 'fire': 725,\n",
       " 'well': 726,\n",
       " 'heat': 727,\n",
       " 'discovery': 728,\n",
       " 'element': 729,\n",
       " 'useful': 730,\n",
       " 'food': 731,\n",
       " 'some': 732,\n",
       " 'offals': 733,\n",
       " 'travellers': 734,\n",
       " 'roasted': 735,\n",
       " 'tasted': 736,\n",
       " 'savoury': 737,\n",
       " 'berries': 738,\n",
       " 'gathered': 739,\n",
       " 'traced': 740,\n",
       " 'windings': 741,\n",
       " 'hailed': 742,\n",
       " 'steeple': 743,\n",
       " 'length': 744,\n",
       " 'issuing': 745,\n",
       " 'behind': 746,\n",
       " 'promontory': 747,\n",
       " 'friendship': 748,\n",
       " 'lasted': 749,\n",
       " 'several': 750,\n",
       " 'years': 751,\n",
       " 'during': 752,\n",
       " 'general': 753,\n",
       " 'temperament': 754,\n",
       " 'character': 755,\n",
       " 'instrumentality': 756,\n",
       " 'fiend': 757,\n",
       " 'intemperance': 758,\n",
       " 'blush': 759,\n",
       " 'confess': 760,\n",
       " 'experienced': 761,\n",
       " 'radical': 762,\n",
       " 'alteration': 763,\n",
       " 'just': 764,\n",
       " 'begin': 765,\n",
       " 'birch': 766,\n",
       " 'story': 767,\n",
       " 'hardly': 768,\n",
       " 'decide': 769,\n",
       " 'since': 770,\n",
       " 'practiced': 771,\n",
       " 'teller': 772,\n",
       " 'finally': 773,\n",
       " 'summoned': 774,\n",
       " 'up': 775,\n",
       " 'courage': 776,\n",
       " 'propped': 777,\n",
       " 'object': 778,\n",
       " 'table': 779,\n",
       " 'book': 780,\n",
       " 'turned': 781,\n",
       " 'rays': 782,\n",
       " 'peculiar': 783,\n",
       " 'violet': 784,\n",
       " 'lomar': 785,\n",
       " 'save': 786,\n",
       " 'nocturnal': 787,\n",
       " 'imaginings': 788,\n",
       " 'realms': 789,\n",
       " 'pole': 790,\n",
       " 'star': 791,\n",
       " 'shines': 792,\n",
       " 'high': 793,\n",
       " 'red': 794,\n",
       " 'aldebaran': 795,\n",
       " 'crawls': 796,\n",
       " 'low': 797,\n",
       " 'around': 798,\n",
       " 'horizon': 799,\n",
       " 'naught': 800,\n",
       " 'ice': 801,\n",
       " 'snow': 802,\n",
       " 'thousands': 803,\n",
       " 'squat': 804,\n",
       " 'yellow': 805,\n",
       " 'blighted': 806,\n",
       " 'cold': 807,\n",
       " 'call': 808,\n",
       " 'esquimaux': 809,\n",
       " 'perceive': 810,\n",
       " 'happiness': 811,\n",
       " 'late': 812,\n",
       " 'england': 813,\n",
       " 'undertook': 814,\n",
       " 'task': 815,\n",
       " 'unequal': 816,\n",
       " 'frequently': 817,\n",
       " 'play': 818,\n",
       " 'contrived': 819,\n",
       " 'gambler': 820,\n",
       " 'usual': 821,\n",
       " 'art': 822,\n",
       " 'let': 823,\n",
       " 'win': 824,\n",
       " 'considerable': 825,\n",
       " 'sums': 826,\n",
       " 'effectually': 827,\n",
       " 'entangle': 828,\n",
       " 'snares': 829,\n",
       " 'truth': 830,\n",
       " 'impossible': 831,\n",
       " 'imagine': 832,\n",
       " 'seen': 833,\n",
       " 'thoughts': 834,\n",
       " 'lawyer': 835,\n",
       " 'intersperse': 836,\n",
       " 'singular': 837,\n",
       " 'ingenuity': 838,\n",
       " 'wherever': 839,\n",
       " 'find': 840,\n",
       " 'room': 841,\n",
       " 'chisel': 842,\n",
       " 'thou': 843,\n",
       " 'holdest': 844,\n",
       " 'keys': 845,\n",
       " 'frost': 846,\n",
       " 'canst': 847,\n",
       " 'chain': 848,\n",
       " 'set': 849,\n",
       " 'free': 850,\n",
       " 'streams': 851,\n",
       " 'gentle': 852,\n",
       " 'governance': 853,\n",
       " 'buds': 854,\n",
       " 'born': 855,\n",
       " 'flourish': 856,\n",
       " 'nursed': 857,\n",
       " 'thee': 858,\n",
       " 'durst': 859,\n",
       " 'complain': 860,\n",
       " 'sinister': 861,\n",
       " 'couple': 862,\n",
       " 'atal': 863,\n",
       " 'innkeeper': 864,\n",
       " 'vowed': 865,\n",
       " 'twilight': 866,\n",
       " 'cats': 867,\n",
       " 'ulthar': 868,\n",
       " 'accursed': 869,\n",
       " 'yard': 870,\n",
       " 'pacing': 871,\n",
       " 'slowly': 872,\n",
       " 'solemnly': 873,\n",
       " 'circle': 874,\n",
       " 'cottage': 875,\n",
       " 'abreast': 876,\n",
       " 'performance': 877,\n",
       " 'unheard': 878,\n",
       " 'rite': 879,\n",
       " 'beasts': 880,\n",
       " 'regard': 881,\n",
       " 'personal': 882,\n",
       " 'appearance': 883,\n",
       " 'greatly': 884,\n",
       " 'dissimilar': 885,\n",
       " 'extreme': 886,\n",
       " 'quiescence': 887,\n",
       " 'having': 888,\n",
       " 'slumbered': 889,\n",
       " 'profoundly': 890,\n",
       " 'lying': 891,\n",
       " 'motionless': 892,\n",
       " 'fully': 893,\n",
       " 'prostrate': 894,\n",
       " 'midsummer': 895,\n",
       " 'noon': 896,\n",
       " 'begins': 897,\n",
       " 'steal': 898,\n",
       " 'consciousness': 899,\n",
       " 'mere': 900,\n",
       " 'sufficiency': 901,\n",
       " 'sleep': 902,\n",
       " 'without': 903,\n",
       " 'awakened': 904,\n",
       " 'external': 905,\n",
       " 'disturbances': 906,\n",
       " 'neither': 907,\n",
       " 'jealousy': 908,\n",
       " 'inquietude': 909,\n",
       " 'mistrust': 910,\n",
       " 'sentiment': 911,\n",
       " 'devotion': 912,\n",
       " 'faith': 913,\n",
       " 'kidnapping': 914,\n",
       " 'before': 915,\n",
       " 'orne': 916,\n",
       " 'gangway': 917,\n",
       " 'year': 918,\n",
       " 'child': 919,\n",
       " 'clod': 920,\n",
       " 'laundry': 921,\n",
       " 'worker': 922,\n",
       " 'named': 923,\n",
       " 'anastasia': 924,\n",
       " 'wolejko': 925,\n",
       " 'completely': 926,\n",
       " 'vanished': 927,\n",
       " 'sight': 928,\n",
       " 'persons': 929,\n",
       " 'neighbors': 930,\n",
       " 'evidence': 931,\n",
       " 'effect': 932,\n",
       " 'farm': 933,\n",
       " 'grounds': 934,\n",
       " 'extended': 935,\n",
       " 'deeply': 936,\n",
       " 'hill': 937,\n",
       " 'almost': 938,\n",
       " 'wheaton': 939,\n",
       " 'street': 940,\n",
       " 'arts': 941,\n",
       " 'arose': 942,\n",
       " 'supreme': 943,\n",
       " 'enthroned': 944,\n",
       " 'cast': 945,\n",
       " 'elevated': 946,\n",
       " 'abysses': 947,\n",
       " 'vacant': 948,\n",
       " 'crowded': 949,\n",
       " 'indescribably': 950,\n",
       " 'angled': 951,\n",
       " 'alien': 952,\n",
       " 'hued': 953,\n",
       " 'substance': 954,\n",
       " 'organic': 955,\n",
       " 'others': 956,\n",
       " 'inorganic': 957,\n",
       " 'reasonable': 958,\n",
       " 'objections': 959,\n",
       " 'urged': 960,\n",
       " 'solution': 961,\n",
       " 'chess': 962,\n",
       " 'player': 963,\n",
       " 'gone': 964,\n",
       " 'carriage': 965,\n",
       " 'post': 966,\n",
       " 'chaise': 967,\n",
       " 'horses': 968,\n",
       " 'orders': 969,\n",
       " 'london': 970,\n",
       " 'road': 971,\n",
       " 'eye': 972,\n",
       " 'dropped': 973,\n",
       " 'beetle': 974,\n",
       " 'minutes': 975,\n",
       " 'remained': 976,\n",
       " 'wrapped': 977,\n",
       " 'profoundest': 978,\n",
       " 'meditation': 979,\n",
       " 'flash': 980,\n",
       " 'lightning': 981,\n",
       " 'illuminated': 982,\n",
       " 'discovered': 983,\n",
       " 'its': 984,\n",
       " 'shape': 985,\n",
       " 'plainly': 986,\n",
       " 'gigantic': 987,\n",
       " 'stature': 988,\n",
       " 'deformity': 989,\n",
       " 'hideous': 990,\n",
       " 'belongs': 991,\n",
       " 'instantly': 992,\n",
       " 'informed': 993,\n",
       " 'wretch': 994,\n",
       " 'filthy': 995,\n",
       " 'daemon': 996,\n",
       " 'given': 997,\n",
       " 'she': 998,\n",
       " 'gentleman': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1640625 ,  0.18847656,  0.14160156, -0.02941895,  0.02087402,\n",
       "        0.13769531, -0.0168457 , -0.32617188,  0.07519531, -0.05200195,\n",
       "        0.11816406,  0.09179688,  0.06689453, -0.04614258, -0.04321289,\n",
       "        0.38476562,  0.0213623 , -0.09423828,  0.05712891,  0.18066406,\n",
       "       -0.08740234,  0.3359375 , -0.078125  , -0.07861328, -0.02111816,\n",
       "       -0.28320312,  0.08740234,  0.1796875 ,  0.11083984,  0.0480957 ,\n",
       "       -0.00469971,  0.03857422,  0.01940918,  0.15332031,  0.07714844,\n",
       "        0.01574707,  0.21875   ,  0.16113281, -0.14257812,  0.12695312,\n",
       "        0.04736328, -0.48242188,  0.10302734,  0.11816406,  0.24316406,\n",
       "       -0.00631714, -0.04858398,  0.05395508,  0.31835938,  0.16113281], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.word_vec(\"star\")[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix['star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1640625 ,  0.18847656,  0.14160156, -0.02941895,  0.02087402,\n",
       "        0.13769531, -0.0168457 , -0.32617188,  0.07519531, -0.05200195,\n",
       "        0.11816406,  0.09179688,  0.06689453, -0.04614258, -0.04321289,\n",
       "        0.38476562,  0.0213623 , -0.09423828,  0.05712891,  0.18066406,\n",
       "       -0.08740234,  0.3359375 , -0.078125  , -0.07861328, -0.02111816,\n",
       "       -0.28320312,  0.08740234,  0.1796875 ,  0.11083984,  0.0480957 ,\n",
       "       -0.00469971,  0.03857422,  0.01940918,  0.15332031,  0.07714844,\n",
       "        0.01574707,  0.21875   ,  0.16113281, -0.14257812,  0.12695312,\n",
       "        0.04736328, -0.48242188,  0.10302734,  0.11816406,  0.24316406,\n",
       "       -0.00631714, -0.04858398,  0.05395508,  0.31835938,  0.16113281], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[791][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_DIM = 300\n",
    "HIDDEN_DIM = 60\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruClassifierW2vec(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, vocab_size, label_size, pre_trained_weights, dropout):\n",
    "        super(GruClassifierW2vec, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_embeddings.weight.data=torch.Tensor(pre_trained_weights)\n",
    "        self.gru = nn.GRU(input_size = embedding_dim,\n",
    "                            hidden_size = hidden_dim,\n",
    "                            num_layers = num_layers,\n",
    "                            dropout = dropout)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the first is the hidden h\n",
    "        return (Variable(torch.zeros(self.num_layers, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = embeds.view(len(sentence), 1, -1)\n",
    "        for i in range(self.num_layers):\n",
    "            gru_out, self.hidden = self.gru(x, self.hidden)\n",
    "        y  = self.hidden2label(gru_out[-1])\n",
    "        log_probs = F.log_softmax(y)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GruClassifierW2vec(embedding_dim=W2V_DIM,\n",
    "                            hidden_dim=HIDDEN_DIM,\n",
    "                            num_layers=NUM_LAYERS,\n",
    "                            vocab_size=VOCAB_SIZE,\n",
    "                            label_size=NUM_LABELS,\n",
    "                            pre_trained_weights = weights,\n",
    "                            dropout = DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GruClassifierW2vec(\n",
       "  (word_embeddings): Embedding(28307, 300)\n",
       "  (gru): GRU(300, 60, num_layers=2, dropout=0.5)\n",
       "  (hidden2label): Linear(in_features=60, out_features=3)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function with mask to compensate class inbalance\n",
    "# mask=torch.FloatTensor((1,1.37))\n",
    "# loss_function = nn.CrossEntropyLoss(weight=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instances of desertion became more frequent and even murders which made the hearer sick with horror where the fear of contagion had armed those nearest in blood against each other '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=train_data[2][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 74\n",
       " 20\n",
       " 75\n",
       " 76\n",
       " 77\n",
       " 78\n",
       " 26\n",
       " 79\n",
       " 80\n",
       "  6\n",
       " 81\n",
       "  3\n",
       " 82\n",
       " 83\n",
       " 84\n",
       " 85\n",
       " 86\n",
       "  3\n",
       " 87\n",
       " 20\n",
       " 88\n",
       " 89\n",
       " 90\n",
       " 48\n",
       " 91\n",
       "  2\n",
       " 92\n",
       " 93\n",
       " 94\n",
       " 95\n",
       "[torch.LongTensor of size 30]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_context=Variable(make_context_vector(sample,word_to_ix))\n",
    "sample_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0413 -1.0175 -1.2536\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=model(sample_context)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "n_iters = 1500\n",
    "num_epochs = n_iters/(len(x_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 500. Loss: 1.0241338014602661\n",
      "Iterations: 1000. Loss: 0.6654553413391113\n",
      "Iterations: 1500. Loss: 0.6815277338027954\n",
      "Iterations: 2000. Loss: 0.45777907967567444\n",
      "Iterations: 2500. Loss: 0.7934134006500244\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for (sent,label) in train_data:\n",
    "        # Step 1 - clear the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "    \n",
    "        ## Avoid breaking for empty input\n",
    "        try:\n",
    "            ## Step 2- Prepare input and label\n",
    "            context_vec = Variable(make_context_vector(sent, word_to_ix))\n",
    "            target = Variable(make_target(label, label_to_ix)) \n",
    "            # Step 3 - Run forward pass\n",
    "            output = model(context_vec)  \n",
    "            # Step 4 - Compute loss, gradients, update parameters\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            pass\n",
    "        iter+=1      \n",
    "        ## Calculate final accuracy\n",
    "        if iter % 500 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (sent,label) in valid_data:\n",
    "                context_vec = Variable(make_context_vector(sent, word_to_ix))\n",
    "                target = Variable(make_target(label, label_to_ix))\n",
    "                output = model(context_vec)\n",
    "                _,predicted = torch.max(output.data,1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == make_target(label, label_to_ix)).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print('Iterations: {}. Loss: {}'.format(iter,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "bow_vec = Variable(make_context_vector(valid_data[n][0], word_to_ix))\n",
    "print(\"-\"*20 + \" INPUT \"+\"-\"*30)\n",
    "print(\"TRUE LABEL = {}\".format(valid_data[n][1]))\n",
    "print(\"SENTENCE = {}\".format(valid_data[n][0]))\n",
    "print(\"-\"*20 + \" PREDICTION \"+\"-\"*30)\n",
    "log_probs = model(bow_vec)\n",
    "_,predicted = torch.max(log_probs.data,1)\n",
    "print(\"PRED = {}\".format(predicted[0]))\n",
    "print(\"PRED = {}\".format(list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted[0])]))\n",
    "##print(\"LOG_PROB = {}\".format(log_probs))\n",
    "print(\"PROBS = {}\".format(F.softmax(log_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    my_sub.loc[i] = [test['id'][i], preds_proba[i][0], preds_proba[i][1], preds_proba[i][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub.to_csv('roberto_new_2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
