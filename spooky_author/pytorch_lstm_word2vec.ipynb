{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotting Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## NLP Libraries\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "spacy_en = spacy.load('en')\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking if GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'> - <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.cuda.FloatTensor([1])\n",
    "print(\"{} - {}\".format(type(a),type(a[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "8387  id11749         All this is now the fitter for my purpose.\n",
       "8388  id10526                 I fixed myself on a wide solitude.\n",
       "8389  id13477  It is easily understood that what might improv...\n",
       "8390  id13761  Be this as it may, I now began to feel the ins...\n",
       "8391  id04282  Long winded, statistical, and drearily genealo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking dataset unbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>19572</td>\n",
       "      <td>id03325</td>\n",
       "      <td>But these and other difficulties attending res...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7896</th>\n",
       "      <td>19574</td>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7897</th>\n",
       "      <td>19575</td>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>19576</td>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>19577</td>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id                                               text author\n",
       "7895  19572  id03325  But these and other difficulties attending res...    EAP\n",
       "7896  19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "7897  19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "7898  19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "7899  19577  id17513  For an item of news like this, it strikes us i...    EAP"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAP = train[train['author']=='EAP'].reset_index()\n",
    "EAP_size = len(EAP)\n",
    "print(EAP_size)\n",
    "EAP.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>19554</td>\n",
       "      <td>id07976</td>\n",
       "      <td>They admitted they had been drunk, but both vo...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>19559</td>\n",
       "      <td>id18823</td>\n",
       "      <td>When a fumbling came in the nearer casements h...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>19561</td>\n",
       "      <td>id08678</td>\n",
       "      <td>Average people in society and business New Eng...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>19571</td>\n",
       "      <td>id14420</td>\n",
       "      <td>My watch was still going, and told me that the...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>19578</td>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id                                               text author\n",
       "5630  19554  id07976  They admitted they had been drunk, but both vo...    HPL\n",
       "5631  19559  id18823  When a fumbling came in the nearer casements h...    HPL\n",
       "5632  19561  id08678  Average people in society and business New Eng...    HPL\n",
       "5633  19571  id14420  My watch was still going, and told me that the...    HPL\n",
       "5634  19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPL = train[train['author']=='HPL'].reset_index()\n",
    "HPL_size = len(HPL)\n",
    "print(HPL_size)\n",
    "HPL.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>19563</td>\n",
       "      <td>id10563</td>\n",
       "      <td>Yet from whom has not that rude hand rent away...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>19566</td>\n",
       "      <td>id00832</td>\n",
       "      <td>These reflections made our legislators pause, ...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>19569</td>\n",
       "      <td>id26790</td>\n",
       "      <td>Once my fancy was soothed with dreams of virtu...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>19570</td>\n",
       "      <td>id14263</td>\n",
       "      <td>Nay, you may have met with another whom you ma...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>19573</td>\n",
       "      <td>id07567</td>\n",
       "      <td>Stress of weather drove us up the Adriatic Gul...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id                                               text author\n",
       "6039  19563  id10563  Yet from whom has not that rude hand rent away...    MWS\n",
       "6040  19566  id00832  These reflections made our legislators pause, ...    MWS\n",
       "6041  19569  id26790  Once my fancy was soothed with dreams of virtu...    MWS\n",
       "6042  19570  id14263  Nay, you may have met with another whom you ma...    MWS\n",
       "6043  19573  id07567  Stress of weather drove us up the Adriatic Gul...    MWS"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWS = train[train['author']=='MWS'].reset_index()\n",
    "MWS_size = len(MWS)\n",
    "print(MWS_size)\n",
    "MWS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>13951</td>\n",
       "      <td>id16972</td>\n",
       "      <td>I saw them now even more unequivocally than I ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>13952</td>\n",
       "      <td>id05477</td>\n",
       "      <td>For some time his countenance had been losing ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>13954</td>\n",
       "      <td>id17337</td>\n",
       "      <td>\"It is done it is most cheerfully agreed.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>13956</td>\n",
       "      <td>id05256</td>\n",
       "      <td>\"At this stage of my reflections I endeavored ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>13959</td>\n",
       "      <td>id12599</td>\n",
       "      <td>Coincidences ten times as remarkable as this t...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id                                               text author\n",
       "5630  13951  id16972  I saw them now even more unequivocally than I ...    EAP\n",
       "5631  13952  id05477  For some time his countenance had been losing ...    EAP\n",
       "5632  13954  id17337          \"It is done it is most cheerfully agreed.    EAP\n",
       "5633  13956  id05256  \"At this stage of my reflections I endeavored ...    EAP\n",
       "5634  13959  id12599  Coincidences ten times as remarkable as this t...    EAP"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAP[0:HPL_size].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>id11176</td>\n",
       "      <td>Muffled sounds of possible vocal origin approa...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>id25516</td>\n",
       "      <td>It was that of an ancient Puritan interior a h...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>id21478</td>\n",
       "      <td>At evening Iranon sang, and while he sang an o...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>id17472</td>\n",
       "      <td>As before, he dreamed first of the village tha...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>id00605</td>\n",
       "      <td>So matters went till that night when Williams ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "16900  id11176  Muffled sounds of possible vocal origin approa...    HPL\n",
       "16901  id25516  It was that of an ancient Puritan interior a h...    HPL\n",
       "16902  id21478  At evening Iranon sang, and while he sang an o...    HPL\n",
       "16903  id17472  As before, he dreamed first of the village tha...    HPL\n",
       "16904  id00605  So matters went till that night when Williams ...    HPL"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_undersampled = pd.concat([EAP[0:HPL_size],HPL,MWS[0:HPL_size]], ignore_index=True)\n",
    "train_undersampled.drop(['index'],axis=1,inplace=True)\n",
    "train_undersampled = train_undersampled.sample(frac=1).reset_index(drop=True)\n",
    "train_undersampled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19579"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    \n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "\n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=2)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>could have fancied while looked at it that som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>the lids clenched themselves together as if in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>mais il faut agir that is to say frenchman nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>for an item of news like this it strikes us it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>he laid gnarled claw on my shoulder and it see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "       label                                phrase_preprocessed  \n",
       "19574      0  could have fancied while looked at it that som...  \n",
       "19575      0  the lids clenched themselves together as if in...  \n",
       "19576      0  mais il faut agir that is to say frenchman nev...  \n",
       "19577      0  for an item of news like this it strikes us it...  \n",
       "19578      1  he laid gnarled claw on my shoulder and it see...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['phrase_preprocessed']=train['text'].apply(lambda x: transformText(x,do_stop=False, do_stem=False))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>id11176</td>\n",
       "      <td>Muffled sounds of possible vocal origin approa...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>muffled sounds of possible vocal origin approa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>id25516</td>\n",
       "      <td>It was that of an ancient Puritan interior a h...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it was that of an ancient puritan interior hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>id21478</td>\n",
       "      <td>At evening Iranon sang, and while he sang an o...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>at evening iranon sang and while he sang an ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>id17472</td>\n",
       "      <td>As before, he dreamed first of the village tha...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>as before he dreamed first of the village that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>id00605</td>\n",
       "      <td>So matters went till that night when Williams ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>so matters went till that night when williams ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "16900  id11176  Muffled sounds of possible vocal origin approa...    HPL   \n",
       "16901  id25516  It was that of an ancient Puritan interior a h...    HPL   \n",
       "16902  id21478  At evening Iranon sang, and while he sang an o...    HPL   \n",
       "16903  id17472  As before, he dreamed first of the village tha...    HPL   \n",
       "16904  id00605  So matters went till that night when Williams ...    HPL   \n",
       "\n",
       "                                     phrase_preprocessed  \n",
       "16900  muffled sounds of possible vocal origin approa...  \n",
       "16901  it was that of an ancient puritan interior hea...  \n",
       "16902  at evening iranon sang and while he sang an ol...  \n",
       "16903  as before he dreamed first of the village that...  \n",
       "16904  so matters went till that night when williams ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_undersampled['phrase_preprocessed']=train_undersampled['text'].apply(lambda x: transformText(x,do_stop=False, do_stem=False))\n",
    "train_undersampled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  label\n",
       "0  id26305  This process, however, afforded me no means of...    EAP      0\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL      1\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP      0\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS      2\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL      1\n",
       "5  id22965  A youth passed in solitude, my best years spen...    MWS      2\n",
       "6  id09674  The astronomer, perhaps, at this point, took r...    EAP      0\n",
       "7  id13515        The surcingle hung in ribands from my body.    EAP      0\n",
       "8  id19322  I knew that you could not say to yourself 'ste...    EAP      0\n",
       "9  id00912  I confess that neither the structure of langua...    MWS      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix = { \"EAP\": 0, \"HPL\": 1, \"MWS\": 2 }\n",
    "train['label']=[label_to_ix[a] for a in train.author]\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>still as urged our leaving ireland with such i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>if fire wanted fanning it could readily be fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>and when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>while was thinking how should possibly manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>am not sure to what limit his knowledge may ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1  id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2  id00134  And when they had broken down the frail door t...   \n",
       "3  id27757  While I was thinking how I should possibly man...   \n",
       "4  id04081  I am not sure to what limit his knowledge may ...   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  still as urged our leaving ireland with such i...  \n",
       "1  if fire wanted fanning it could readily be fan...  \n",
       "2  and when they had broken down the frail door t...  \n",
       "3  while was thinking how should possibly manage ...  \n",
       "4  am not sure to what limit his knowledge may ex...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['phrase_preprocessed']=test['text'].apply(lambda x: transformText(x,do_stop=False, do_stem=False))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test split, Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train['phrase_preprocessed'],\n",
    "                                                      train['author'], \n",
    "                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'still as urged our leaving ireland with such inquietude and impatience my father thought it best to yield ',\n",
       "       'if fire wanted fanning it could readily be fanned with newspaper and as the government grew weaker have no doubt that leather and iron acquired durability in proportion for in very short time there was not pair of bellows in all rotterdam that ever stood in need of stitch or required the assistance of hammer ',\n",
       "       'and when they had broken down the frail door they found only this two cleanly picked human skeletons on the earthen floor and number of singular beetles crawling in the shadowy corners ',\n",
       "       ...,\n",
       "       'it is easily understood that what might improve closely scrutinized detail may at the same time injure general or more distantly observed effect ',\n",
       "       'be this as it may now began to feel the inspiration of burning hope and at length nurtured in my secret thoughts stern and desperate resolution that would submit no longer to be enslaved ',\n",
       "       'long winded statistical and drearily genealogical as some of the matter was there ran through it continuous thread of brooding tenacious horror and preternatural malevolence which impressed me even more than it had impressed the good doctor '], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test['phrase_preprocessed'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in list(x_train) + list(x_valid) + list(x_test):\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28307\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = { \"EAP\": 0, \"HPL\": 1, \"MWS\": 2 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28307, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saw lord raymond on his charger small company of officers had gathered about him and behind was promiscuous concourse of soldiers and subalterns their discipline lost their arms thrown aside no music sounded no banners streamed ',\n",
       "  'MWS'),\n",
       " ('its shrill loathsome tittering stuck more and more in gilman s head and he could remember in the morning how it had pronounced the words azathoth and nyarlathotep ',\n",
       "  'HPL'),\n",
       " ('the lady whom was much astonished to hear addressed as madame joyeuse after the description of madame joyeuse she had just given blushed up to the eyebrows and seemed exceedingly abashed at the reproof ',\n",
       "  'EAP'),\n",
       " ('but everteeming nature will create another and another and thou wilt loose nought by my destruction ',\n",
       "  'MWS'),\n",
       " ('for that the man always watched and listened no one could doubt ', 'HPL')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=list(zip(x_train,y_train))\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('need not go into details ', 'EAP'),\n",
       " ('but wish to call your attention to the distinction which is made between drowned bodies and bodies thrown into the water immediately after death by violence ',\n",
       "  'EAP'),\n",
       " (' do not catechise me lionel will do my duty by her be assured ', 'MWS'),\n",
       " ('have indeed no abhorrence of danger except in its absolute effect in terror ',\n",
       "  'EAP'),\n",
       " ('it echoed and echoed through the dim vaultings of that ancient and nitrous cellar and had to choke back flood of reaction that threatened to burst out as hysterical laughter ',\n",
       "  'HPL')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data=list(zip(x_valid,y_valid))\n",
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq.split()]\n",
    "    tensor = torch.cuda.LongTensor(idxs)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_idx):\n",
    "    return torch.cuda.LongTensor([label_to_idx[label]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model - LSTM Classifier with Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.42B.300d.txt  GoogleNews-vectors-negative300.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../vectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = '../../vectors/glove.42B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 1917494  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_vector = loadGloveModel(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3013  ,  0.49315 , -0.47456 , -0.55259 , -0.079275, -0.069589,\n",
       "       -3.5792  ,  0.28671 , -0.034099, -0.23643 , -0.042276,  0.25939 ,\n",
       "       -0.080374, -0.25137 ,  0.22347 ,  0.22123 ,  0.077188,  0.41157 ,\n",
       "       -0.1154  , -0.065081, -0.1549  , -0.08466 ,  0.078873, -0.109   ,\n",
       "       -0.018008,  0.2591  ,  0.09544 , -0.33333 , -0.24942 , -0.29616 ,\n",
       "       -0.60454 , -0.11145 ,  0.21661 , -0.17045 ,  0.2329  ,  0.24699 ,\n",
       "       -0.37996 , -0.035888, -0.035235,  0.14275 , -0.13491 ,  0.018954,\n",
       "        0.35121 , -0.34182 ,  0.041529, -0.48883 ,  0.29649 ,  0.25711 ,\n",
       "        0.21757 , -0.04452 ,  0.49266 ,  0.30706 , -0.30375 ,  0.12427 ,\n",
       "       -0.090547,  0.055427, -0.357   ,  0.049935, -0.12842 ,  0.037939,\n",
       "        0.20706 ,  0.24645 ,  0.45067 ,  0.26154 , -0.39262 ,  0.10625 ,\n",
       "       -0.090539,  0.13802 ,  0.088777, -0.4219  , -0.14283 ,  0.053959,\n",
       "       -0.40817 , -0.13262 , -0.44289 ,  0.046249,  0.53221 ,  0.030767,\n",
       "        0.06197 , -0.18862 , -0.28016 ,  0.09877 ,  0.064807,  0.10248 ,\n",
       "        0.28618 ,  0.47056 ,  0.40463 , -0.1651  , -0.086233,  0.17781 ,\n",
       "       -0.28773 , -0.10748 ,  0.18487 , -0.054304,  0.21486 , -0.43958 ,\n",
       "       -1.9126  ,  0.27618 ,  0.60843 ,  0.38416 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vector['start'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v = KeyedVectors.load_word2vec_format('../../vectors/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_DIM = 300\n",
    "## standard deviation to use\n",
    "sd = 1/np.sqrt(W2V_DIM)\n",
    "## Random initialization\n",
    "weights = np.random.normal(0, scale=sd, size=[VOCAB_SIZE, W2V_DIM])\n",
    "weights = weights.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_to_ix:\n",
    "    id = word_to_ix.get(word,None)\n",
    "    if id is not None:\n",
    "        try:\n",
    "            #weights[id]=w2v.wv.word_vec(word)\n",
    "            weights[id]=glove_vector[word]\n",
    "        except:\n",
    "            weights[id]=np.random.normal(0, scale=sd, size=[1, W2V_DIM]) ## If word not present, initialize randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'saw': 0,\n",
       " 'lord': 1,\n",
       " 'raymond': 2,\n",
       " 'on': 3,\n",
       " 'his': 4,\n",
       " 'charger': 5,\n",
       " 'small': 6,\n",
       " 'company': 7,\n",
       " 'of': 8,\n",
       " 'officers': 9,\n",
       " 'had': 10,\n",
       " 'gathered': 11,\n",
       " 'about': 12,\n",
       " 'him': 13,\n",
       " 'and': 14,\n",
       " 'behind': 15,\n",
       " 'was': 16,\n",
       " 'promiscuous': 17,\n",
       " 'concourse': 18,\n",
       " 'soldiers': 19,\n",
       " 'subalterns': 20,\n",
       " 'their': 21,\n",
       " 'discipline': 22,\n",
       " 'lost': 23,\n",
       " 'arms': 24,\n",
       " 'thrown': 25,\n",
       " 'aside': 26,\n",
       " 'no': 27,\n",
       " 'music': 28,\n",
       " 'sounded': 29,\n",
       " 'banners': 30,\n",
       " 'streamed': 31,\n",
       " 'its': 32,\n",
       " 'shrill': 33,\n",
       " 'loathsome': 34,\n",
       " 'tittering': 35,\n",
       " 'stuck': 36,\n",
       " 'more': 37,\n",
       " 'in': 38,\n",
       " 'gilman': 39,\n",
       " 's': 40,\n",
       " 'head': 41,\n",
       " 'he': 42,\n",
       " 'could': 43,\n",
       " 'remember': 44,\n",
       " 'the': 45,\n",
       " 'morning': 46,\n",
       " 'how': 47,\n",
       " 'it': 48,\n",
       " 'pronounced': 49,\n",
       " 'words': 50,\n",
       " 'azathoth': 51,\n",
       " 'nyarlathotep': 52,\n",
       " 'lady': 53,\n",
       " 'whom': 54,\n",
       " 'much': 55,\n",
       " 'astonished': 56,\n",
       " 'to': 57,\n",
       " 'hear': 58,\n",
       " 'addressed': 59,\n",
       " 'as': 60,\n",
       " 'madame': 61,\n",
       " 'joyeuse': 62,\n",
       " 'after': 63,\n",
       " 'description': 64,\n",
       " 'she': 65,\n",
       " 'just': 66,\n",
       " 'given': 67,\n",
       " 'blushed': 68,\n",
       " 'up': 69,\n",
       " 'eyebrows': 70,\n",
       " 'seemed': 71,\n",
       " 'exceedingly': 72,\n",
       " 'abashed': 73,\n",
       " 'at': 74,\n",
       " 'reproof': 75,\n",
       " 'but': 76,\n",
       " 'everteeming': 77,\n",
       " 'nature': 78,\n",
       " 'will': 79,\n",
       " 'create': 80,\n",
       " 'another': 81,\n",
       " 'thou': 82,\n",
       " 'wilt': 83,\n",
       " 'loose': 84,\n",
       " 'nought': 85,\n",
       " 'by': 86,\n",
       " 'my': 87,\n",
       " 'destruction': 88,\n",
       " 'for': 89,\n",
       " 'that': 90,\n",
       " 'man': 91,\n",
       " 'always': 92,\n",
       " 'watched': 93,\n",
       " 'listened': 94,\n",
       " 'one': 95,\n",
       " 'doubt': 96,\n",
       " 'meanwhile': 97,\n",
       " 'would': 98,\n",
       " 'try': 99,\n",
       " 'keep': 100,\n",
       " 'track': 101,\n",
       " 'somnambulism': 102,\n",
       " 'already': 103,\n",
       " 'been': 104,\n",
       " 'out': 105,\n",
       " 'many': 106,\n",
       " 'hours': 107,\n",
       " 'felt': 108,\n",
       " 'torment': 109,\n",
       " 'burning': 110,\n",
       " 'thirst': 111,\n",
       " 'prelude': 112,\n",
       " 'other': 113,\n",
       " 'sufferings': 114,\n",
       " 'moved': 115,\n",
       " 'hand': 116,\n",
       " 'whose': 117,\n",
       " 'mechanical': 118,\n",
       " 'nodding': 119,\n",
       " 'able': 120,\n",
       " 'stop': 121,\n",
       " 'shouted': 122,\n",
       " 'ear': 123,\n",
       " 'we': 124,\n",
       " 'must': 125,\n",
       " 'both': 126,\n",
       " 'flee': 127,\n",
       " 'from': 128,\n",
       " 'unknown': 129,\n",
       " 'things': 130,\n",
       " 'night': 131,\n",
       " 'when': 132,\n",
       " 'they': 133,\n",
       " 'gone': 134,\n",
       " 'spoke': 135,\n",
       " 'freely': 136,\n",
       " 'with': 137,\n",
       " 'm': 138,\n",
       " 'valdemar': 139,\n",
       " 'subject': 140,\n",
       " 'approaching': 141,\n",
       " 'dissolution': 142,\n",
       " 'well': 143,\n",
       " 'particularly': 144,\n",
       " 'experiment': 145,\n",
       " 'proposed': 146,\n",
       " 'twilight': 147,\n",
       " 'stars': 148,\n",
       " 'came': 149,\n",
       " 'moon': 150,\n",
       " 'cast': 151,\n",
       " 'marsh': 152,\n",
       " 'radiance': 153,\n",
       " 'like': 154,\n",
       " 'which': 155,\n",
       " 'child': 156,\n",
       " 'sees': 157,\n",
       " 'quivering': 158,\n",
       " 'floor': 159,\n",
       " 'is': 160,\n",
       " 'rocked': 161,\n",
       " 'sleep': 162,\n",
       " 'evening': 163,\n",
       " 'there': 164,\n",
       " 'walked': 165,\n",
       " 'into': 166,\n",
       " 'lethal': 167,\n",
       " 'quicksands': 168,\n",
       " 'very': 169,\n",
       " 'old': 170,\n",
       " 'tattered': 171,\n",
       " 'purple': 172,\n",
       " 'crowned': 173,\n",
       " 'withered': 174,\n",
       " 'vine': 175,\n",
       " 'leaves': 176,\n",
       " 'gazing': 177,\n",
       " 'ahead': 178,\n",
       " 'if': 179,\n",
       " 'upon': 180,\n",
       " 'golden': 181,\n",
       " 'domes': 182,\n",
       " 'fair': 183,\n",
       " 'city': 184,\n",
       " 'where': 185,\n",
       " 'dreams': 186,\n",
       " 'are': 187,\n",
       " 'understood': 188,\n",
       " 'besides': 189,\n",
       " 'estates': 190,\n",
       " 'were': 191,\n",
       " 'contiguous': 192,\n",
       " 'long': 193,\n",
       " 'exercised': 194,\n",
       " 'rival': 195,\n",
       " 'influence': 196,\n",
       " 'affairs': 197,\n",
       " 'busy': 198,\n",
       " 'government': 199,\n",
       " 'now': 200,\n",
       " 'noon': 201,\n",
       " 'or': 202,\n",
       " 'thereabouts': 203,\n",
       " 'shall': 204,\n",
       " 'have': 205,\n",
       " 'time': 206,\n",
       " 'enough': 207,\n",
       " 'get': 208,\n",
       " 'through': 209,\n",
       " 'them': 210,\n",
       " 'all': 211,\n",
       " 'before': 212,\n",
       " 'midnight': 213,\n",
       " 'president': 214,\n",
       " 'however': 215,\n",
       " 'first': 216,\n",
       " 'recover': 217,\n",
       " 'composure': 218,\n",
       " 'length': 219,\n",
       " 'turning': 220,\n",
       " 'legs': 221,\n",
       " 'great': 222,\n",
       " 'dignity': 223,\n",
       " 'recommenced': 224,\n",
       " 'most': 225,\n",
       " 'willingly': 226,\n",
       " 'gratify': 227,\n",
       " 'any': 228,\n",
       " 'reasonable': 229,\n",
       " 'curiosity': 230,\n",
       " 'part': 231,\n",
       " 'guests': 232,\n",
       " 'so': 233,\n",
       " 'illustrious': 234,\n",
       " 'unbidden': 235,\n",
       " 'though': 236,\n",
       " 'be': 237,\n",
       " 'finally': 238,\n",
       " 'concluded': 239,\n",
       " 'senses': 240,\n",
       " 'impressed': 241,\n",
       " 'certain': 242,\n",
       " 'air': 243,\n",
       " 'gravity': 244,\n",
       " 'sadness': 245,\n",
       " 'still': 246,\n",
       " 'properly': 247,\n",
       " 'weariness': 248,\n",
       " 'took': 249,\n",
       " 'something': 250,\n",
       " 'youth': 251,\n",
       " 'freshness': 252,\n",
       " 'countenance': 253,\n",
       " 'only': 254,\n",
       " 'endow': 255,\n",
       " 'seraphic': 256,\n",
       " 'tenderness': 257,\n",
       " 'majesty': 258,\n",
       " 'thus': 259,\n",
       " 'course': 260,\n",
       " 'enthusiastic': 261,\n",
       " 'romantic': 262,\n",
       " 'temperment': 263,\n",
       " 'an': 264,\n",
       " 'interest': 265,\n",
       " 'tenfold': 266,\n",
       " 'windows': 267,\n",
       " 'room': 268,\n",
       " 'darkened': 269,\n",
       " 'kind': 270,\n",
       " 'panic': 271,\n",
       " 'seeing': 272,\n",
       " 'pale': 273,\n",
       " 'yellow': 274,\n",
       " 'light': 275,\n",
       " 'illuminate': 276,\n",
       " 'chamber': 277,\n",
       " 'bruises': 278,\n",
       " 'body': 279,\n",
       " 'l': 280,\n",
       " 'espanaye': 281,\n",
       " 'do': 282,\n",
       " 'not': 283,\n",
       " 'speak': 284,\n",
       " 'contemplated': 285,\n",
       " 'lake': 286,\n",
       " 'waters': 287,\n",
       " 'placid': 288,\n",
       " 'around': 289,\n",
       " 'calm': 290,\n",
       " 'snowy': 291,\n",
       " 'mountains': 292,\n",
       " 'palaces': 293,\n",
       " 'changed': 294,\n",
       " 'such': 295,\n",
       " 'strange': 296,\n",
       " 'incredible': 297,\n",
       " 'events': 298,\n",
       " 'brought': 299,\n",
       " 'union': 300,\n",
       " 'sister': 301,\n",
       " 'best': 302,\n",
       " 'friend': 303,\n",
       " 'adored': 304,\n",
       " 'idris': 305,\n",
       " 'damp': 306,\n",
       " 'low': 307,\n",
       " 'ceiled': 308,\n",
       " 'library': 309,\n",
       " 'musty': 310,\n",
       " 'white': 311,\n",
       " 'panelling': 312,\n",
       " 'heavy': 313,\n",
       " 'carved': 314,\n",
       " 'overmantel': 315,\n",
       " 'paned': 316,\n",
       " 'shaded': 317,\n",
       " 'relics': 318,\n",
       " 'records': 319,\n",
       " 'ancient': 320,\n",
       " 'family': 321,\n",
       " 'among': 322,\n",
       " 'dubious': 323,\n",
       " 'allusions': 324,\n",
       " 'shunned': 325,\n",
       " 'house': 326,\n",
       " 'benefit': 327,\n",
       " 'street': 328,\n",
       " 'think': 329,\n",
       " 'professor': 330,\n",
       " 'angell': 331,\n",
       " 'died': 332,\n",
       " 'because': 333,\n",
       " 'knew': 334,\n",
       " 'too': 335,\n",
       " 'likely': 336,\n",
       " 'learn': 337,\n",
       " 'this': 338,\n",
       " 'topic': 339,\n",
       " 'smith': 340,\n",
       " 'personal': 341,\n",
       " 'appearance': 342,\n",
       " 'melancholy': 343,\n",
       " 'satisfaction': 344,\n",
       " 'being': 345,\n",
       " 'minute': 346,\n",
       " 'seen': 347,\n",
       " 'even': 348,\n",
       " 'three': 349,\n",
       " 'per': 350,\n",
       " 'cent': 351,\n",
       " 'annual': 352,\n",
       " 'income': 353,\n",
       " 'inheritance': 354,\n",
       " 'amounted': 355,\n",
       " 'less': 356,\n",
       " 'than': 357,\n",
       " 'thirteen': 358,\n",
       " 'millions': 359,\n",
       " 'five': 360,\n",
       " 'hundred': 361,\n",
       " 'thousand': 362,\n",
       " 'dollars': 363,\n",
       " 'million': 364,\n",
       " 'twenty': 365,\n",
       " 'month': 366,\n",
       " 'thirty': 367,\n",
       " 'six': 368,\n",
       " 'nine': 369,\n",
       " 'eighty': 370,\n",
       " 'day': 371,\n",
       " 'forty': 372,\n",
       " 'hour': 373,\n",
       " 'every': 374,\n",
       " 'flew': 375,\n",
       " 'paint': 376,\n",
       " 'cellar': 377,\n",
       " 'inspiration': 378,\n",
       " 'thickest': 379,\n",
       " 'i': 380,\n",
       " 've': 381,\n",
       " 'rooms': 382,\n",
       " 'furnished': 383,\n",
       " 'ground': 384,\n",
       " 'resolved': 385,\n",
       " 'accompany': 386,\n",
       " 'perdita': 387,\n",
       " 'last': 388,\n",
       " 'figure': 389,\n",
       " 'rumbling': 390,\n",
       " 'voice': 391,\n",
       " 'chilled': 392,\n",
       " 'me': 393,\n",
       " 'dull': 394,\n",
       " 'hollowness': 395,\n",
       " 'latent': 396,\n",
       " 'malevolence': 397,\n",
       " 'address': 398,\n",
       " 'caused': 399,\n",
       " 'considerable': 400,\n",
       " 'change': 401,\n",
       " 'physiognomy': 402,\n",
       " 'own': 403,\n",
       " 'auditor': 404,\n",
       " 'emotions': 405,\n",
       " 'benevolence': 406,\n",
       " 'towards': 407,\n",
       " 'should': 408,\n",
       " 'return': 409,\n",
       " 'hundredfold': 410,\n",
       " 'creature': 411,\n",
       " 'sake': 412,\n",
       " 'make': 413,\n",
       " 'peace': 414,\n",
       " 'whole': 415,\n",
       " 'indulge': 416,\n",
       " 'bliss': 417,\n",
       " 'cannot': 418,\n",
       " 'realized': 419,\n",
       " 'shivered': 420,\n",
       " 'read': 421,\n",
       " 'scroll': 422,\n",
       " 'carter': 423,\n",
       " 'reflection': 424,\n",
       " 'thawed': 425,\n",
       " 'congealing': 426,\n",
       " 'blood': 427,\n",
       " 'again': 428,\n",
       " 'tide': 429,\n",
       " 'life': 430,\n",
       " 'love': 431,\n",
       " 'flowed': 432,\n",
       " 'impetuously': 433,\n",
       " 'onward': 434,\n",
       " 'ebb': 435,\n",
       " 'thoughts': 436,\n",
       " 'deep': 437,\n",
       " 'sense': 438,\n",
       " 'joy': 439,\n",
       " 'although': 440,\n",
       " 'airs': 441,\n",
       " 'blew': 442,\n",
       " 'heavens': 443,\n",
       " 'yet': 444,\n",
       " 'thing': 445,\n",
       " 'motion': 446,\n",
       " 'gentle': 447,\n",
       " 'sweepings': 448,\n",
       " 'fro': 449,\n",
       " 'innumerable': 450,\n",
       " 'butterflies': 451,\n",
       " 'might': 452,\n",
       " 'mistaken': 453,\n",
       " 'tulips': 454,\n",
       " 'wings': 455,\n",
       " 'determined': 456,\n",
       " 'fancy': 457,\n",
       " 'conjured': 458,\n",
       " 'miserable': 459,\n",
       " 'abode': 460,\n",
       " 'greek': 461,\n",
       " 'girl': 462,\n",
       " 'foreigners': 463,\n",
       " 'credulous': 464,\n",
       " 'grandmothers': 465,\n",
       " 'equally': 466,\n",
       " 'garrulous': 467,\n",
       " 'modern': 468,\n",
       " 'nickel': 469,\n",
       " 'crucifix': 470,\n",
       " 'broken': 471,\n",
       " 'chain': 472,\n",
       " 'mixed': 473,\n",
       " 'rubbish': 474,\n",
       " 'shiveringly': 475,\n",
       " 'identified': 476,\n",
       " 'joe': 477,\n",
       " 'mazurewicz': 478,\n",
       " 'poor': 479,\n",
       " 'years': 480,\n",
       " 'others': 481,\n",
       " 'll': 482,\n",
       " 'worship': 483,\n",
       " 'us': 484,\n",
       " 'meetin': 485,\n",
       " 'sarten': 486,\n",
       " 'haouses': 487,\n",
       " 'hez': 488,\n",
       " 'got': 489,\n",
       " 'entertain': 490,\n",
       " 'spoken': 491,\n",
       " 'two': 492,\n",
       " 'openings': 493,\n",
       " 'vale': 494,\n",
       " 'same': 495,\n",
       " 'period': 496,\n",
       " 'aright': 497,\n",
       " 'altercation': 498,\n",
       " 'violence': 499,\n",
       " 'usually': 500,\n",
       " 'off': 501,\n",
       " 'guard': 502,\n",
       " 'acted': 503,\n",
       " 'openness': 504,\n",
       " 'demeanor': 505,\n",
       " 'rather': 506,\n",
       " 'foreign': 507,\n",
       " 'discovered': 508,\n",
       " 'fancied': 509,\n",
       " 'accent': 510,\n",
       " 'general': 511,\n",
       " 'startled': 512,\n",
       " 'then': 513,\n",
       " 'deeply': 514,\n",
       " 'interested': 515,\n",
       " 'bringing': 516,\n",
       " 'mind': 517,\n",
       " 'dim': 518,\n",
       " 'visions': 519,\n",
       " 'earliest': 520,\n",
       " 'infancy': 521,\n",
       " 'wild': 522,\n",
       " 'confused': 523,\n",
       " 'thronging': 524,\n",
       " 'memories': 525,\n",
       " 'memory': 526,\n",
       " 'herself': 527,\n",
       " 'unborn': 528,\n",
       " 'scenery': 529,\n",
       " 'presented': 530,\n",
       " 'itself': 531,\n",
       " 'sides': 532,\n",
       " 'scarcely': 533,\n",
       " 'entitled': 534,\n",
       " 'called': 535,\n",
       " 'grand': 536,\n",
       " 'indescribable': 537,\n",
       " 'delicious': 538,\n",
       " 'aspect': 539,\n",
       " 'dreary': 540,\n",
       " 'desolation': 541,\n",
       " 'fool': 542,\n",
       " 'beyond': 543,\n",
       " 'interposed': 544,\n",
       " 'some': 545,\n",
       " 'compared': 546,\n",
       " 'individual': 547,\n",
       " 'know': 548,\n",
       " 'exception': 549,\n",
       " 'gentleman': 550,\n",
       " 'somehow': 551,\n",
       " 'taken': 552,\n",
       " 'granted': 553,\n",
       " 'abandoned': 554,\n",
       " 'approached': 555,\n",
       " 'sure': 556,\n",
       " 'walks': 557,\n",
       " 'indeed': 558,\n",
       " 'overgrown': 559,\n",
       " 'weeds': 560,\n",
       " 'retain': 561,\n",
       " 'little': 562,\n",
       " 'argue': 563,\n",
       " 'complete': 564,\n",
       " 'desertion': 565,\n",
       " 'immediate': 566,\n",
       " 'actions': 567,\n",
       " 'peculiar': 568,\n",
       " 'situation': 569,\n",
       " 'tales': 570,\n",
       " 'does': 571,\n",
       " 'dramatic': 572,\n",
       " 'foreseen': 573,\n",
       " 'frantic': 574,\n",
       " 'ascent': 575,\n",
       " 'slope': 576,\n",
       " 'cliff': 577,\n",
       " 'delirious': 578,\n",
       " 'journey': 579,\n",
       " 'back': 580,\n",
       " 'stranded': 581,\n",
       " 'boat': 582,\n",
       " 'accessory': 583,\n",
       " 'points': 584,\n",
       " 'design': 585,\n",
       " 'served': 586,\n",
       " 'convey': 587,\n",
       " 'idea': 588,\n",
       " 'excavation': 589,\n",
       " 'lay': 590,\n",
       " 'exceeding': 591,\n",
       " 'depth': 592,\n",
       " 'below': 593,\n",
       " 'surface': 594,\n",
       " 'earth': 595,\n",
       " 'greeks': 596,\n",
       " 'wept': 597,\n",
       " 'beheld': 598,\n",
       " 'mediterranean': 599,\n",
       " 'hills': 600,\n",
       " 'asia': 601,\n",
       " 'hailed': 602,\n",
       " 'rapture': 603,\n",
       " 'boundary': 604,\n",
       " 'toils': 605,\n",
       " 'beholds': 606,\n",
       " 'has': 607,\n",
       " 'injured': 608,\n",
       " 'unto': 609,\n",
       " 'death': 610,\n",
       " 'derive': 611,\n",
       " 'hope': 612,\n",
       " 'kindness': 613,\n",
       " 'can': 614,\n",
       " 'possibly': 615,\n",
       " 'intentions': 616,\n",
       " 'young': 617,\n",
       " 'people': 618,\n",
       " 'etonians': 619,\n",
       " 'children': 620,\n",
       " 'neighbouring': 621,\n",
       " 'gentry': 622,\n",
       " 'held': 623,\n",
       " 'mock': 624,\n",
       " 'country': 625,\n",
       " 'invited': 626,\n",
       " 'you': 627,\n",
       " 'world': 628,\n",
       " 'am': 629,\n",
       " 'dutchman': 630,\n",
       " 'maintains': 631,\n",
       " 'frenchman': 632,\n",
       " 'find': 633,\n",
       " 'stated': 634,\n",
       " 'understanding': 635,\n",
       " 'french': 636,\n",
       " 'witness': 637,\n",
       " 'examined': 638,\n",
       " 'interpreter': 639,\n",
       " 'shed': 640,\n",
       " 'tears': 641,\n",
       " 'task': 642,\n",
       " 'almost': 643,\n",
       " 'fulfilled': 644,\n",
       " 'rewarded': 645,\n",
       " 'burthensome': 646,\n",
       " 'suffering': 647,\n",
       " 'hard': 648,\n",
       " 'who': 649,\n",
       " 'once': 650,\n",
       " 'happy': 651,\n",
       " 'sic': 652,\n",
       " 'voluntarily': 653,\n",
       " 'divest': 654,\n",
       " 'themselves': 655,\n",
       " 'sensation': 656,\n",
       " 'go': 657,\n",
       " 'alone': 658,\n",
       " 'grave': 659,\n",
       " 'dare': 660,\n",
       " 'traces': 661,\n",
       " 'land': 662,\n",
       " 'water': 663,\n",
       " 'clouded': 664,\n",
       " 'variable': 665,\n",
       " 'spots': 666,\n",
       " 'belted': 667,\n",
       " 'tropical': 668,\n",
       " 'equatorial': 669,\n",
       " 'zones': 670,\n",
       " 'may': 671,\n",
       " 'state': 672,\n",
       " 'system': 673,\n",
       " 'terms': 674,\n",
       " 'patients': 675,\n",
       " 'menages': 676,\n",
       " 'humored': 677,\n",
       " 'true': 678,\n",
       " 'object': 679,\n",
       " 'admit': 680,\n",
       " 'arm': 681,\n",
       " 'attendant': 682,\n",
       " 'adjust': 683,\n",
       " 'necessary': 684,\n",
       " 'hands': 685,\n",
       " 'clock': 686,\n",
       " 'within': 687,\n",
       " 'having': 688,\n",
       " 'fathomed': 689,\n",
       " 'jehovah': 690,\n",
       " 'these': 691,\n",
       " 'built': 692,\n",
       " 'systems': 693,\n",
       " 'remote': 694,\n",
       " 'ancestors': 695,\n",
       " 'superfluous': 696,\n",
       " 'say': 697,\n",
       " 'recall': 698,\n",
       " 'scene': 699,\n",
       " 'final': 700,\n",
       " 'moments': 701,\n",
       " 'autumnal': 702,\n",
       " 'over': 703,\n",
       " 'graves': 704,\n",
       " 'casting': 705,\n",
       " 'horrible': 706,\n",
       " 'shadows': 707,\n",
       " 'grotesque': 708,\n",
       " 'trees': 709,\n",
       " 'drooping': 710,\n",
       " 'sullenly': 711,\n",
       " 'meet': 712,\n",
       " 'neglected': 713,\n",
       " 'grass': 714,\n",
       " 'crumbling': 715,\n",
       " 'slabs': 716,\n",
       " 'vast': 717,\n",
       " 'legions': 718,\n",
       " 'strangely': 719,\n",
       " 'colossal': 720,\n",
       " 'bats': 721,\n",
       " 'against': 722,\n",
       " 'antique': 723,\n",
       " 'ivied': 724,\n",
       " 'church': 725,\n",
       " 'pointing': 726,\n",
       " 'huge': 727,\n",
       " 'spectral': 728,\n",
       " 'finger': 729,\n",
       " 'livid': 730,\n",
       " 'sky': 731,\n",
       " 'phosphorescent': 732,\n",
       " 'insects': 733,\n",
       " 'danced': 734,\n",
       " 'fires': 735,\n",
       " 'under': 736,\n",
       " 'yews': 737,\n",
       " 'distant': 738,\n",
       " 'corner': 739,\n",
       " 'odours': 740,\n",
       " 'mould': 741,\n",
       " 'vegetation': 742,\n",
       " 'explicable': 743,\n",
       " 'mingled': 744,\n",
       " 'feebly': 745,\n",
       " 'wind': 746,\n",
       " 'far': 747,\n",
       " 'swamps': 748,\n",
       " 'seas': 749,\n",
       " 'worst': 750,\n",
       " 'faint': 751,\n",
       " 'toned': 752,\n",
       " 'baying': 753,\n",
       " 'gigantic': 754,\n",
       " 'hound': 755,\n",
       " 'neither': 756,\n",
       " 'see': 757,\n",
       " 'nor': 758,\n",
       " 'definitely': 759,\n",
       " 'place': 760,\n",
       " 'passage': 761,\n",
       " 'face': 762,\n",
       " 'distorted': 763,\n",
       " 'epileptic': 764,\n",
       " 'reverberant': 765,\n",
       " 'laughter': 766,\n",
       " 'thought': 767,\n",
       " 'heard': 768,\n",
       " 'fiendish': 769,\n",
       " 'echoes': 770,\n",
       " 'curious': 771,\n",
       " 'feeling': 772,\n",
       " 'unreality': 773,\n",
       " 'attached': 774,\n",
       " 'comparison': 775,\n",
       " 'close': 776,\n",
       " 'home': 777,\n",
       " 'lies': 778,\n",
       " 'singular': 779,\n",
       " 'wooded': 780,\n",
       " 'hollow': 781,\n",
       " 'deeps': 782,\n",
       " 'spent': 783,\n",
       " 'reading': 784,\n",
       " 'thinking': 785,\n",
       " 'dreaming': 786,\n",
       " 'tranquillity': 787,\n",
       " 'remarkable': 788,\n",
       " 'amongst': 789,\n",
       " 'gentlemen': 790,\n",
       " 'opposed': 791,\n",
       " 'opinions': 792,\n",
       " 'lived': 793,\n",
       " 'retired': 794,\n",
       " 'reputed': 795,\n",
       " 'money': 796,\n",
       " 'everywhere': 797,\n",
       " 'irrevocably': 798,\n",
       " 'excluded': 799,\n",
       " 'glance': 800,\n",
       " 'what': 801,\n",
       " 'triumphantly': 802,\n",
       " 'adduced': 803,\n",
       " 'support': 804,\n",
       " 'articles': 805,\n",
       " 'least': 806,\n",
       " 'four': 807,\n",
       " 'weeks': 808,\n",
       " 'thicket': 809,\n",
       " 'absurdly': 810,\n",
       " 'null': 811,\n",
       " 'regards': 812,\n",
       " 'evidence': 813,\n",
       " 'fact': 814,\n",
       " 'matter': 815,\n",
       " 'consequence': 816,\n",
       " 'window': 817,\n",
       " 'top': 818,\n",
       " 'balloon': 819,\n",
       " 'prevented': 820,\n",
       " 'making': 821,\n",
       " 'use': 822,\n",
       " 'gazed': 823,\n",
       " 'slept': 824,\n",
       " 'melted': 825,\n",
       " 'filled': 826,\n",
       " 'possessed': 827,\n",
       " 'cradled': 828,\n",
       " 'those': 829,\n",
       " 'idolized': 830,\n",
       " 'mortal': 831,\n",
       " 'lineaments': 832,\n",
       " 'entering': 833,\n",
       " 'cut': 834,\n",
       " 'glanced': 835,\n",
       " 'pursuer': 836,\n",
       " 'honor': 837,\n",
       " 'concerned': 838,\n",
       " 'green': 839,\n",
       " 'tombs': 840,\n",
       " 'theirs': 841,\n",
       " 'buds': 842,\n",
       " 'decked': 843,\n",
       " 'flowers': 844,\n",
       " 'adorned': 845,\n",
       " 'dark': 846,\n",
       " 'branches': 847,\n",
       " 'swollen': 848,\n",
       " 'seasonable': 849,\n",
       " 'juices': 850,\n",
       " 'expanded': 851,\n",
       " 'variegated': 852,\n",
       " 'foliage': 853,\n",
       " 'spring': 854,\n",
       " 'bending': 855,\n",
       " 'singing': 856,\n",
       " 'breeze': 857,\n",
       " 'rejoiced': 858,\n",
       " 'genial': 859,\n",
       " 'warmth': 860,\n",
       " 'unclouded': 861,\n",
       " 'empyrean': 862,\n",
       " 'brooks': 863,\n",
       " 'murmuring': 864,\n",
       " 'sea': 865,\n",
       " 'waveless': 866,\n",
       " 'promontories': 867,\n",
       " 'hung': 868,\n",
       " 'reflected': 869,\n",
       " 'birds': 870,\n",
       " 'awoke': 871,\n",
       " 'woods': 872,\n",
       " 'while': 873,\n",
       " 'abundant': 874,\n",
       " 'food': 875,\n",
       " 'beast': 876,\n",
       " 'sprung': 877,\n",
       " 'opinion': 878,\n",
       " 'dumas': 879,\n",
       " 'mademoiselle': 880,\n",
       " 'throttled': 881,\n",
       " 'person': 882,\n",
       " 'persons': 883,\n",
       " 'shepherd': 884,\n",
       " 'boy': 885,\n",
       " 'tends': 886,\n",
       " 'silly': 887,\n",
       " 'flock': 888,\n",
       " 'scale': 889,\n",
       " 'society': 890,\n",
       " 'congratulate': 891,\n",
       " 'found': 892,\n",
       " 'fitting': 893,\n",
       " 'scope': 894,\n",
       " 'powers': 895,\n",
       " 'grown': 896,\n",
       " 'large': 897,\n",
       " 'fluent': 898,\n",
       " 'incredibly': 899,\n",
       " 'intelligent': 900,\n",
       " 'talker': 901,\n",
       " 'your': 902,\n",
       " 'diddler': 903,\n",
       " 'guided': 904,\n",
       " 'self': 905,\n",
       " 'point': 906,\n",
       " 'view': 907,\n",
       " 'valley': 908,\n",
       " 'altogether': 909,\n",
       " 'nearly': 910,\n",
       " 'survey': 911,\n",
       " 'haow': 912,\n",
       " 'd': 913,\n",
       " 'ye': 914,\n",
       " 'livin': 915,\n",
       " 'taown': 916,\n",
       " 'everything': 917,\n",
       " 'rottin': 918,\n",
       " 'dyin': 919,\n",
       " 'boarded': 920,\n",
       " 'monsters': 921,\n",
       " 'crawlin': 922,\n",
       " 'bleatin': 923,\n",
       " 'barkin': 924,\n",
       " 'hoppin': 925,\n",
       " 'araoun': 926,\n",
       " 'black': 927,\n",
       " 'cellars': 928,\n",
       " 'attics': 929,\n",
       " 'way': 930,\n",
       " 'turn': 931,\n",
       " 'right': 932,\n",
       " 'clenched': 933,\n",
       " 'left': 934,\n",
       " 'partially': 935,\n",
       " 'open': 936,\n",
       " 'devoutly': 937,\n",
       " 'loved': 938,\n",
       " 'bend': 939,\n",
       " 'her': 940,\n",
       " 'glossy': 941,\n",
       " 'ringlets': 942,\n",
       " 'form': 943,\n",
       " 'subjects': 944,\n",
       " 'admiration': 945,\n",
       " 'melodious': 946,\n",
       " 'tones': 947,\n",
       " 'entered': 948,\n",
       " 'soul': 949,\n",
       " 'soon': 950,\n",
       " 'softened': 951,\n",
       " 'comforting': 952,\n",
       " 'caressing': 953,\n",
       " 'endeavouring': 954,\n",
       " 'cheat': 955,\n",
       " 'himself': 956,\n",
       " 'belief': 957,\n",
       " 'never': 958,\n",
       " 'wronged': 959,\n",
       " 'attired': 960,\n",
       " 'expected': 961,\n",
       " 'costume': 962,\n",
       " 'similar': 963,\n",
       " 'wearing': 964,\n",
       " 'spanish': 965,\n",
       " 'cloak': 966,\n",
       " 'blue': 967,\n",
       " 'velvet': 968,\n",
       " 'begirt': 969,\n",
       " 'waist': 970,\n",
       " 'crimson': 971,\n",
       " 'belt': 972,\n",
       " 'sustaining': 973,\n",
       " 'rapier': 974,\n",
       " 'species': 975,\n",
       " 'telegraph': 976,\n",
       " 'put': 977,\n",
       " 'operation': 978,\n",
       " 'horse': 979,\n",
       " 'considered': 980,\n",
       " 'quite': 981,\n",
       " 'impossible': 982,\n",
       " 'wires': 983,\n",
       " 'loss': 984,\n",
       " 'comprehend': 985,\n",
       " 'difficulty': 986,\n",
       " 'wags': 987,\n",
       " 'smell': 988,\n",
       " 'awful': 989,\n",
       " 'araound': 990,\n",
       " 'wizard': 991,\n",
       " 'whateley': 992,\n",
       " 'ol': 993,\n",
       " 'haouse': 994,\n",
       " 'shub': 995,\n",
       " 'niggurath': 996,\n",
       " 'foulness': 997,\n",
       " 'selecting': 998,\n",
       " 'hill': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.27130000e-01,   1.34660000e-01,  -3.49210000e-01,\n",
       "         4.81920000e-01,  -4.93770000e-01,  -3.87940000e-02,\n",
       "        -1.36500000e+00,  -6.52720000e-02,  -2.83830000e-01,\n",
       "        -5.63370000e-01,  -2.60910000e-01,  -2.14390000e-02,\n",
       "        -1.68270000e-01,  -1.90030000e-01,   1.46610000e-01,\n",
       "         4.86780000e-01,   1.23060000e-01,  -3.40320000e-01,\n",
       "         1.81250000e-01,   5.68720000e-01,  -1.14460000e-03,\n",
       "        -5.96980000e-01,   1.30130000e-01,   7.11450000e-02,\n",
       "        -5.22910000e-02,   1.61650000e-01,  -2.21380000e-01,\n",
       "        -4.95220000e-01,   1.44850000e-01,  -1.23160000e-01,\n",
       "         9.43030000e-02,   2.70700000e-01,   3.47260000e-02,\n",
       "         4.33490000e-01,   8.71990000e-02,  -1.09690000e-01,\n",
       "        -3.34760000e-01,   2.29290000e-01,   1.56970000e-01,\n",
       "         1.58630000e-01,  -1.97850000e-01,   5.14440000e-02,\n",
       "        -4.40730000e-01,   2.08360000e-01,   7.55970000e-02,\n",
       "        -3.68940000e-01,  -1.75310000e-02,   5.62600000e-02,\n",
       "         3.93250000e-01,   5.95630000e-01])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vector[\"confessed\"][0:50]\n",
    "#w2v.wv.word_vec(\"confessed\")[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=word_to_ix['confessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.27130014e-01,   1.34660006e-01,  -3.49209994e-01,\n",
       "         4.81920004e-01,  -4.93770003e-01,  -3.87939997e-02,\n",
       "        -1.36500001e+00,  -6.52720034e-02,  -2.83829987e-01,\n",
       "        -5.63369989e-01,  -2.60910004e-01,  -2.14389991e-02,\n",
       "        -1.68270007e-01,  -1.90029994e-01,   1.46610007e-01,\n",
       "         4.86779988e-01,   1.23060003e-01,  -3.40319991e-01,\n",
       "         1.81250006e-01,   5.68719983e-01,  -1.14459998e-03,\n",
       "        -5.96979976e-01,   1.30129993e-01,   7.11449981e-02,\n",
       "        -5.22909984e-02,   1.61650002e-01,  -2.21379995e-01,\n",
       "        -4.95220006e-01,   1.44850001e-01,  -1.23159997e-01,\n",
       "         9.43029970e-02,   2.70700008e-01,   3.47260013e-02,\n",
       "         4.33490008e-01,   8.71990025e-02,  -1.09690003e-01,\n",
       "        -3.34760010e-01,   2.29289994e-01,   1.56969994e-01,\n",
       "         1.58629999e-01,  -1.97850004e-01,   5.14440015e-02,\n",
       "        -4.40730006e-01,   2.08360001e-01,   7.55970031e-02,\n",
       "        -3.68939996e-01,  -1.75310001e-02,   5.62600009e-02,\n",
       "         3.93249989e-01,   5.95629990e-01], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[idx][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_DIM = 300\n",
    "HIDDEN_DIM = 80\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruClassifierW2vec(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, vocab_size, label_size, pre_trained_weights, dropout):\n",
    "        super(GruClassifierW2vec, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_embeddings.weight.data=torch.Tensor(pre_trained_weights)\n",
    "        self.gru = nn.GRU(input_size = embedding_dim,\n",
    "                            hidden_size = hidden_dim,\n",
    "                            num_layers = num_layers,\n",
    "                            dropout = dropout)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the first is the hidden h\n",
    "        return (Variable(torch.zeros(self.num_layers, 1, self.hidden_dim)).cuda())\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = embeds.view(len(sentence), 1, -1)\n",
    "        for i in range(self.num_layers):\n",
    "            gru_out, self.hidden = self.gru(x, self.hidden)\n",
    "        y  = self.hidden2label(gru_out[-1])\n",
    "        log_probs = F.log_softmax(y)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GruClassifierW2vec(embedding_dim=W2V_DIM,\n",
    "                            hidden_dim=HIDDEN_DIM,\n",
    "                            num_layers=NUM_LAYERS,\n",
    "                            vocab_size=VOCAB_SIZE,\n",
    "                            label_size=NUM_LABELS,\n",
    "                            pre_trained_weights = weights,\n",
    "                            dropout = DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GruClassifierW2vec(\n",
       "  (word_embeddings): Embedding(28307, 300)\n",
       "  (gru): GRU(300, 80, num_layers=3, dropout=0.2)\n",
       "  (hidden2label): Linear(in_features=80, out_features=3)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6526"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg=int((EAP_size+HPL_size+MWS_size)/3)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260759493670886\n",
      "1.1581188997338066\n",
      "1.0797485109199205\n"
     ]
    }
   ],
   "source": [
    "print(float(avg/EAP_size))\n",
    "print(float(avg/HPL_size))\n",
    "print(float(avg/MWS_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6525.4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAP_size*0.826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6525.33"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPL_size*1.158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6521.476"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWS_size*1.079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAP': 0, 'HPL': 1, 'MWS': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function with mask to compensate class inbalance\n",
    "mask=torch.cuda.FloatTensor((0.826,1.158,1.079))\n",
    "#loss_function = nn.CrossEntropyLoss(weight=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "#print(loss_function.weight)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the lady whom was much astonished to hear addressed as madame joyeuse after the description of madame joyeuse she had just given blushed up to the eyebrows and seemed exceedingly abashed at the reproof '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=train_data[2][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 45\n",
       " 53\n",
       " 54\n",
       " 16\n",
       " 55\n",
       " 56\n",
       " 57\n",
       " 58\n",
       " 59\n",
       " 60\n",
       " 61\n",
       " 62\n",
       " 63\n",
       " 45\n",
       " 64\n",
       "  8\n",
       " 61\n",
       " 62\n",
       " 65\n",
       " 10\n",
       " 66\n",
       " 67\n",
       " 68\n",
       " 69\n",
       " 57\n",
       " 45\n",
       " 70\n",
       " 14\n",
       " 71\n",
       " 72\n",
       " 73\n",
       " 74\n",
       " 45\n",
       " 75\n",
       "[torch.cuda.LongTensor of size 34 (GPU 0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_context=Variable(make_context_vector(sample,word_to_ix)).cuda()\n",
    "sample_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0662 -1.1038 -1.1268\n",
       "[torch.cuda.FloatTensor of size 1x3 (GPU 0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=model(sample_context)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters/(len(x_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 1000. Loss: 0.0010656398953869939. Accuracy: 75.48518896833504\n",
      "Iterations: 2000. Loss: 5.364274329622276e-05. Accuracy: 75.74055158324822\n",
      "Iterations: 3000. Loss: 0.0001517419150331989. Accuracy: 75.79162410623084\n",
      "Iterations: 4000. Loss: 0.0003995097358711064. Accuracy: 75.79162410623084\n",
      "Iterations: 5000. Loss: 0.0010583758121356368. Accuracy: 75.25536261491318\n",
      "Iterations: 6000. Loss: 0.00024256148026324809. Accuracy: 75.79162410623084\n",
      "Iterations: 7000. Loss: 0.006435029674321413. Accuracy: 76.22574055158324\n",
      "Iterations: 8000. Loss: 0.00018463814922142774. Accuracy: 73.56996935648621\n",
      "Iterations: 9000. Loss: 2.706014311115723e-05. Accuracy: 72.88049029622063\n",
      "Iterations: 10000. Loss: 3.421248038648628e-05. Accuracy: 73.1103166496425\n",
      "Iterations: 11000. Loss: 0.00024136967840604484. Accuracy: 74.41266598569969\n",
      "Iterations: 12000. Loss: 0.00011777184408856556. Accuracy: 74.1317671092952\n",
      "Iterations: 13000. Loss: 0.06839083880186081. Accuracy: 73.54443309499489\n",
      "Iterations: 14000. Loss: 0.004312501288950443. Accuracy: 73.62104187946885\n",
      "Iterations: 15000. Loss: 0.0009450022480450571. Accuracy: 74.54034729315629\n",
      "Iterations: 16000. Loss: 3.361645576660521e-05. Accuracy: 74.31052093973442\n",
      "Iterations: 17000. Loss: 5.94836674281396e-05. Accuracy: 73.51889683350358\n",
      "Iterations: 18000. Loss: 5.864924969500862e-05. Accuracy: 71.60367722165475\n",
      "Iterations: 19000. Loss: 0.00026925752172246575. Accuracy: 73.92747701736465\n",
      "Iterations: 20000. Loss: 3.1822872161865234. Accuracy: 74.31052093973442\n",
      "Iterations: 21000. Loss: 0.000582644424866885. Accuracy: 74.74463738508682\n",
      "Iterations: 22000. Loss: 0.00031716562807559967. Accuracy: 75.33197139938713\n",
      "Iterations: 23000. Loss: 5.2689116273541003e-05. Accuracy: 74.36159346271705\n",
      "Iterations: 24000. Loss: 0.00034564718953333795. Accuracy: 73.21246169560776\n",
      "Iterations: 25000. Loss: 0.00018356545479036868. Accuracy: 72.9826353421859\n",
      "Iterations: 26000. Loss: 0.001073975581675768. Accuracy: 73.31460674157303\n",
      "Iterations: 27000. Loss: 0.0002953569928649813. Accuracy: 74.38712972420838\n",
      "Iterations: 28000. Loss: 0.0005372511222958565. Accuracy: 75.97037793667008\n",
      "Iterations: 29000. Loss: 0.002661735750734806. Accuracy: 75.20429009193055\n",
      "Iterations: 30000. Loss: 0.00030322244856506586. Accuracy: 74.61695607763023\n",
      "Iterations: 31000. Loss: 8.21318244561553e-05. Accuracy: 76.5832482124617\n",
      "Iterations: 32000. Loss: 0.0003854485403280705. Accuracy: 75.63840653728295\n",
      "Iterations: 33000. Loss: 0.00015269544383045286. Accuracy: 75.68947906026558\n",
      "Iterations: 34000. Loss: 0.0003923600015696138. Accuracy: 76.20020429009193\n",
      "Iterations: 35000. Loss: 0.00043704494601115584. Accuracy: 74.87231869254342\n",
      "Iterations: 36000. Loss: 0.0008883106056600809. Accuracy: 74.92339121552605\n",
      "Iterations: 37000. Loss: 0.0014444880653172731. Accuracy: 76.35342185903984\n",
      "Iterations: 38000. Loss: 0.00037472377880476415. Accuracy: 76.60878447395301\n",
      "Iterations: 39000. Loss: 0.000747758662328124. Accuracy: 76.07252298263535\n",
      "Iterations: 40000. Loss: 0.0010140759404748678. Accuracy: 75.58733401430031\n",
      "Iterations: 41000. Loss: 0.00018308870494365692. Accuracy: 75.76608784473953\n",
      "Iterations: 42000. Loss: 8.451581379631534e-05. Accuracy: 75.0\n",
      "Iterations: 43000. Loss: 0.00026258357684127986. Accuracy: 75.15321756894791\n",
      "Iterations: 44000. Loss: 0.001648973091505468. Accuracy: 75.45965270684371\n",
      "Iterations: 45000. Loss: 0.0002898749662563205. Accuracy: 75.99591419816139\n",
      "Iterations: 46000. Loss: 9.870042413240299e-05. Accuracy: 75.02553626149131\n",
      "Iterations: 47000. Loss: 5.9960475482512265e-05. Accuracy: 76.09805924412666\n",
      "Iterations: 48000. Loss: 0.000200609109015204. Accuracy: 75.35750766087845\n",
      "Iterations: 49000. Loss: 7.855583680793643e-05. Accuracy: 75.28089887640449\n",
      "Iterations: 50000. Loss: 0.00010251473577227443. Accuracy: 75.10214504596527\n",
      "Iterations: 51000. Loss: 5.364274329622276e-05. Accuracy: 75.30643513789582\n",
      "Iterations: 52000. Loss: 0.00011443436960689723. Accuracy: 74.23391215526047\n",
      "Iterations: 53000. Loss: 0.03232719004154205. Accuracy: 74.97446373850869\n",
      "Iterations: 54000. Loss: 8.237022848334163e-05. Accuracy: 75.28089887640449\n",
      "Iterations: 55000. Loss: 0.0001392267586197704. Accuracy: 74.66802860061287\n",
      "Iterations: 56000. Loss: 0.0004049911512993276. Accuracy: 75.4341164453524\n",
      "Iterations: 57000. Loss: 0.00040904260822571814. Accuracy: 74.66802860061287\n",
      "Iterations: 58000. Loss: 9.798523387871683e-05. Accuracy: 74.89785495403473\n",
      "Iterations: 59000. Loss: 0.00012003655137959868. Accuracy: 74.89785495403473\n",
      "Iterations: 60000. Loss: 0.00017188502533826977. Accuracy: 74.94892747701736\n",
      "Iterations: 61000. Loss: 8.451581379631534e-05. Accuracy: 74.25944841675178\n",
      "Iterations: 62000. Loss: 0.0017477489309385419. Accuracy: 74.36159346271705\n",
      "Iterations: 63000. Loss: 0.00011252723925281316. Accuracy: 76.22574055158324\n",
      "Iterations: 64000. Loss: 6.8662193370983e-05. Accuracy: 76.7364657814096\n",
      "Iterations: 65000. Loss: 1.8358061424805783e-05. Accuracy: 75.99591419816139\n",
      "Iterations: 66000. Loss: 4.172316494077677e-06. Accuracy: 75.89376915219611\n",
      "Iterations: 67000. Loss: 2.4199192921514623e-05. Accuracy: 74.43820224719101\n",
      "Iterations: 68000. Loss: 0.00022742546570952982. Accuracy: 75.61287027579162\n",
      "Iterations: 69000. Loss: 7.903263758635148e-05. Accuracy: 75.76608784473953\n",
      "Iterations: 70000. Loss: 0.00018761781393550336. Accuracy: 73.87640449438203\n",
      "Iterations: 71000. Loss: 3.7788631743751466e-05. Accuracy: 76.07252298263535\n",
      "Iterations: 72000. Loss: 2.455681169521995e-05. Accuracy: 75.99591419816139\n",
      "Iterations: 73000. Loss: 5.745722592109814e-05. Accuracy: 76.12359550561797\n",
      "Iterations: 74000. Loss: 1.549708758830093e-05. Accuracy: 75.15321756894791\n",
      "Iterations: 75000. Loss: 2.0861407392658293e-05. Accuracy: 74.1317671092952\n",
      "Iterations: 76000. Loss: 0.00016139635408762842. Accuracy: 72.85495403472932\n",
      "Iterations: 77000. Loss: 2.2649508537142538e-05. Accuracy: 73.8508682328907\n",
      "Iterations: 78000. Loss: 1.6689286894688848e-06. Accuracy: 75.53626149131767\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for (sent,label) in train_data:\n",
    "        # Step 1 - clear the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        ## Step 2- Prepare input and label\n",
    "        context_vec = Variable(make_context_vector(sent, word_to_ix)).cuda()\n",
    "        target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "        \n",
    "        # Step 3 - Run forward pass\n",
    "        output = model(context_vec)  \n",
    "        \n",
    "        # Step 4 - Compute loss, gradients, update parameters\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1     \n",
    "        ## Calculate final accuracy\n",
    "        if iter % 1000 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (sent,label) in valid_data:\n",
    "                context_vec = Variable(make_context_vector(sent, word_to_ix)).cuda()\n",
    "                target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "                output = model(context_vec)\n",
    "                _,predicted = torch.max(output.data,1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted[0] == make_target(label, label_to_ix)).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print('Iterations: {}. Loss: {}. Accuracy: {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- INPUT ------------------------------\n",
      "TRUE LABEL = EAP\n",
      "SENTENCE = have indeed no abhorrence of danger except in its absolute effect in terror \n",
      "-------------------- PREDICTION ------------------------------\n",
      "PRED = 0\n",
      "PRED = EAP\n",
      "PROBS = Variable containing:\n",
      " 0.8685  0.1270  0.0045\n",
      "[torch.cuda.FloatTensor of size 1x3 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "bow_vec = Variable(make_context_vector(valid_data[n][0], word_to_ix))\n",
    "print(\"-\"*20 + \" INPUT \"+\"-\"*30)\n",
    "print(\"TRUE LABEL = {}\".format(valid_data[n][1]))\n",
    "print(\"SENTENCE = {}\".format(valid_data[n][0]))\n",
    "print(\"-\"*20 + \" PREDICTION \"+\"-\"*30)\n",
    "log_probs = model(bow_vec)\n",
    "_,predicted = torch.max(log_probs.data,1)\n",
    "print(\"PRED = {}\".format(predicted[0]))\n",
    "print(\"PRED = {}\".format(list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted[0])]))\n",
    "##print(\"LOG_PROB = {}\".format(log_probs))\n",
    "print(\"PROBS = {}\".format(F.softmax(log_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vec = Variable(make_context_vector(valid_data[10][0], word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_loss(valid_data, model, label_to_ix, word_to_ix):\n",
    "    true_label = np.zeros((len(valid_data),1))\n",
    "    results_valid = np.zeros((len(valid_data),len(label_to_ix)))\n",
    "    for i in range(len(valid_data)):\n",
    "        bow_vec = Variable(make_context_vector(valid_data[i][0], word_to_ix))\n",
    "        log_probs = model(bow_vec)\n",
    "        pred = F.softmax(log_probs,dim=1).data.cpu().numpy()\n",
    "        results_valid[i]=pred\n",
    "        true_label[i]=label_to_ix[valid_data[i][1]]\n",
    "    return log_loss(true_label,results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1709497185753852"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_loss(valid_data, model, label_to_ix, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model,test):\n",
    "    my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "    my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "    for i in range(len(test['phrase_preprocessed'])):\n",
    "        sample=test['phrase_preprocessed'][i]\n",
    "        #print(sample)\n",
    "        sample_context=Variable(make_context_vector(sample,word_to_ix)).cuda()\n",
    "        log_prob=model(sample_context)\n",
    "        probs=F.softmax(log_prob)\n",
    "        my_sub.loc[i] = [test['id'][i], probs.data[0][0],probs.data[0][1],probs.data[0][2]]\n",
    "    return my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=make_preds(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('roberto_new_12.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
