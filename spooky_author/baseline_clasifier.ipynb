{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAP = train[train['author']=='EAP'].reset_index(drop=True)\n",
    "print(\"Size of Edgar Allan Poe dataset = {}\".format(len(EAP)))\n",
    "print(\"% of Edgar Allan Poe dataset = {0:.03f}\".format(len(EAP)/len(train)))\n",
    "EAP[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPL = train[train['author']=='HPL'].reset_index(drop=True)\n",
    "print(\"Size of HP Lovercraft dataset = {}\".format(len(HPL)))\n",
    "print(\"% of HP Lovercraft dataset = {0:.03f}\".format(len(HPL)/len(train)))\n",
    "HPL[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MWS = train[train['author']=='MWS'].reset_index(drop=True)\n",
    "print(\"Size of Mary Shelley dataset = {}\".format(len(MWS)))\n",
    "print(\"% of Marry Shelley dataset = {0:.03f}\".format(len(MWS)/len(train)))\n",
    "MWS[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enconder = preprocessing.LabelEncoder()\n",
    "label_enconder.fit(train['author'])\n",
    "train['label_encoded'] = label_enconder.transform(train['author'])\n",
    "train[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punkt(text):\n",
    "    import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_processed']=train['text'].apply(lambda x: lower_case(x))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train['text_processed'], train['label_encoded'], test_size = 0.2, random_state = 4)\n",
    "true_label = np.array(y_test)\n",
    "print(\"#\" * 20 + \" Some stats \" + \"#\"*20)\n",
    "print(\"Dataset training: {} uterances\".format(x_train.shape[0]))\n",
    "print(\"Dataset testing: {} uterances\".format(x_test.shape[0]))\n",
    "print(\"Different classes: {}\".format(len(y_train.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = TfidfVectorizer(\n",
    "                        max_df = 0.5,\n",
    "                        stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features = features.fit_transform(x_train)\n",
    "x_test_features = features.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = SGDClassifier(penalty = 'l2', loss = 'log', class_weight = 'balanced')\n",
    "model_sgd.fit(x_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sgd = model_sgd.predict(x_test_features)\n",
    "print(\"Current Accuracy: {0:.3f}\".format(accuracy_score(preds_sgd,true_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_proba_response(msg, vectors, model):\n",
    "    msg_vec = vectors.transform([msg])\n",
    "#    print(msg_vec)\n",
    "    pred_prob=model.predict_proba(msg_vec)\n",
    "    pd_unsorted = pd.DataFrame(\n",
    "        {'label_encode': model.classes_,\n",
    "         'label_decode': label_enconder.inverse_transform(model.classes_),\n",
    "         'pred_proba':  pred_prob[0]})\n",
    "    \n",
    "    probas = {\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[0][0]:\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[0][2],\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[1][0]:\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[1][2],\n",
    "         pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[2][0]:\n",
    "         pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[2][2]}\n",
    "    \n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = (test['text'][0]).lower()\n",
    "print(msg)\n",
    "msg_vec = features.transform([msg])\n",
    "print(msg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_txt_proba_response(msg,features, model_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in range(0,10):\n",
    "    text = test['text'][msg]\n",
    "    print('Sentence {} - {}'.format(msg, text))\n",
    "    print('Prediction = {} \\n'.format(get_txt_proba_response(text,features, model_sgd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = get_txt_proba_response(test['text'][1],features, model_sgd)\n",
    "print(reply)\n",
    "print(reply['EAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    reply=get_txt_proba_response(test['text'][i].lower(),features, model_sgd)\n",
    "    #EAP.append(reply['EAP'])\n",
    "    #HPL.append(reply['HPL'])\n",
    "    #MWS.append(reply['MWS'])\n",
    "    my_sub.loc[i] = [test['id'][i], reply['EAP'], reply['HPL'], reply['MWS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub['EAP'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub.to_csv('roberto_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.1, 0.5, 0.75, 0.9, 1.0),\n",
    "    'vect__max_features': (None, 5000, 7000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams,\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80, 200),\n",
    "    'clf__class_weight': (None, 'balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "    \n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=3)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Stemming\n",
    "    return gensim.parsing.preprocessing.stem_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
