{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotting Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## NLP Libraries\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "spacy_en = spacy.load('en')\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking if GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "8387  id11749         All this is now the fitter for my purpose.\n",
       "8388  id10526                 I fixed myself on a wide solitude.\n",
       "8389  id13477  It is easily understood that what might improv...\n",
       "8390  id13761  Be this as it may, I now began to feel the ins...\n",
       "8391  id04282  Long winded, statistical, and drearily genealo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    \n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "\n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=2)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process howev afford mean ascertain dimens dun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occur fumbl might mere mistak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box which caper hill cut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>love spring look windsor terrac sixteen fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>find noth els even gold superintend abandon at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  process howev afford mean ascertain dimens dun...  \n",
       "1                never occur fumbl might mere mistak  \n",
       "2  left hand gold snuff box which caper hill cut ...  \n",
       "3  love spring look windsor terrac sixteen fertil...  \n",
       "4  find noth els even gold superintend abandon at...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['phrase_preprocessed']=train['text'].apply(lambda x: transformText(x,do_stop=True, do_stem=True))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>still urg leav ireland inquietud impati father...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>fire want fan could readili fan newspap govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>broken frail door found thi two cleanli pick h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>think possibl manag without them on actual tum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>sure limit knowledg mai extend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1  id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2  id00134  And when they had broken down the frail door t...   \n",
       "3  id27757  While I was thinking how I should possibly man...   \n",
       "4  id04081  I am not sure to what limit his knowledge may ...   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  still urg leav ireland inquietud impati father...  \n",
       "1  fire want fan could readili fan newspap govern...  \n",
       "2  broken frail door found thi two cleanli pick h...  \n",
       "3  think possibl manag without them on actual tum...  \n",
       "4                     sure limit knowledg mai extend  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['phrase_preprocessed']=test['text'].apply(lambda x: transformText(x,do_stop=True, do_stem=True))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train['phrase_preprocessed'],\n",
    "                                                      train['author'], \n",
    "                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['still urg leav ireland inquietud impati father thought best yield',\n",
       "       'fire want fan could readili fan newspap govern grew weaker doubt leather iron acquir durabl proport for short time pair bellow rotterdam ever stood need stitch requir assist hammer',\n",
       "       'broken frail door found thi two cleanli pick human skeleton earthen floor number singular beetl crawl shadowi corner',\n",
       "       ...,\n",
       "       'easili understood might improv close scrutin detail mai time injur gener distantli observ effect',\n",
       "       'mai began feel inspir burn hope length nurtur secret thought stern desper resolut would submit longer enslav',\n",
       "       'long wind statist drearili genealog matter wa ran continu thread brood tenaci horror preternatur malevol impress even impress good doctor'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test['phrase_preprocessed'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in list(x_train) + list(x_valid) + list(x_test):\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17364\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = { \"EAP\": 0, \"HPL\": 1, \"MWS\": 2 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17364, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making iterable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agit reflect threw made friend dread danger relaps', 'MWS'),\n",
       " ('thu isol thrown upon resourc spent hour childhood pore ancient tome fill shadow haunt librari chateau roam without aim purpos perpetu dusk spectral wood cloth side hill near foot',\n",
       "  'HPL'),\n",
       " ('delici word letter concern me i cannot tell you said how ardent desir see mathilda',\n",
       "  'MWS'),\n",
       " ('account might properli belong former period life present moment lead far afield',\n",
       "  'MWS'),\n",
       " ('bear mind argument urg thicket scene applic chief part scene outrag commit singl individu',\n",
       "  'EAP')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=list(zip(x_train,y_train))\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('see morrow meantim adieu rose walk room paus door lean it busi thought taken power support herself said lord raymond probabl return',\n",
       "  'MWS'),\n",
       " ('act then ever must impuls', 'MWS'),\n",
       " ('bring right arm across breast actuat littl machineri necessari guid left arm finger figur',\n",
       "  'EAP'),\n",
       " ('di could found record murder whose cruel act might compar hi', 'MWS'),\n",
       " ('none effort plausibl detail voyag itself', 'EAP')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data=list(zip(x_valid,y_valid))\n",
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model - BoW Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        \n",
    "        ## Defining parameters for linear model\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "    \n",
    "    def forward(self, bow_vec):\n",
    "        ## do the foward pass and implement non-linearity\n",
    "        return F.log_softmax(self.linear(bow_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence.split():\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_idx):\n",
    "    return torch.LongTensor([label_to_idx[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> SENTENCE: we kept smack cove five mile higher coast thi practic fine weather take advantag fifteen minut slack push across main channel mosko str m far pool drop upon anchorag somewher near otterholm sandflesen eddi violent elsewher\n",
      ">> SENTIMENT: EAP\n",
      ">> INPUT SIZE: torch.Size([1, 17364])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 1x17364]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5118\n",
    "sample_phrase=make_bow_vector(x_train[n],word_to_ix)\n",
    "print(\">> SENTENCE: {}\".format(x_train[n]))\n",
    "print(\">> SENTIMENT: {}\".format(y_train[n]))\n",
    "print(\">> INPUT SIZE: {}\".format(sample_phrase.size()))\n",
    "sample_phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17364, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (linear): Linear(in_features=17364, out_features=3)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.cuda.FloatTensor((0.826,1.158,1.079))\n",
    "loss_function = nn.CrossEntropyLoss(weight=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "n_iters = 7000\n",
    "num_epochs = n_iters/(len(x_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 1000. Loss: 0.006390612106770277. Accuracy: 82.073544433095\n",
      "Iterations: 2000. Loss: 0.0002262336201965809. Accuracy: 81.86925434116445\n",
      "Iterations: 3000. Loss: 0.008876388892531395. Accuracy: 82.15015321756894\n",
      "Iterations: 4000. Loss: 5.924526340095326e-05. Accuracy: 81.84371807967314\n",
      "Iterations: 5000. Loss: 0.37198179960250854. Accuracy: 81.7926455566905\n",
      "Iterations: 6000. Loss: 0.5646800994873047. Accuracy: 81.97139938712972\n",
      "Iterations: 7000. Loss: 0.1864282637834549. Accuracy: 82.2267620020429\n",
      "Iterations: 8000. Loss: 0.3021472692489624. Accuracy: 81.92032686414709\n",
      "Iterations: 9000. Loss: 0.7592883706092834. Accuracy: 82.25229826353421\n",
      "Iterations: 10000. Loss: 0.19229216873645782. Accuracy: 81.89479060265577\n",
      "Iterations: 11000. Loss: 0.006421408616006374. Accuracy: 81.66496424923392\n",
      "Iterations: 12000. Loss: 0.2754216194152832. Accuracy: 81.94586312563841\n",
      "Iterations: 13000. Loss: 0.01569185219705105. Accuracy: 81.69050051072523\n",
      "Iterations: 14000. Loss: 0.2403641641139984. Accuracy: 82.15015321756894\n",
      "Iterations: 15000. Loss: 0.11718978732824326. Accuracy: 82.073544433095\n",
      "Iterations: 16000. Loss: 0.19086606800556183. Accuracy: 82.12461695607763\n",
      "Iterations: 17000. Loss: 0.8359191417694092. Accuracy: 81.89479060265577\n",
      "Iterations: 18000. Loss: 0.03299754112958908. Accuracy: 81.99693564862105\n",
      "Iterations: 19000. Loss: 0.14400464296340942. Accuracy: 82.04800817160368\n",
      "Iterations: 20000. Loss: 0.0033066379837691784. Accuracy: 81.99693564862105\n",
      "Iterations: 21000. Loss: 0.4602590799331665. Accuracy: 82.12461695607763\n",
      "Iterations: 22000. Loss: 0.27817970514297485. Accuracy: 81.92032686414709\n",
      "Iterations: 23000. Loss: 0.2546246349811554. Accuracy: 82.12461695607763\n",
      "Iterations: 24000. Loss: 0.007330543827265501. Accuracy: 82.15015321756894\n",
      "Iterations: 25000. Loss: 0.33089497685432434. Accuracy: 81.84371807967314\n",
      "Iterations: 26000. Loss: 9.226373367710039e-05. Accuracy: 81.89479060265577\n",
      "Iterations: 27000. Loss: 0.13181713223457336. Accuracy: 81.81818181818181\n",
      "Iterations: 28000. Loss: 0.00035696811391972005. Accuracy: 81.89479060265577\n",
      "Iterations: 29000. Loss: 2.13382354559144e-05. Accuracy: 81.81818181818181\n",
      "Iterations: 30000. Loss: 1.6802804470062256. Accuracy: 82.0990806945863\n",
      "Iterations: 31000. Loss: 0.16309455037117004. Accuracy: 82.02247191011236\n",
      "Iterations: 32000. Loss: 0.35696524381637573. Accuracy: 82.15015321756894\n",
      "Iterations: 33000. Loss: 0.1594158560037613. Accuracy: 82.0990806945863\n",
      "Iterations: 34000. Loss: 0.07139110565185547. Accuracy: 81.92032686414709\n",
      "Iterations: 35000. Loss: 0.0. Accuracy: 81.86925434116445\n",
      "Iterations: 36000. Loss: 0.1914490908384323. Accuracy: 81.92032686414709\n",
      "Iterations: 37000. Loss: 0.13693848252296448. Accuracy: 81.92032686414709\n",
      "Iterations: 38000. Loss: 0.084483303129673. Accuracy: 82.073544433095\n",
      "Iterations: 39000. Loss: 0.03171887248754501. Accuracy: 82.073544433095\n",
      "Iterations: 40000. Loss: 0.0052771554328501225. Accuracy: 82.15015321756894\n",
      "Iterations: 41000. Loss: 0.002083870582282543. Accuracy: 81.86925434116445\n",
      "Iterations: 42000. Loss: 0.03696795180439949. Accuracy: 81.89479060265577\n",
      "Iterations: 43000. Loss: 0.06366200000047684. Accuracy: 82.02247191011236\n",
      "Iterations: 44000. Loss: 0.022641366347670555. Accuracy: 81.89479060265577\n",
      "Iterations: 45000. Loss: 0.058772895485162735. Accuracy: 82.073544433095\n",
      "Iterations: 46000. Loss: 1.0552806854248047. Accuracy: 81.97139938712972\n",
      "Iterations: 47000. Loss: 0.03380505368113518. Accuracy: 82.0990806945863\n",
      "Iterations: 48000. Loss: 0.19054551422595978. Accuracy: 82.0990806945863\n",
      "Iterations: 49000. Loss: 0.2070462703704834. Accuracy: 81.89479060265577\n",
      "Iterations: 50000. Loss: 0.009984430857002735. Accuracy: 82.15015321756894\n",
      "Iterations: 51000. Loss: 0.10083381831645966. Accuracy: 81.94586312563841\n",
      "Iterations: 52000. Loss: 0.27138280868530273. Accuracy: 81.89479060265577\n",
      "Iterations: 53000. Loss: 0.024600939825177193. Accuracy: 81.89479060265577\n",
      "Iterations: 54000. Loss: 0.15092843770980835. Accuracy: 82.12461695607763\n",
      "Iterations: 55000. Loss: 0.057313598692417145. Accuracy: 81.99693564862105\n",
      "Iterations: 56000. Loss: 0.014207523316144943. Accuracy: 82.12461695607763\n",
      "Iterations: 57000. Loss: 0.8733770251274109. Accuracy: 81.81818181818181\n",
      "Iterations: 58000. Loss: 0.7195608615875244. Accuracy: 81.76710929519918\n",
      "Iterations: 59000. Loss: 0.14564862847328186. Accuracy: 81.84371807967314\n",
      "Iterations: 60000. Loss: 0.0020072567276656628. Accuracy: 81.76710929519918\n",
      "Iterations: 61000. Loss: 0.8921930193901062. Accuracy: 81.97139938712972\n",
      "Iterations: 62000. Loss: 0.10850752145051956. Accuracy: 82.02247191011236\n",
      "Iterations: 63000. Loss: 0.8980388045310974. Accuracy: 82.17568947906027\n",
      "Iterations: 64000. Loss: 0.09239519387483597. Accuracy: 81.94586312563841\n",
      "Iterations: 65000. Loss: 0.41234147548675537. Accuracy: 81.92032686414709\n",
      "Iterations: 66000. Loss: 0.03742186352610588. Accuracy: 81.94586312563841\n",
      "Iterations: 67000. Loss: 0.2419983148574829. Accuracy: 81.97139938712972\n",
      "Iterations: 68000. Loss: 0.0384003221988678. Accuracy: 82.04800817160368\n",
      "Iterations: 69000. Loss: 0.02546999603509903. Accuracy: 81.84371807967314\n",
      "Iterations: 70000. Loss: 0.18973194062709808. Accuracy: 82.0990806945863\n",
      "Iterations: 71000. Loss: 0.0024391443002969027. Accuracy: 81.97139938712972\n",
      "Iterations: 72000. Loss: 0.017394958063960075. Accuracy: 81.86925434116445\n",
      "Iterations: 73000. Loss: 0.62080317735672. Accuracy: 81.94586312563841\n",
      "Iterations: 74000. Loss: 0.12058164924383163. Accuracy: 81.86925434116445\n",
      "Iterations: 75000. Loss: 5.960462772236497e-07. Accuracy: 81.81818181818181\n",
      "Iterations: 76000. Loss: 0.30557844042778015. Accuracy: 81.76710929519918\n",
      "Iterations: 77000. Loss: 0.11740688979625702. Accuracy: 81.86925434116445\n",
      "Iterations: 78000. Loss: 0.04997118189930916. Accuracy: 81.94586312563841\n",
      "Iterations: 79000. Loss: 0.0026598332915455103. Accuracy: 81.99693564862105\n",
      "Iterations: 80000. Loss: 0.13335295021533966. Accuracy: 81.97139938712972\n",
      "Iterations: 81000. Loss: 0.14563904702663422. Accuracy: 81.94586312563841\n",
      "Iterations: 82000. Loss: 0.1829305738210678. Accuracy: 81.89479060265577\n",
      "Iterations: 83000. Loss: 0.11729898303747177. Accuracy: 81.94586312563841\n",
      "Iterations: 84000. Loss: 0.0013812772231176496. Accuracy: 81.94586312563841\n",
      "Iterations: 85000. Loss: 1.610978126525879. Accuracy: 81.97139938712972\n",
      "Iterations: 86000. Loss: 0.0510018989443779. Accuracy: 81.89479060265577\n",
      "Iterations: 87000. Loss: 0.21328197419643402. Accuracy: 81.94586312563841\n",
      "Iterations: 88000. Loss: 0.16718576848506927. Accuracy: 81.81818181818181\n",
      "Iterations: 89000. Loss: 0.008462758734822273. Accuracy: 81.89479060265577\n",
      "Iterations: 90000. Loss: 0.1222948506474495. Accuracy: 82.04800817160368\n",
      "Iterations: 91000. Loss: 0.056636154651641846. Accuracy: 81.7926455566905\n",
      "Iterations: 92000. Loss: 0.4946758449077606. Accuracy: 81.89479060265577\n",
      "Iterations: 93000. Loss: 0.1475391834974289. Accuracy: 81.76710929519918\n",
      "Iterations: 94000. Loss: 0.005880910903215408. Accuracy: 81.92032686414709\n",
      "Iterations: 95000. Loss: 0.17233240604400635. Accuracy: 81.89479060265577\n",
      "Iterations: 96000. Loss: 2.3603161025675945e-05. Accuracy: 81.81818181818181\n",
      "Iterations: 97000. Loss: 0.060037095099687576. Accuracy: 81.99693564862105\n",
      "Iterations: 98000. Loss: 0.6038443446159363. Accuracy: 82.02247191011236\n",
      "Iterations: 99000. Loss: 0.12061039358377457. Accuracy: 81.97139938712972\n",
      "Iterations: 100000. Loss: 0.04152883216738701. Accuracy: 82.02247191011236\n",
      "Iterations: 101000. Loss: 0.819781482219696. Accuracy: 81.94586312563841\n",
      "Iterations: 102000. Loss: 0.3341609835624695. Accuracy: 81.97139938712972\n",
      "Iterations: 103000. Loss: 1.0562453269958496. Accuracy: 81.84371807967314\n",
      "Iterations: 104000. Loss: 0.005516188219189644. Accuracy: 81.7926455566905\n",
      "Iterations: 105000. Loss: 0.167463481426239. Accuracy: 81.7926455566905\n",
      "Iterations: 106000. Loss: 0.016475817188620567. Accuracy: 81.86925434116445\n",
      "Iterations: 107000. Loss: 0.1825990080833435. Accuracy: 81.76710929519918\n",
      "Iterations: 108000. Loss: 0.08420160412788391. Accuracy: 81.92032686414709\n",
      "Iterations: 109000. Loss: 0.04053238034248352. Accuracy: 81.92032686414709\n",
      "Iterations: 110000. Loss: 0.06765802949666977. Accuracy: 81.94586312563841\n",
      "Iterations: 111000. Loss: 0.09723000973463058. Accuracy: 81.86925434116445\n",
      "Iterations: 112000. Loss: 0.6546377539634705. Accuracy: 81.81818181818181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 113000. Loss: 0.18517456948757172. Accuracy: 81.92032686414709\n",
      "Iterations: 114000. Loss: 0.03184659406542778. Accuracy: 82.02247191011236\n",
      "Iterations: 115000. Loss: 0.08688245713710785. Accuracy: 82.04800817160368\n",
      "Iterations: 116000. Loss: 0.012554424814879894. Accuracy: 81.94586312563841\n",
      "Iterations: 117000. Loss: 0.19424781203269958. Accuracy: 81.94586312563841\n",
      "Iterations: 118000. Loss: 0.40765267610549927. Accuracy: 81.7926455566905\n",
      "Iterations: 119000. Loss: 1.8756237030029297. Accuracy: 81.7926455566905\n",
      "Iterations: 120000. Loss: 0.14633987843990326. Accuracy: 81.7926455566905\n",
      "Iterations: 121000. Loss: 2.2617061138153076. Accuracy: 81.89479060265577\n",
      "Iterations: 122000. Loss: 0.02996932342648506. Accuracy: 81.76710929519918\n",
      "Iterations: 123000. Loss: 1.2018389701843262. Accuracy: 81.6394279877426\n",
      "Iterations: 124000. Loss: 0.19091542065143585. Accuracy: 81.76710929519918\n",
      "Iterations: 125000. Loss: 0.000780635280534625. Accuracy: 81.89479060265577\n",
      "Iterations: 126000. Loss: 0.39931443333625793. Accuracy: 82.02247191011236\n",
      "Iterations: 127000. Loss: 0.22107844054698944. Accuracy: 81.94586312563841\n",
      "Iterations: 128000. Loss: 0.17849761247634888. Accuracy: 81.84371807967314\n",
      "Iterations: 129000. Loss: 0.007879839278757572. Accuracy: 81.81818181818181\n",
      "Iterations: 130000. Loss: 0.817705512046814. Accuracy: 81.92032686414709\n",
      "Iterations: 131000. Loss: 0.001974658342078328. Accuracy: 82.0990806945863\n",
      "Iterations: 132000. Loss: 0.010022788308560848. Accuracy: 81.92032686414709\n",
      "Iterations: 133000. Loss: 1.2396920919418335. Accuracy: 81.89479060265577\n",
      "Iterations: 134000. Loss: 0.07110758125782013. Accuracy: 81.84371807967314\n",
      "Iterations: 135000. Loss: 0.04672100394964218. Accuracy: 81.69050051072523\n",
      "Iterations: 136000. Loss: 0.0003271759778726846. Accuracy: 81.84371807967314\n",
      "Iterations: 137000. Loss: 0.07151630520820618. Accuracy: 82.073544433095\n",
      "Iterations: 138000. Loss: 2.015711784362793. Accuracy: 81.86925434116445\n",
      "Iterations: 139000. Loss: 0.307001531124115. Accuracy: 81.84371807967314\n",
      "Iterations: 140000. Loss: 0.07709077000617981. Accuracy: 81.74157303370787\n",
      "Iterations: 141000. Loss: 1.0315132141113281. Accuracy: 81.97139938712972\n",
      "Iterations: 142000. Loss: 0.08828113973140717. Accuracy: 81.86925434116445\n",
      "Iterations: 143000. Loss: 0.01772281713783741. Accuracy: 81.7926455566905\n",
      "Iterations: 144000. Loss: 0.03070010244846344. Accuracy: 81.84371807967314\n",
      "Iterations: 145000. Loss: 0.5728832483291626. Accuracy: 81.97139938712972\n",
      "Iterations: 146000. Loss: 0.014798982068896294. Accuracy: 81.94586312563841\n",
      "Iterations: 147000. Loss: 0.00016115797916427255. Accuracy: 82.12461695607763\n",
      "Iterations: 148000. Loss: 0.006503133103251457. Accuracy: 81.81818181818181\n",
      "Iterations: 149000. Loss: 0.46468937397003174. Accuracy: 81.76710929519918\n",
      "Iterations: 150000. Loss: 0.16818898916244507. Accuracy: 81.71603677221655\n",
      "Iterations: 151000. Loss: 0.7323908805847168. Accuracy: 81.66496424923392\n",
      "Iterations: 152000. Loss: 0.2370709627866745. Accuracy: 81.84371807967314\n",
      "Iterations: 153000. Loss: 0.14434851706027985. Accuracy: 81.94586312563841\n",
      "Iterations: 154000. Loss: 0.21253922581672668. Accuracy: 81.81818181818181\n",
      "Iterations: 155000. Loss: 0.06410876661539078. Accuracy: 81.86925434116445\n",
      "Iterations: 156000. Loss: 0.11224915832281113. Accuracy: 81.89479060265577\n",
      "Iterations: 157000. Loss: 0.48232635855674744. Accuracy: 81.99693564862105\n",
      "Iterations: 158000. Loss: 0.20102477073669434. Accuracy: 81.71603677221655\n",
      "Iterations: 159000. Loss: 0.05770278722047806. Accuracy: 81.86925434116445\n",
      "Iterations: 160000. Loss: 0.3755592107772827. Accuracy: 81.84371807967314\n",
      "Iterations: 161000. Loss: 0.1939297318458557. Accuracy: 82.073544433095\n",
      "Iterations: 162000. Loss: 0.6007168292999268. Accuracy: 81.97139938712972\n",
      "Iterations: 163000. Loss: 0.04870394244790077. Accuracy: 81.86925434116445\n",
      "Iterations: 164000. Loss: 0.12361720204353333. Accuracy: 81.86925434116445\n",
      "Iterations: 165000. Loss: 0.0300231222063303. Accuracy: 81.81818181818181\n",
      "Iterations: 166000. Loss: 0.11826155334711075. Accuracy: 81.76710929519918\n",
      "Iterations: 167000. Loss: 0.34624284505844116. Accuracy: 81.66496424923392\n",
      "Iterations: 168000. Loss: 0.7803603410720825. Accuracy: 81.71603677221655\n",
      "Iterations: 169000. Loss: 0.0026179824490100145. Accuracy: 81.66496424923392\n",
      "Iterations: 170000. Loss: 0.5832149386405945. Accuracy: 81.69050051072523\n",
      "Iterations: 171000. Loss: 0.15606600046157837. Accuracy: 81.74157303370787\n",
      "Iterations: 172000. Loss: 0.06582844257354736. Accuracy: 81.76710929519918\n",
      "Iterations: 173000. Loss: 0.0017076447838917375. Accuracy: 81.84371807967314\n",
      "Iterations: 174000. Loss: 0.0004804172203876078. Accuracy: 81.84371807967314\n",
      "Iterations: 175000. Loss: 1.4665412902832031. Accuracy: 81.7926455566905\n",
      "Iterations: 176000. Loss: 0.007383557967841625. Accuracy: 81.81818181818181\n",
      "Iterations: 177000. Loss: 0.1429608315229416. Accuracy: 81.92032686414709\n",
      "Iterations: 178000. Loss: 0.032628383487463. Accuracy: 81.97139938712972\n",
      "Iterations: 179000. Loss: 0.08494298160076141. Accuracy: 81.69050051072523\n",
      "Iterations: 180000. Loss: 0.020208772271871567. Accuracy: 81.7926455566905\n",
      "Iterations: 181000. Loss: 5.590759246842936e-05. Accuracy: 81.61389172625128\n",
      "Iterations: 182000. Loss: 0.015454770997166634. Accuracy: 81.66496424923392\n",
      "Iterations: 183000. Loss: 0.0016558758215978742. Accuracy: 81.81818181818181\n",
      "Iterations: 184000. Loss: 0.004727733321487904. Accuracy: 81.97139938712972\n",
      "Iterations: 185000. Loss: 0.000259365770034492. Accuracy: 81.66496424923392\n",
      "Iterations: 186000. Loss: 0.011308973655104637. Accuracy: 81.81818181818181\n",
      "Iterations: 187000. Loss: 0.05048961937427521. Accuracy: 81.6394279877426\n",
      "Iterations: 188000. Loss: 0.023525867611169815. Accuracy: 81.92032686414709\n",
      "Iterations: 189000. Loss: 0.011042083613574505. Accuracy: 81.81818181818181\n",
      "Iterations: 190000. Loss: 0.09057670086622238. Accuracy: 81.74157303370787\n",
      "Iterations: 191000. Loss: 0.11879701912403107. Accuracy: 81.76710929519918\n",
      "Iterations: 192000. Loss: 0.09372302144765854. Accuracy: 81.92032686414709\n",
      "Iterations: 193000. Loss: 0.3924039304256439. Accuracy: 81.89479060265577\n",
      "Iterations: 194000. Loss: 0.028294706717133522. Accuracy: 82.04800817160368\n",
      "Iterations: 195000. Loss: 0.3937472701072693. Accuracy: 81.84371807967314\n",
      "Iterations: 196000. Loss: 6.568216485902667e-05. Accuracy: 81.69050051072523\n",
      "Iterations: 197000. Loss: 0.0689488872885704. Accuracy: 81.76710929519918\n",
      "Iterations: 198000. Loss: 0.10747266560792923. Accuracy: 81.71603677221655\n",
      "Iterations: 199000. Loss: 0.028578346595168114. Accuracy: 81.76710929519918\n",
      "Iterations: 200000. Loss: 0.32499927282333374. Accuracy: 81.99693564862105\n",
      "Iterations: 201000. Loss: 0.5006741285324097. Accuracy: 81.66496424923392\n",
      "Iterations: 202000. Loss: 0.2080896943807602. Accuracy: 81.66496424923392\n",
      "Iterations: 203000. Loss: 0.014020283706486225. Accuracy: 81.71603677221655\n",
      "Iterations: 204000. Loss: 0.014627478085458279. Accuracy: 81.99693564862105\n",
      "Iterations: 205000. Loss: 0.4408385157585144. Accuracy: 81.69050051072523\n",
      "Iterations: 206000. Loss: 0.6170278191566467. Accuracy: 81.84371807967314\n",
      "Iterations: 207000. Loss: 0.05318562313914299. Accuracy: 81.86925434116445\n",
      "Iterations: 208000. Loss: 0.9341861009597778. Accuracy: 81.92032686414709\n",
      "Iterations: 209000. Loss: 0.31949684023857117. Accuracy: 81.86925434116445\n",
      "Iterations: 210000. Loss: 0.06511552631855011. Accuracy: 81.89479060265577\n",
      "Iterations: 211000. Loss: 0.05466257408261299. Accuracy: 81.66496424923392\n",
      "Iterations: 212000. Loss: 3.361645576660521e-05. Accuracy: 81.6394279877426\n",
      "Iterations: 213000. Loss: 0.0013147291028872132. Accuracy: 81.7926455566905\n",
      "Iterations: 214000. Loss: 0.00012015574611723423. Accuracy: 81.69050051072523\n",
      "Iterations: 215000. Loss: 0.11747728288173676. Accuracy: 81.71603677221655\n",
      "Iterations: 216000. Loss: 0.41692984104156494. Accuracy: 81.66496424923392\n",
      "Iterations: 217000. Loss: 0.03077339194715023. Accuracy: 81.58835546475996\n",
      "Iterations: 218000. Loss: 0.21727854013442993. Accuracy: 81.6394279877426\n",
      "Iterations: 219000. Loss: 0.13160865008831024. Accuracy: 81.74157303370787\n",
      "Iterations: 220000. Loss: 0.0011403016978874803. Accuracy: 81.89479060265577\n",
      "Iterations: 221000. Loss: 0.03270811215043068. Accuracy: 81.71603677221655\n",
      "Iterations: 222000. Loss: 0.0004643315332941711. Accuracy: 81.7926455566905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 223000. Loss: 0.029759787023067474. Accuracy: 81.69050051072523\n",
      "Iterations: 224000. Loss: 0.4507604241371155. Accuracy: 81.89479060265577\n",
      "Iterations: 225000. Loss: 0.01650993898510933. Accuracy: 81.84371807967314\n",
      "Iterations: 226000. Loss: 0.5342569947242737. Accuracy: 81.69050051072523\n",
      "Iterations: 227000. Loss: 0.47353145480155945. Accuracy: 81.69050051072523\n",
      "Iterations: 228000. Loss: 0.07962946593761444. Accuracy: 81.61389172625128\n",
      "Iterations: 229000. Loss: 0.6731911301612854. Accuracy: 81.69050051072523\n",
      "Iterations: 230000. Loss: 0.2767869234085083. Accuracy: 81.7926455566905\n",
      "Iterations: 231000. Loss: 0.1019599661231041. Accuracy: 81.89479060265577\n",
      "Iterations: 232000. Loss: 2.3841855067985307e-07. Accuracy: 81.61389172625128\n",
      "Iterations: 233000. Loss: 0.4327751398086548. Accuracy: 81.69050051072523\n",
      "Iterations: 234000. Loss: 0.06536513566970825. Accuracy: 81.69050051072523\n",
      "Iterations: 235000. Loss: 0.014691618271172047. Accuracy: 81.84371807967314\n",
      "Iterations: 236000. Loss: 0.007760020438581705. Accuracy: 81.81818181818181\n",
      "Iterations: 237000. Loss: 0.20870600640773773. Accuracy: 81.61389172625128\n",
      "Iterations: 238000. Loss: 0.3813595175743103. Accuracy: 81.69050051072523\n",
      "Iterations: 239000. Loss: 0.4521598815917969. Accuracy: 81.84371807967314\n",
      "Iterations: 240000. Loss: 0.6220741271972656. Accuracy: 81.76710929519918\n",
      "Iterations: 241000. Loss: 0.13388581573963165. Accuracy: 81.89479060265577\n",
      "Iterations: 242000. Loss: 0.06665516644716263. Accuracy: 81.74157303370787\n",
      "Iterations: 243000. Loss: 0.05035122111439705. Accuracy: 81.61389172625128\n",
      "Iterations: 244000. Loss: 0.001772262854501605. Accuracy: 81.58835546475996\n",
      "Iterations: 245000. Loss: 0.2690064609050751. Accuracy: 81.69050051072523\n",
      "Iterations: 246000. Loss: 0.13609495759010315. Accuracy: 81.69050051072523\n",
      "Iterations: 247000. Loss: 0.0010744519531726837. Accuracy: 81.84371807967314\n",
      "Iterations: 248000. Loss: 0.31267091631889343. Accuracy: 81.69050051072523\n",
      "Iterations: 249000. Loss: 0.007847077213227749. Accuracy: 81.74157303370787\n",
      "Iterations: 250000. Loss: 0.016517912968993187. Accuracy: 81.76710929519918\n",
      "Iterations: 251000. Loss: 5.996047184453346e-05. Accuracy: 81.76710929519918\n",
      "Iterations: 252000. Loss: 0.03500969335436821. Accuracy: 81.71603677221655\n",
      "Iterations: 253000. Loss: 0.14890286326408386. Accuracy: 81.66496424923392\n",
      "Iterations: 254000. Loss: 0.03705824539065361. Accuracy: 81.89479060265577\n",
      "Iterations: 255000. Loss: 0.3834691047668457. Accuracy: 81.84371807967314\n",
      "Iterations: 256000. Loss: 0.9962824583053589. Accuracy: 81.84371807967314\n",
      "Iterations: 257000. Loss: 0.15783019363880157. Accuracy: 81.81818181818181\n",
      "Iterations: 258000. Loss: 0.6175790429115295. Accuracy: 81.58835546475996\n",
      "Iterations: 259000. Loss: 0.013398018665611744. Accuracy: 81.48621041879468\n",
      "Iterations: 260000. Loss: 0.006316340994089842. Accuracy: 81.69050051072523\n",
      "Iterations: 261000. Loss: 0.05463165044784546. Accuracy: 81.66496424923392\n",
      "Iterations: 262000. Loss: 0.036070771515369415. Accuracy: 81.71603677221655\n",
      "Iterations: 263000. Loss: 0.0005017452058382332. Accuracy: 81.69050051072523\n",
      "Iterations: 264000. Loss: 0.00274757225997746. Accuracy: 81.6394279877426\n",
      "Iterations: 265000. Loss: 0.047375865280628204. Accuracy: 81.53728294177732\n",
      "Iterations: 266000. Loss: 0.0499209463596344. Accuracy: 81.66496424923392\n",
      "Iterations: 267000. Loss: 0.08767634630203247. Accuracy: 81.7926455566905\n",
      "Iterations: 268000. Loss: 0.0017876136116683483. Accuracy: 81.69050051072523\n",
      "Iterations: 269000. Loss: 0.1808900684118271. Accuracy: 81.76710929519918\n",
      "Iterations: 270000. Loss: 0.02937716618180275. Accuracy: 81.74157303370787\n",
      "Iterations: 271000. Loss: 0.36522215604782104. Accuracy: 81.81818181818181\n",
      "Iterations: 272000. Loss: 0.27126720547676086. Accuracy: 81.7926455566905\n",
      "Iterations: 273000. Loss: 0.09034529328346252. Accuracy: 81.58835546475996\n",
      "Iterations: 274000. Loss: 0.03751946613192558. Accuracy: 81.56281920326865\n",
      "Iterations: 275000. Loss: 0.0009321396937593818. Accuracy: 81.53728294177732\n",
      "Iterations: 276000. Loss: 1.6689286894688848e-06. Accuracy: 81.53728294177732\n",
      "Iterations: 277000. Loss: 0.004678731318563223. Accuracy: 81.69050051072523\n",
      "Iterations: 278000. Loss: 0.17270508408546448. Accuracy: 81.7926455566905\n",
      "Iterations: 279000. Loss: 0.003422714304178953. Accuracy: 81.66496424923392\n",
      "Iterations: 280000. Loss: 0.0065766796469688416. Accuracy: 81.6394279877426\n",
      "Iterations: 281000. Loss: 0.0004854215949308127. Accuracy: 81.74157303370787\n",
      "Iterations: 282000. Loss: 1.1920927533992653e-07. Accuracy: 81.69050051072523\n",
      "Iterations: 283000. Loss: 0.07426486164331436. Accuracy: 81.69050051072523\n",
      "Iterations: 284000. Loss: 0.0006282739923335612. Accuracy: 81.56281920326865\n",
      "Iterations: 285000. Loss: 0.0060682580806314945. Accuracy: 81.71603677221655\n",
      "Iterations: 286000. Loss: 0.23939059674739838. Accuracy: 81.86925434116445\n",
      "Iterations: 287000. Loss: 0.45017972588539124. Accuracy: 81.76710929519918\n",
      "Iterations: 288000. Loss: 0.03899208828806877. Accuracy: 81.74157303370787\n",
      "Iterations: 289000. Loss: 0.1206779032945633. Accuracy: 81.6394279877426\n",
      "Iterations: 290000. Loss: 0.4333733320236206. Accuracy: 81.56281920326865\n",
      "Iterations: 291000. Loss: 1.1920858014491387e-05. Accuracy: 81.66496424923392\n",
      "Iterations: 292000. Loss: 0.2512849271297455. Accuracy: 81.6394279877426\n",
      "Iterations: 293000. Loss: 0.36894428730010986. Accuracy: 81.53728294177732\n",
      "Iterations: 294000. Loss: 0.8812770247459412. Accuracy: 81.58835546475996\n",
      "Iterations: 295000. Loss: 0.26088640093803406. Accuracy: 81.61389172625128\n",
      "Iterations: 296000. Loss: 0.2718927562236786. Accuracy: 81.58835546475996\n",
      "Iterations: 297000. Loss: 0.00304057402536273. Accuracy: 81.56281920326865\n",
      "Iterations: 298000. Loss: 0.06943945586681366. Accuracy: 81.66496424923392\n",
      "Iterations: 299000. Loss: 0.2825925648212433. Accuracy: 81.66496424923392\n",
      "Iterations: 300000. Loss: 4.768370445162873e-07. Accuracy: 81.66496424923392\n",
      "Iterations: 301000. Loss: 0.5267648696899414. Accuracy: 81.71603677221655\n",
      "Iterations: 302000. Loss: 0.4332171380519867. Accuracy: 81.81818181818181\n",
      "Iterations: 303000. Loss: 2.3007127310847864e-05. Accuracy: 81.7926455566905\n",
      "Iterations: 304000. Loss: 0.011791529133915901. Accuracy: 81.76710929519918\n",
      "Iterations: 305000. Loss: 0.01677631214261055. Accuracy: 81.56281920326865\n",
      "Iterations: 306000. Loss: 0.005104485433548689. Accuracy: 81.48621041879468\n",
      "Iterations: 307000. Loss: 0.35625579953193665. Accuracy: 81.56281920326865\n",
      "Iterations: 308000. Loss: 0.003844253486022353. Accuracy: 81.56281920326865\n",
      "Iterations: 309000. Loss: 0.2393719106912613. Accuracy: 81.71603677221655\n",
      "Iterations: 310000. Loss: 0.29406100511550903. Accuracy: 81.61389172625128\n",
      "Iterations: 311000. Loss: 0.16107095777988434. Accuracy: 81.53728294177732\n",
      "Iterations: 312000. Loss: 0.5999037027359009. Accuracy: 81.56281920326865\n",
      "Iterations: 313000. Loss: 0.008696421980857849. Accuracy: 81.58835546475996\n",
      "Iterations: 314000. Loss: 0.0008156548719853163. Accuracy: 81.66496424923392\n",
      "Iterations: 315000. Loss: 0.2032308131456375. Accuracy: 81.69050051072523\n",
      "Iterations: 316000. Loss: 0.8247147798538208. Accuracy: 81.6394279877426\n",
      "Iterations: 317000. Loss: 0.2007930874824524. Accuracy: 81.81818181818181\n",
      "Iterations: 318000. Loss: 0.6168636679649353. Accuracy: 81.74157303370787\n",
      "Iterations: 319000. Loss: 0.5849277377128601. Accuracy: 81.76710929519918\n",
      "Iterations: 320000. Loss: 0.0006401872960850596. Accuracy: 81.66496424923392\n",
      "Iterations: 321000. Loss: 0.002167734783142805. Accuracy: 81.40960163432074\n",
      "Iterations: 322000. Loss: 0.07572705298662186. Accuracy: 81.56281920326865\n",
      "Iterations: 323000. Loss: 0.46247541904449463. Accuracy: 81.46067415730337\n",
      "Iterations: 324000. Loss: 0.23411279916763306. Accuracy: 81.6394279877426\n",
      "Iterations: 325000. Loss: 0.2736152112483978. Accuracy: 81.69050051072523\n",
      "Iterations: 326000. Loss: 0.011767849326133728. Accuracy: 81.61389172625128\n",
      "Iterations: 327000. Loss: 0.5440826416015625. Accuracy: 81.61389172625128\n",
      "Iterations: 328000. Loss: 0.8083467483520508. Accuracy: 81.56281920326865\n",
      "Iterations: 329000. Loss: 0.08091717213392258. Accuracy: 81.51174668028601\n",
      "Iterations: 330000. Loss: 0.19535380601882935. Accuracy: 81.58835546475996\n",
      "Iterations: 331000. Loss: 0.0077233510091900826. Accuracy: 81.51174668028601\n",
      "Iterations: 332000. Loss: 0.1094999685883522. Accuracy: 81.6394279877426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 333000. Loss: 0.03390335664153099. Accuracy: 81.86925434116445\n",
      "Iterations: 334000. Loss: 0.45538032054901123. Accuracy: 81.94586312563841\n",
      "Iterations: 335000. Loss: 0.00046754872892051935. Accuracy: 81.74157303370787\n",
      "Iterations: 336000. Loss: 0.3920731842517853. Accuracy: 81.6394279877426\n",
      "Iterations: 337000. Loss: 0.010014409199357033. Accuracy: 81.53728294177732\n",
      "Iterations: 338000. Loss: 4.410734163684538e-06. Accuracy: 81.48621041879468\n",
      "Iterations: 339000. Loss: 0.0009205871028825641. Accuracy: 81.48621041879468\n",
      "Iterations: 340000. Loss: 0.33416634798049927. Accuracy: 81.61389172625128\n",
      "Iterations: 341000. Loss: 0.0319293849170208. Accuracy: 81.43513789581205\n",
      "Iterations: 342000. Loss: 1.319566249847412. Accuracy: 81.51174668028601\n",
      "Iterations: 343000. Loss: 0.0891244038939476. Accuracy: 81.46067415730337\n",
      "Iterations: 344000. Loss: 0.2714027762413025. Accuracy: 81.51174668028601\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for (sent,label) in train_data:\n",
    "        # Step 1 - clear the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Step 2- Prepare input and label\n",
    "        bow_vec = Variable(make_bow_vector(sent, word_to_ix)).cuda()\n",
    "        target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "        \n",
    "        # Step 3 - Run forward pass\n",
    "        output = model(bow_vec)\n",
    "        #print(\"Log probabilities - {}\".format(log_probs))\n",
    "        \n",
    "        # Step 4 - Compute loss, gradients, update parameters\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1      \n",
    "        ## Calculate final accuracy\n",
    "        if iter % 1000 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (sent,label) in valid_data:\n",
    "                bow_vec = Variable(make_bow_vector(sent, word_to_ix)).cuda()\n",
    "                target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "                output = model(bow_vec)\n",
    "                _,predicted = torch.max(output.data,1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted[0] == make_target(label, label_to_ix)).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print('Iterations: {}. Loss: {}. Accuracy: {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_loss(valid_data, model, label_to_ix, word_to_ix):\n",
    "    true_label = np.zeros((len(valid_data),1))\n",
    "    results_valid = np.zeros((len(valid_data),len(label_to_ix)))\n",
    "    for i in range(len(valid_data)):\n",
    "        bow_vec = Variable(make_bow_vector(valid_data[i][0], word_to_ix)).cuda()\n",
    "        log_probs = model(bow_vec)\n",
    "        pred = F.softmax(log_probs,dim=1).data.cpu().numpy()\n",
    "        results_valid[i]=pred\n",
    "        true_label[i]=label_to_ix[valid_data[i][1]]\n",
    "    return log_loss(true_label,results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46161438170183672"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_loss(valid_data, model, label_to_ix, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model,test):\n",
    "    my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "    my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "    for i in range(len(test['phrase_preprocessed'])):\n",
    "        sample=test['phrase_preprocessed'][i]\n",
    "        #print(sample)\n",
    "        sample_context=Variable(make_bow_vector(sample,word_to_ix)).cuda()\n",
    "        log_prob=model(sample_context)\n",
    "        probs=F.softmax(log_prob)\n",
    "        my_sub.loc[i] = [test['id'][i], probs.data[0][0],probs.data[0][1],probs.data[0][2]]\n",
    "    return my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, EAP, HPL, MWS]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "preds=make_preds(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>0.644002</td>\n",
       "      <td>0.057733</td>\n",
       "      <td>0.298265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>0.082567</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.877731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.601846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>0.376146</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>0.604954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       EAP       HPL       MWS\n",
       "8387  id11749  0.644002  0.057733  0.298265\n",
       "8388  id10526  0.082567  0.039702  0.877731\n",
       "8389  id13477  0.390211  0.007943  0.601846\n",
       "8390  id13761  0.376146  0.018901  0.604954\n",
       "8391  id04282  0.008989  0.990818  0.000193"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('roberto_new_14.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
