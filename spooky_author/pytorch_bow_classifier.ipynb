{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotting Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## NLP Libraries\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "spacy_en = spacy.load('en')\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking if GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "8387  id11749         All this is now the fitter for my purpose.\n",
       "8388  id10526                 I fixed myself on a wide solitude.\n",
       "8389  id13477  It is easily understood that what might improv...\n",
       "8390  id13761  Be this as it may, I now began to feel the ins...\n",
       "8391  id04282  Long winded, statistical, and drearily genealo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    \n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "\n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=2)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process howev afford mean ascertain dimens dun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occur fumbl might mere mistak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box which caper hill cut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>love spring look windsor terrac sixteen fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>find noth els even gold superintend abandon at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  process howev afford mean ascertain dimens dun...  \n",
       "1                never occur fumbl might mere mistak  \n",
       "2  left hand gold snuff box which caper hill cut ...  \n",
       "3  love spring look windsor terrac sixteen fertil...  \n",
       "4  find noth els even gold superintend abandon at...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['phrase_preprocessed']=train['text'].apply(lambda x: transformText(x,do_stop=True, do_stem=True))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>phrase_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>still urg leav ireland inquietud impati father...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>fire want fan could readili fan newspap govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>broken frail door found thi two cleanli pick h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>think possibl manag without them on actual tum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>sure limit knowledg mai extend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1  id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2  id00134  And when they had broken down the frail door t...   \n",
       "3  id27757  While I was thinking how I should possibly man...   \n",
       "4  id04081  I am not sure to what limit his knowledge may ...   \n",
       "\n",
       "                                 phrase_preprocessed  \n",
       "0  still urg leav ireland inquietud impati father...  \n",
       "1  fire want fan could readili fan newspap govern...  \n",
       "2  broken frail door found thi two cleanli pick h...  \n",
       "3  think possibl manag without them on actual tum...  \n",
       "4                     sure limit knowledg mai extend  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['phrase_preprocessed']=test['text'].apply(lambda x: transformText(x,do_stop=True, do_stem=True))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train['phrase_preprocessed'],\n",
    "                                                      train['author'], \n",
    "                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['still urg leav ireland inquietud impati father thought best yield',\n",
       "       'fire want fan could readili fan newspap govern grew weaker doubt leather iron acquir durabl proport for short time pair bellow rotterdam ever stood need stitch requir assist hammer',\n",
       "       'broken frail door found thi two cleanli pick human skeleton earthen floor number singular beetl crawl shadowi corner',\n",
       "       ...,\n",
       "       'easili understood might improv close scrutin detail mai time injur gener distantli observ effect',\n",
       "       'mai began feel inspir burn hope length nurtur secret thought stern desper resolut would submit longer enslav',\n",
       "       'long wind statist drearili genealog matter wa ran continu thread brood tenaci horror preternatur malevol impress even impress good doctor'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test['phrase_preprocessed'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in list(x_train) + list(x_valid) + list(x_test):\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17364\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = { \"EAP\": 0, \"HPL\": 1, \"MWS\": 2 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17364, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making iterable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agit reflect threw made friend dread danger relaps', 'MWS'),\n",
       " ('thu isol thrown upon resourc spent hour childhood pore ancient tome fill shadow haunt librari chateau roam without aim purpos perpetu dusk spectral wood cloth side hill near foot',\n",
       "  'HPL'),\n",
       " ('delici word letter concern me i cannot tell you said how ardent desir see mathilda',\n",
       "  'MWS'),\n",
       " ('account might properli belong former period life present moment lead far afield',\n",
       "  'MWS'),\n",
       " ('bear mind argument urg thicket scene applic chief part scene outrag commit singl individu',\n",
       "  'EAP')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=list(zip(x_train,y_train))\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('see morrow meantim adieu rose walk room paus door lean it busi thought taken power support herself said lord raymond probabl return',\n",
       "  'MWS'),\n",
       " ('act then ever must impuls', 'MWS'),\n",
       " ('bring right arm across breast actuat littl machineri necessari guid left arm finger figur',\n",
       "  'EAP'),\n",
       " ('di could found record murder whose cruel act might compar hi', 'MWS'),\n",
       " ('none effort plausibl detail voyag itself', 'EAP')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data=list(zip(x_valid,y_valid))\n",
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model - BoW Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        \n",
    "        ## Defining parameters for linear model\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "    \n",
    "    def forward(self, bow_vec):\n",
    "        ## do the foward pass and implement non-linearity\n",
    "        return F.log_softmax(self.linear(bow_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence.split():\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_idx):\n",
    "    return torch.LongTensor([label_to_idx[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> SENTENCE: we kept smack cove five mile higher coast thi practic fine weather take advantag fifteen minut slack push across main channel mosko str m far pool drop upon anchorag somewher near otterholm sandflesen eddi violent elsewher\n",
      ">> SENTIMENT: EAP\n",
      ">> INPUT SIZE: torch.Size([1, 17364])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 1x17364]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5118\n",
    "sample_phrase=make_bow_vector(x_train[n],word_to_ix)\n",
    "print(\">> SENTENCE: {}\".format(x_train[n]))\n",
    "print(\">> SENTIMENT: {}\".format(y_train[n]))\n",
    "print(\">> INPUT SIZE: {}\".format(sample_phrase.size()))\n",
    "sample_phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17364, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "VOCAB_SIZE, NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (linear): Linear(in_features=17364, out_features=3)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters/(len(x_train) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 100. Loss: 1.1417611837387085. Accuracy: 41.215526046986724\n",
      "Iterations: 200. Loss: 1.2148423194885254. Accuracy: 41.29213483146067\n",
      "Iterations: 300. Loss: 1.1584199666976929. Accuracy: 46.220633299284984\n",
      "Iterations: 400. Loss: 0.9859713315963745. Accuracy: 46.016343207354446\n",
      "Iterations: 500. Loss: 1.0582222938537598. Accuracy: 54.03472931562819\n",
      "Iterations: 600. Loss: 1.0999226570129395. Accuracy: 59.6782431052094\n",
      "Iterations: 700. Loss: 1.138018250465393. Accuracy: 53.983656792645554\n",
      "Iterations: 800. Loss: 0.8971432447433472. Accuracy: 54.13687436159346\n",
      "Iterations: 900. Loss: 1.0161608457565308. Accuracy: 51.40449438202247\n",
      "Iterations: 1000. Loss: 1.114119529724121. Accuracy: 46.88457609805924\n",
      "Iterations: 1100. Loss: 1.2058254480361938. Accuracy: 48.34014300306435\n",
      "Iterations: 1200. Loss: 1.1601815223693848. Accuracy: 49.84678243105209\n",
      "Iterations: 1300. Loss: 0.893349289894104. Accuracy: 48.92747701736466\n",
      "Iterations: 1400. Loss: 0.9689179062843323. Accuracy: 51.22574055158325\n",
      "Iterations: 1500. Loss: 0.8477248549461365. Accuracy: 49.923391215526046\n",
      "Iterations: 1600. Loss: 0.6356902122497559. Accuracy: 55.74565883554648\n",
      "Iterations: 1700. Loss: 0.8259708285331726. Accuracy: 63.32992849846782\n",
      "Iterations: 1800. Loss: 0.9103226065635681. Accuracy: 61.77221654749744\n",
      "Iterations: 1900. Loss: 1.0464394092559814. Accuracy: 58.631256384065374\n",
      "Iterations: 2000. Loss: 0.9556487202644348. Accuracy: 53.472931562819205\n",
      "Iterations: 2100. Loss: 1.2161555290222168. Accuracy: 58.50357507660878\n",
      "Iterations: 2200. Loss: 1.4771634340286255. Accuracy: 58.12053115423902\n",
      "Iterations: 2300. Loss: 1.231624960899353. Accuracy: 57.43105209397344\n",
      "Iterations: 2400. Loss: 1.1748007535934448. Accuracy: 59.703779366700715\n",
      "Iterations: 2500. Loss: 0.746887743473053. Accuracy: 57.86516853932584\n",
      "Iterations: 2600. Loss: 0.7917606234550476. Accuracy: 61.1338100102145\n",
      "Iterations: 2700. Loss: 0.8277654647827148. Accuracy: 60.9805924412666\n",
      "Iterations: 2800. Loss: 0.41765743494033813. Accuracy: 61.21041879468846\n",
      "Iterations: 2900. Loss: 0.8395662307739258. Accuracy: 63.96833503575077\n",
      "Iterations: 3000. Loss: 0.6623216867446899. Accuracy: 63.94279877425945\n",
      "Iterations: 3100. Loss: 0.6530407071113586. Accuracy: 61.874361593462716\n",
      "Iterations: 3200. Loss: 0.9505662322044373. Accuracy: 62.10418794688458\n",
      "Iterations: 3300. Loss: 0.9004151821136475. Accuracy: 62.99795709908069\n",
      "Iterations: 3400. Loss: 1.1481478214263916. Accuracy: 62.12972420837589\n",
      "Iterations: 3500. Loss: 0.8459884524345398. Accuracy: 60.597548518896836\n",
      "Iterations: 3600. Loss: 0.812162458896637. Accuracy: 60.648621041879466\n",
      "Iterations: 3700. Loss: 0.3863692283630371. Accuracy: 62.793667007150155\n",
      "Iterations: 3800. Loss: 0.8524723052978516. Accuracy: 62.56384065372829\n",
      "Iterations: 3900. Loss: 1.0119338035583496. Accuracy: 65.755873340143\n",
      "Iterations: 4000. Loss: 0.6658664345741272. Accuracy: 67.95199182839632\n",
      "Iterations: 4100. Loss: 1.1238667964935303. Accuracy: 68.56486210418795\n",
      "Iterations: 4200. Loss: 0.6330282688140869. Accuracy: 66.70071501532176\n",
      "Iterations: 4300. Loss: 0.6185594201087952. Accuracy: 67.28804902962206\n",
      "Iterations: 4400. Loss: 0.8533970713615417. Accuracy: 66.49642492339122\n",
      "Iterations: 4500. Loss: 0.8872354626655579. Accuracy: 66.67517875383044\n",
      "Iterations: 4600. Loss: 0.9614145159721375. Accuracy: 68.76915219611848\n",
      "Iterations: 4700. Loss: 1.0629851818084717. Accuracy: 68.94790602655772\n",
      "Iterations: 4800. Loss: 0.9454188346862793. Accuracy: 69.20326864147088\n",
      "Iterations: 4900. Loss: 0.9435902833938599. Accuracy: 69.10112359550561\n",
      "Iterations: 5000. Loss: 0.8689405918121338. Accuracy: 69.63738508682329\n",
      "Iterations: 5100. Loss: 0.8509359359741211. Accuracy: 70.58222676200204\n",
      "Iterations: 5200. Loss: 0.7371595501899719. Accuracy: 70.48008171603678\n",
      "Iterations: 5300. Loss: 0.6482378244400024. Accuracy: 70.12257405515832\n",
      "Iterations: 5400. Loss: 0.8138461112976074. Accuracy: 68.99897854954035\n",
      "Iterations: 5500. Loss: 0.28548574447631836. Accuracy: 67.74770173646579\n",
      "Iterations: 5600. Loss: 0.6903615593910217. Accuracy: 69.8161389172625\n",
      "Iterations: 5700. Loss: 0.6353176832199097. Accuracy: 69.0755873340143\n",
      "Iterations: 5800. Loss: 0.5454338192939758. Accuracy: 70.70990806945863\n",
      "Iterations: 5900. Loss: 1.0101358890533447. Accuracy: 69.73953013278856\n",
      "Iterations: 6000. Loss: 0.7793189883232117. Accuracy: 66.77732379979571\n",
      "Iterations: 6100. Loss: 0.7213590145111084. Accuracy: 68.99897854954035\n",
      "Iterations: 6200. Loss: 0.6406852602958679. Accuracy: 67.03268641470889\n",
      "Iterations: 6300. Loss: 0.4135604202747345. Accuracy: 65.78140960163432\n",
      "Iterations: 6400. Loss: 0.8414816856384277. Accuracy: 66.317671092952\n",
      "Iterations: 6500. Loss: 0.6916953921318054. Accuracy: 68.69254341164454\n",
      "Iterations: 6600. Loss: 0.9496791362762451. Accuracy: 71.32277834525026\n",
      "Iterations: 6700. Loss: 1.1035878658294678. Accuracy: 71.78243105209397\n",
      "Iterations: 6800. Loss: 0.8776244521141052. Accuracy: 69.99489274770174\n",
      "Iterations: 6900. Loss: 0.6537847518920898. Accuracy: 70.19918283963227\n",
      "Iterations: 7000. Loss: 0.6921145915985107. Accuracy: 72.34422880490297\n",
      "Iterations: 7100. Loss: 1.2521564960479736. Accuracy: 72.70173646578141\n",
      "Iterations: 7200. Loss: 0.09133513271808624. Accuracy: 72.21654749744637\n",
      "Iterations: 7300. Loss: 0.7923388481140137. Accuracy: 71.5270684371808\n",
      "Iterations: 7400. Loss: 1.0541844367980957. Accuracy: 70.2247191011236\n",
      "Iterations: 7500. Loss: 0.8379170298576355. Accuracy: 66.29213483146067\n",
      "Iterations: 7600. Loss: 0.2909729480743408. Accuracy: 69.8161389172625\n",
      "Iterations: 7700. Loss: 1.1525328159332275. Accuracy: 67.59448416751788\n",
      "Iterations: 7800. Loss: 0.25066685676574707. Accuracy: 69.15219611848825\n",
      "Iterations: 7900. Loss: 0.9686475992202759. Accuracy: 71.22063329928498\n",
      "Iterations: 8000. Loss: 0.9943931102752686. Accuracy: 70.27579162410623\n",
      "Iterations: 8100. Loss: 0.7238132953643799. Accuracy: 71.01634320735444\n",
      "Iterations: 8200. Loss: 0.9223161935806274. Accuracy: 70.55669050051073\n",
      "Iterations: 8300. Loss: 0.5911049246788025. Accuracy: 70.50561797752809\n",
      "Iterations: 8400. Loss: 1.0441462993621826. Accuracy: 71.70582226762002\n",
      "Iterations: 8500. Loss: 0.8031913042068481. Accuracy: 70.63329928498467\n",
      "Iterations: 8600. Loss: 0.7192990183830261. Accuracy: 71.88457609805924\n",
      "Iterations: 8700. Loss: 1.2787907123565674. Accuracy: 73.1103166496425\n",
      "Iterations: 8800. Loss: 0.8226982355117798. Accuracy: 72.77834525025536\n",
      "Iterations: 8900. Loss: 0.8903398513793945. Accuracy: 73.1103166496425\n",
      "Iterations: 9000. Loss: 1.1658105850219727. Accuracy: 73.2635342185904\n",
      "Iterations: 9100. Loss: 0.9380909204483032. Accuracy: 72.75280898876404\n",
      "Iterations: 9200. Loss: 0.4893418550491333. Accuracy: 72.80388151174668\n",
      "Iterations: 9300. Loss: 0.7682898640632629. Accuracy: 71.91011235955057\n",
      "Iterations: 9400. Loss: 0.4606901705265045. Accuracy: 72.01225740551584\n",
      "Iterations: 9500. Loss: 0.6899886727333069. Accuracy: 73.39121552604699\n",
      "Iterations: 9600. Loss: 0.7841110229492188. Accuracy: 72.03779366700715\n",
      "Iterations: 9700. Loss: 0.6421616077423096. Accuracy: 71.42492339121553\n",
      "Iterations: 9800. Loss: 0.7509279251098633. Accuracy: 72.77834525025536\n",
      "Iterations: 9900. Loss: 0.3557562232017517. Accuracy: 72.13993871297242\n",
      "Iterations: 10000. Loss: 1.4596073627471924. Accuracy: 72.52298263534219\n",
      "Iterations: 10100. Loss: 0.44213536381721497. Accuracy: 70.50561797752809\n",
      "Iterations: 10200. Loss: 0.14123395085334778. Accuracy: 70.30132788559754\n",
      "Iterations: 10300. Loss: 1.497626781463623. Accuracy: 72.03779366700715\n",
      "Iterations: 10400. Loss: 0.4396132826805115. Accuracy: 70.91419816138917\n",
      "Iterations: 10500. Loss: 0.5304454565048218. Accuracy: 71.32277834525026\n",
      "Iterations: 10600. Loss: 0.6616093516349792. Accuracy: 71.0929519918284\n",
      "Iterations: 10700. Loss: 0.016253111883997917. Accuracy: 71.27170582226762\n",
      "Iterations: 10800. Loss: 0.7421855926513672. Accuracy: 70.9652706843718\n",
      "Iterations: 10900. Loss: 0.8237534165382385. Accuracy: 70.35240040858018\n",
      "Iterations: 11000. Loss: 0.1901281625032425. Accuracy: 69.8161389172625\n",
      "Iterations: 11100. Loss: 0.6904111504554749. Accuracy: 69.9438202247191\n",
      "Iterations: 11200. Loss: 0.2503916323184967. Accuracy: 70.04596527068438\n",
      "Iterations: 11300. Loss: 1.9394769668579102. Accuracy: 71.62921348314607\n",
      "Iterations: 11400. Loss: 0.5986583232879639. Accuracy: 73.56996935648621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 11500. Loss: 0.736420750617981. Accuracy: 74.00408580183861\n",
      "Iterations: 11600. Loss: 0.7553919553756714. Accuracy: 74.46373850868233\n",
      "Iterations: 11700. Loss: 0.8663567304611206. Accuracy: 73.92747701736465\n",
      "Iterations: 11800. Loss: 1.1619982719421387. Accuracy: 73.79979570990807\n",
      "Iterations: 11900. Loss: 1.4577738046646118. Accuracy: 73.31460674157303\n",
      "Iterations: 12000. Loss: 0.797548770904541. Accuracy: 72.6762002042901\n",
      "Iterations: 12100. Loss: 1.5051548480987549. Accuracy: 72.85495403472932\n",
      "Iterations: 12200. Loss: 0.19910919666290283. Accuracy: 72.57405515832482\n",
      "Iterations: 12300. Loss: 0.1526978313922882. Accuracy: 73.4167517875383\n",
      "Iterations: 12400. Loss: 0.6748184561729431. Accuracy: 73.23799795709908\n",
      "Iterations: 12500. Loss: 0.03355148062109947. Accuracy: 72.9826353421859\n",
      "Iterations: 12600. Loss: 0.6780412793159485. Accuracy: 73.4167517875383\n",
      "Iterations: 12700. Loss: 1.0964689254760742. Accuracy: 73.23799795709908\n",
      "Iterations: 12800. Loss: 0.5165092945098877. Accuracy: 73.46782431052094\n",
      "Iterations: 12900. Loss: 0.39123672246932983. Accuracy: 72.95709908069459\n",
      "Iterations: 13000. Loss: 0.5549077391624451. Accuracy: 73.18692543411645\n",
      "Iterations: 13100. Loss: 0.4393734633922577. Accuracy: 73.90194075587334\n",
      "Iterations: 13200. Loss: 0.445050984621048. Accuracy: 74.38712972420838\n",
      "Iterations: 13300. Loss: 1.2565821409225464. Accuracy: 73.31460674157303\n",
      "Iterations: 13400. Loss: 0.17775601148605347. Accuracy: 73.28907048008172\n",
      "Iterations: 13500. Loss: 0.7408483624458313. Accuracy: 74.79570990806945\n",
      "Iterations: 13600. Loss: 0.9742429256439209. Accuracy: 74.94892747701736\n",
      "Iterations: 13700. Loss: 0.9616453647613525. Accuracy: 75.12768130745658\n",
      "Iterations: 13800. Loss: 1.0593675374984741. Accuracy: 74.97446373850869\n",
      "Iterations: 13900. Loss: 0.941028356552124. Accuracy: 75.15321756894791\n",
      "Iterations: 14000. Loss: 0.9852970838546753. Accuracy: 75.38304392236977\n",
      "Iterations: 14100. Loss: 1.0922399759292603. Accuracy: 75.66394279877426\n",
      "Iterations: 14200. Loss: 0.11680949479341507. Accuracy: 75.4341164453524\n",
      "Iterations: 14300. Loss: 0.38917115330696106. Accuracy: 75.07660878447395\n",
      "Iterations: 14400. Loss: 0.029236741364002228. Accuracy: 75.0\n",
      "Iterations: 14500. Loss: 1.4213087558746338. Accuracy: 74.97446373850869\n",
      "Iterations: 14600. Loss: 1.0298165082931519. Accuracy: 74.36159346271705\n",
      "Iterations: 14700. Loss: 0.9010128378868103. Accuracy: 74.48927477017365\n",
      "Iterations: 14800. Loss: 0.3270016312599182. Accuracy: 75.15321756894791\n",
      "Iterations: 14900. Loss: 0.7158080339431763. Accuracy: 75.35750766087845\n",
      "Iterations: 15000. Loss: 1.0812373161315918. Accuracy: 75.4341164453524\n",
      "Iterations: 15100. Loss: 0.5208777189254761. Accuracy: 74.41266598569969\n",
      "Iterations: 15200. Loss: 0.7944018840789795. Accuracy: 74.25944841675178\n",
      "Iterations: 15300. Loss: 0.8551047444343567. Accuracy: 74.48927477017365\n",
      "Iterations: 15400. Loss: 0.572523832321167. Accuracy: 74.38712972420838\n",
      "Iterations: 15500. Loss: 0.36463645100593567. Accuracy: 74.64249233912155\n",
      "Iterations: 15600. Loss: 1.1093106269836426. Accuracy: 75.22982635342186\n",
      "Iterations: 15700. Loss: 0.9159512519836426. Accuracy: 75.10214504596527\n",
      "Iterations: 15800. Loss: 0.6958714723587036. Accuracy: 73.97854954034729\n",
      "Iterations: 15900. Loss: 0.7286562919616699. Accuracy: 74.84678243105209\n",
      "Iterations: 16000. Loss: 0.703663170337677. Accuracy: 74.59141981613892\n",
      "Iterations: 16100. Loss: 0.24648717045783997. Accuracy: 74.74463738508682\n",
      "Iterations: 16200. Loss: 1.0683308839797974. Accuracy: 75.28089887640449\n",
      "Iterations: 16300. Loss: 1.227250099182129. Accuracy: 75.25536261491318\n",
      "Iterations: 16400. Loss: 0.5196169018745422. Accuracy: 75.40858018386108\n",
      "Iterations: 16500. Loss: 0.7549840211868286. Accuracy: 75.40858018386108\n",
      "Iterations: 16600. Loss: 0.2829248905181885. Accuracy: 75.30643513789582\n",
      "Iterations: 16700. Loss: 0.6060498952865601. Accuracy: 74.33605720122574\n",
      "Iterations: 16800. Loss: 1.499927282333374. Accuracy: 74.41266598569969\n",
      "Iterations: 16900. Loss: 0.42792317271232605. Accuracy: 75.40858018386108\n",
      "Iterations: 17000. Loss: 1.5227092504501343. Accuracy: 74.94892747701736\n",
      "Iterations: 17100. Loss: 0.4120158553123474. Accuracy: 74.94892747701736\n",
      "Iterations: 17200. Loss: 0.2118557244539261. Accuracy: 75.33197139938713\n",
      "Iterations: 17300. Loss: 0.7197006344795227. Accuracy: 75.30643513789582\n",
      "Iterations: 17400. Loss: 0.40229332447052. Accuracy: 75.81716036772217\n",
      "Iterations: 17500. Loss: 0.8236287832260132. Accuracy: 75.28089887640449\n",
      "Iterations: 17600. Loss: 0.2930440902709961. Accuracy: 75.28089887640449\n",
      "Iterations: 17700. Loss: 0.8068704605102539. Accuracy: 74.89785495403473\n",
      "Iterations: 17800. Loss: 0.019858237355947495. Accuracy: 75.28089887640449\n",
      "Iterations: 17900. Loss: 0.9891633987426758. Accuracy: 74.69356486210418\n",
      "Iterations: 18000. Loss: 0.8666377067565918. Accuracy: 74.74463738508682\n",
      "Iterations: 18100. Loss: 0.6433562636375427. Accuracy: 74.23391215526047\n",
      "Iterations: 18200. Loss: 1.1446635723114014. Accuracy: 74.92339121552605\n",
      "Iterations: 18300. Loss: 0.9320133924484253. Accuracy: 75.20429009193055\n",
      "Iterations: 18400. Loss: 1.3100183010101318. Accuracy: 75.07660878447395\n",
      "Iterations: 18500. Loss: 0.33449795842170715. Accuracy: 74.84678243105209\n",
      "Iterations: 18600. Loss: 0.3660447895526886. Accuracy: 75.40858018386108\n",
      "Iterations: 18700. Loss: 0.11093258857727051. Accuracy: 75.02553626149131\n",
      "Iterations: 18800. Loss: 0.5331114530563354. Accuracy: 75.02553626149131\n",
      "Iterations: 18900. Loss: 0.29741790890693665. Accuracy: 74.74463738508682\n",
      "Iterations: 19000. Loss: 0.7541583776473999. Accuracy: 75.0\n",
      "Iterations: 19100. Loss: 0.6142964363098145. Accuracy: 74.92339121552605\n",
      "Iterations: 19200. Loss: 1.2906099557876587. Accuracy: 74.54034729315629\n",
      "Iterations: 19300. Loss: 0.5065235495567322. Accuracy: 74.23391215526047\n",
      "Iterations: 19400. Loss: 0.8940532803535461. Accuracy: 75.07660878447395\n",
      "Iterations: 19500. Loss: 0.46322715282440186. Accuracy: 74.84678243105209\n",
      "Iterations: 19600. Loss: 1.2349696159362793. Accuracy: 74.89785495403473\n",
      "Iterations: 19700. Loss: 0.44159048795700073. Accuracy: 74.92339121552605\n",
      "Iterations: 19800. Loss: 0.7209970355033875. Accuracy: 75.56179775280899\n",
      "Iterations: 19900. Loss: 0.613360583782196. Accuracy: 75.02553626149131\n",
      "Iterations: 20000. Loss: 0.09284386783838272. Accuracy: 75.66394279877426\n",
      "Iterations: 20100. Loss: 0.38407447934150696. Accuracy: 75.07660878447395\n",
      "Iterations: 20200. Loss: 0.9616069197654724. Accuracy: 75.63840653728295\n",
      "Iterations: 20300. Loss: 0.5518704652786255. Accuracy: 75.35750766087845\n",
      "Iterations: 20400. Loss: 0.5985954999923706. Accuracy: 75.91930541368744\n",
      "Iterations: 20500. Loss: 0.8808714151382446. Accuracy: 76.04698672114402\n",
      "Iterations: 20600. Loss: 0.9953187704086304. Accuracy: 75.68947906026558\n",
      "Iterations: 20700. Loss: 0.3981662094593048. Accuracy: 75.56179775280899\n",
      "Iterations: 20800. Loss: 0.7852804064750671. Accuracy: 75.53626149131767\n",
      "Iterations: 20900. Loss: 0.10026675462722778. Accuracy: 76.20020429009193\n",
      "Iterations: 21000. Loss: 1.157555341720581. Accuracy: 76.25127681307457\n",
      "Iterations: 21100. Loss: 0.45910197496414185. Accuracy: 75.48518896833504\n",
      "Iterations: 21200. Loss: 1.1875414848327637. Accuracy: 75.76608784473953\n",
      "Iterations: 21300. Loss: 0.18244855105876923. Accuracy: 75.8682328907048\n",
      "Iterations: 21400. Loss: 0.2187185436487198. Accuracy: 75.94484167517875\n",
      "Iterations: 21500. Loss: 1.7241129875183105. Accuracy: 75.89376915219611\n",
      "Iterations: 21600. Loss: 0.25754785537719727. Accuracy: 75.79162410623084\n",
      "Iterations: 21700. Loss: 0.3849034309387207. Accuracy: 75.4341164453524\n",
      "Iterations: 21800. Loss: 1.6230239868164062. Accuracy: 75.89376915219611\n",
      "Iterations: 21900. Loss: 0.3236084580421448. Accuracy: 75.20429009193055\n",
      "Iterations: 22000. Loss: 0.5978561043739319. Accuracy: 75.0\n",
      "Iterations: 22100. Loss: 0.38896894454956055. Accuracy: 75.17875383043922\n",
      "Iterations: 22200. Loss: 0.7211515307426453. Accuracy: 75.61287027579162\n",
      "Iterations: 22300. Loss: 0.4066838026046753. Accuracy: 76.20020429009193\n",
      "Iterations: 22400. Loss: 0.6315872073173523. Accuracy: 76.27681307456588\n",
      "Iterations: 22500. Loss: 1.019608974456787. Accuracy: 76.07252298263535\n",
      "Iterations: 22600. Loss: 0.700052797794342. Accuracy: 76.35342185903984\n",
      "Iterations: 22700. Loss: 1.3968242406845093. Accuracy: 76.65985699693564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 22800. Loss: 0.3892107307910919. Accuracy: 76.35342185903984\n",
      "Iterations: 22900. Loss: 0.5325114130973816. Accuracy: 76.45556690500511\n",
      "Iterations: 23000. Loss: 0.6042300462722778. Accuracy: 76.32788559754852\n",
      "Iterations: 23100. Loss: 0.46884605288505554. Accuracy: 75.66394279877426\n",
      "Iterations: 23200. Loss: 0.1807669997215271. Accuracy: 75.8682328907048\n",
      "Iterations: 23300. Loss: 0.16387897729873657. Accuracy: 76.3023493360572\n",
      "Iterations: 23400. Loss: 0.5086198449134827. Accuracy: 75.53626149131767\n",
      "Iterations: 23500. Loss: 1.1658060550689697. Accuracy: 76.02145045965271\n",
      "Iterations: 23600. Loss: 1.6550219058990479. Accuracy: 76.40449438202248\n",
      "Iterations: 23700. Loss: 1.4432082176208496. Accuracy: 76.04698672114402\n",
      "Iterations: 23800. Loss: 0.4843158721923828. Accuracy: 75.66394279877426\n",
      "Iterations: 23900. Loss: 0.28227996826171875. Accuracy: 75.74055158324822\n",
      "Iterations: 24000. Loss: 0.3798034191131592. Accuracy: 76.3023493360572\n",
      "Iterations: 24100. Loss: 1.0071837902069092. Accuracy: 76.40449438202248\n",
      "Iterations: 24200. Loss: 0.5706714391708374. Accuracy: 75.61287027579162\n",
      "Iterations: 24300. Loss: 1.150303840637207. Accuracy: 76.65985699693564\n",
      "Iterations: 24400. Loss: 0.7545782327651978. Accuracy: 76.76200204290092\n",
      "Iterations: 24500. Loss: 1.385148286819458. Accuracy: 76.86414708886619\n",
      "Iterations: 24600. Loss: 0.29369109869003296. Accuracy: 76.8896833503575\n",
      "Iterations: 24700. Loss: 0.3053026497364044. Accuracy: 76.35342185903984\n",
      "Iterations: 24800. Loss: 1.0872547626495361. Accuracy: 76.20020429009193\n",
      "Iterations: 24900. Loss: 0.1725815087556839. Accuracy: 75.94484167517875\n",
      "Iterations: 25000. Loss: 0.7598336935043335. Accuracy: 75.84269662921348\n",
      "Iterations: 25100. Loss: 0.3767898678779602. Accuracy: 76.1491317671093\n",
      "Iterations: 25200. Loss: 0.9594472646713257. Accuracy: 76.43003064351379\n",
      "Iterations: 25300. Loss: 0.6692396998405457. Accuracy: 76.35342185903984\n",
      "Iterations: 25400. Loss: 0.847308337688446. Accuracy: 76.43003064351379\n",
      "Iterations: 25500. Loss: 0.1881197839975357. Accuracy: 75.89376915219611\n",
      "Iterations: 25600. Loss: 0.29202473163604736. Accuracy: 76.27681307456588\n",
      "Iterations: 25700. Loss: 0.5792403221130371. Accuracy: 76.20020429009193\n",
      "Iterations: 25800. Loss: 0.06900118291378021. Accuracy: 75.07660878447395\n",
      "Iterations: 25900. Loss: 0.4432987868785858. Accuracy: 75.58733401430031\n",
      "Iterations: 26000. Loss: 0.014097393490374088. Accuracy: 75.89376915219611\n",
      "Iterations: 26100. Loss: 0.15571236610412598. Accuracy: 75.63840653728295\n",
      "Iterations: 26200. Loss: 1.4175865650177002. Accuracy: 75.66394279877426\n",
      "Iterations: 26300. Loss: 0.1584058403968811. Accuracy: 76.45556690500511\n",
      "Iterations: 26400. Loss: 0.40971019864082336. Accuracy: 76.20020429009193\n",
      "Iterations: 26500. Loss: 1.3815569877624512. Accuracy: 75.63840653728295\n",
      "Iterations: 26600. Loss: 0.7364006638526917. Accuracy: 75.33197139938713\n",
      "Iterations: 26700. Loss: 0.13703547418117523. Accuracy: 75.35750766087845\n",
      "Iterations: 26800. Loss: 0.3344022333621979. Accuracy: 75.58733401430031\n",
      "Iterations: 26900. Loss: 0.4862063229084015. Accuracy: 75.58733401430031\n",
      "Iterations: 27000. Loss: 0.6422832012176514. Accuracy: 76.20020429009193\n",
      "Iterations: 27100. Loss: 1.0164382457733154. Accuracy: 77.04290091930541\n",
      "Iterations: 27200. Loss: 0.9699305295944214. Accuracy: 77.09397344228805\n",
      "Iterations: 27300. Loss: 0.5439571738243103. Accuracy: 77.29826353421859\n",
      "Iterations: 27400. Loss: 0.283564954996109. Accuracy: 77.40040858018386\n",
      "Iterations: 27500. Loss: 0.3874059021472931. Accuracy: 77.0173646578141\n",
      "Iterations: 27600. Loss: 1.0357199907302856. Accuracy: 77.0173646578141\n",
      "Iterations: 27700. Loss: 0.6113826632499695. Accuracy: 76.71092951991828\n",
      "Iterations: 27800. Loss: 0.3561381697654724. Accuracy: 76.83861082737488\n",
      "Iterations: 27900. Loss: 0.8570569157600403. Accuracy: 76.43003064351379\n",
      "Iterations: 28000. Loss: 0.04978813976049423. Accuracy: 76.94075587334014\n",
      "Iterations: 28100. Loss: 0.6778879761695862. Accuracy: 76.5832482124617\n",
      "Iterations: 28200. Loss: 0.623991072177887. Accuracy: 76.81307456588355\n",
      "Iterations: 28300. Loss: 0.25987276434898376. Accuracy: 77.0173646578141\n",
      "Iterations: 28400. Loss: 0.7696037292480469. Accuracy: 76.5832482124617\n",
      "Iterations: 28500. Loss: 0.15732644498348236. Accuracy: 76.68539325842697\n",
      "Iterations: 28600. Loss: 0.025281252339482307. Accuracy: 76.09805924412666\n",
      "Iterations: 28700. Loss: 0.44530731439590454. Accuracy: 76.99182839632277\n",
      "Iterations: 28800. Loss: 1.041921615600586. Accuracy: 76.99182839632277\n",
      "Iterations: 28900. Loss: 0.05937632545828819. Accuracy: 76.91521961184883\n",
      "Iterations: 29000. Loss: 0.09605725854635239. Accuracy: 76.48110316649642\n",
      "Iterations: 29100. Loss: 0.6685323119163513. Accuracy: 77.04290091930541\n",
      "Iterations: 29200. Loss: 0.8344810009002686. Accuracy: 77.50255362614914\n",
      "Iterations: 29300. Loss: 1.024949073791504. Accuracy: 77.52808988764045\n",
      "Iterations: 29400. Loss: 0.37886062264442444. Accuracy: 77.52808988764045\n",
      "Iterations: 29500. Loss: 0.27660080790519714. Accuracy: 77.47701736465781\n",
      "Iterations: 29600. Loss: 0.8996345400810242. Accuracy: 77.50255362614914\n",
      "Iterations: 29700. Loss: 0.5902923941612244. Accuracy: 77.91113381001021\n",
      "Iterations: 29800. Loss: 0.18038077652454376. Accuracy: 77.78345250255363\n",
      "Iterations: 29900. Loss: 0.3172886073589325. Accuracy: 77.68130745658836\n",
      "Iterations: 30000. Loss: 1.8044610023498535. Accuracy: 77.78345250255363\n",
      "Iterations: 30100. Loss: 0.7795006632804871. Accuracy: 77.65577119509703\n",
      "Iterations: 30200. Loss: 0.5003047585487366. Accuracy: 77.55362614913177\n",
      "Iterations: 30300. Loss: 0.0032989149913191795. Accuracy: 77.8855975485189\n",
      "Iterations: 30400. Loss: 0.9299249053001404. Accuracy: 77.55362614913177\n",
      "Iterations: 30500. Loss: 0.5943105816841125. Accuracy: 77.70684371807967\n",
      "Iterations: 30600. Loss: 0.5687360167503357. Accuracy: 77.98774259448416\n",
      "Iterations: 30700. Loss: 0.7079455852508545. Accuracy: 77.732379979571\n",
      "Iterations: 30800. Loss: 0.5808019638061523. Accuracy: 77.57916241062308\n",
      "Iterations: 30900. Loss: 0.7735959887504578. Accuracy: 77.27272727272727\n",
      "Iterations: 31000. Loss: 0.6490246653556824. Accuracy: 77.52808988764045\n",
      "Iterations: 31100. Loss: 1.3551223278045654. Accuracy: 77.37487231869254\n",
      "Iterations: 31200. Loss: 1.1396007537841797. Accuracy: 77.91113381001021\n",
      "Iterations: 31300. Loss: 1.1071813106536865. Accuracy: 77.57916241062308\n",
      "Iterations: 31400. Loss: 0.9844092726707458. Accuracy: 77.68130745658836\n",
      "Iterations: 31500. Loss: 0.486327201128006. Accuracy: 77.19611848825332\n",
      "Iterations: 31600. Loss: 0.4922558069229126. Accuracy: 77.47701736465781\n",
      "Iterations: 31700. Loss: 0.4576748013496399. Accuracy: 76.96629213483146\n",
      "Iterations: 31800. Loss: 0.3480339050292969. Accuracy: 77.17058222676201\n",
      "Iterations: 31900. Loss: 0.024891560897231102. Accuracy: 77.80898876404494\n",
      "Iterations: 32000. Loss: 0.7760902047157288. Accuracy: 77.91113381001021\n",
      "Iterations: 32100. Loss: 0.46567869186401367. Accuracy: 78.06435137895812\n",
      "Iterations: 32200. Loss: 0.5469970703125. Accuracy: 77.80898876404494\n",
      "Iterations: 32300. Loss: 0.36182984709739685. Accuracy: 77.52808988764045\n",
      "Iterations: 32400. Loss: 0.2625799775123596. Accuracy: 77.55362614913177\n",
      "Iterations: 32500. Loss: 0.47385072708129883. Accuracy: 77.7579162410623\n",
      "Iterations: 32600. Loss: 0.1270676851272583. Accuracy: 77.3237997957099\n",
      "Iterations: 32700. Loss: 0.4980977773666382. Accuracy: 77.42594484167518\n",
      "Iterations: 32800. Loss: 0.5315209627151489. Accuracy: 77.06843718079674\n",
      "Iterations: 32900. Loss: 0.06045496463775635. Accuracy: 77.70684371807967\n",
      "Iterations: 33000. Loss: 0.5630815029144287. Accuracy: 77.80898876404494\n",
      "Iterations: 33100. Loss: 0.8217347264289856. Accuracy: 77.732379979571\n",
      "Iterations: 33200. Loss: 0.0880054235458374. Accuracy: 77.50255362614914\n",
      "Iterations: 33300. Loss: 1.4046193361282349. Accuracy: 77.24719101123596\n",
      "Iterations: 33400. Loss: 0.42463913559913635. Accuracy: 77.14504596527068\n",
      "Iterations: 33500. Loss: 0.7138937711715698. Accuracy: 77.29826353421859\n",
      "Iterations: 33600. Loss: 0.09689507633447647. Accuracy: 77.47701736465781\n",
      "Iterations: 33700. Loss: 0.007066613994538784. Accuracy: 77.40040858018386\n",
      "Iterations: 33800. Loss: 0.3502194583415985. Accuracy: 76.94075587334014\n",
      "Iterations: 33900. Loss: 0.7906545996665955. Accuracy: 77.19611848825332\n",
      "Iterations: 34000. Loss: 0.421993225812912. Accuracy: 77.22165474974464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 34100. Loss: 0.6508767604827881. Accuracy: 77.47701736465781\n",
      "Iterations: 34200. Loss: 0.12920980155467987. Accuracy: 77.40040858018386\n",
      "Iterations: 34300. Loss: 0.11926945298910141. Accuracy: 77.7579162410623\n",
      "Iterations: 34400. Loss: 0.32661619782447815. Accuracy: 77.27272727272727\n",
      "Iterations: 34500. Loss: 0.15161071717739105. Accuracy: 76.94075587334014\n",
      "Iterations: 34600. Loss: 0.35220301151275635. Accuracy: 77.06843718079674\n",
      "Iterations: 34700. Loss: 0.23493121564388275. Accuracy: 77.24719101123596\n",
      "Iterations: 34800. Loss: 0.48224541544914246. Accuracy: 76.5832482124617\n",
      "Iterations: 34900. Loss: 0.43967947363853455. Accuracy: 76.71092951991828\n",
      "Iterations: 35000. Loss: 8.272782724816352e-05. Accuracy: 76.76200204290092\n",
      "Iterations: 35100. Loss: 0.1238052248954773. Accuracy: 77.27272727272727\n",
      "Iterations: 35200. Loss: 0.23099704086780548. Accuracy: 77.19611848825332\n",
      "Iterations: 35300. Loss: 0.04567185416817665. Accuracy: 77.57916241062308\n",
      "Iterations: 35400. Loss: 0.7615048289299011. Accuracy: 77.732379979571\n",
      "Iterations: 35500. Loss: 1.1809543371200562. Accuracy: 77.40040858018386\n",
      "Iterations: 35600. Loss: 0.7162725329399109. Accuracy: 77.55362614913177\n",
      "Iterations: 35700. Loss: 0.40831443667411804. Accuracy: 77.37487231869254\n",
      "Iterations: 35800. Loss: 0.3443485200405121. Accuracy: 77.68130745658836\n",
      "Iterations: 35900. Loss: 1.234364628791809. Accuracy: 77.70684371807967\n",
      "Iterations: 36000. Loss: 0.6344376802444458. Accuracy: 77.47701736465781\n",
      "Iterations: 36100. Loss: 0.4765531122684479. Accuracy: 77.80898876404494\n",
      "Iterations: 36200. Loss: 0.5932013988494873. Accuracy: 77.7579162410623\n",
      "Iterations: 36300. Loss: 0.37954825162887573. Accuracy: 77.91113381001021\n",
      "Iterations: 36400. Loss: 0.0707671195268631. Accuracy: 77.96220633299285\n",
      "Iterations: 36500. Loss: 0.43203532695770264. Accuracy: 77.93667007150154\n",
      "Iterations: 36600. Loss: 0.010433179326355457. Accuracy: 77.91113381001021\n",
      "Iterations: 36700. Loss: 0.8399808406829834. Accuracy: 78.0388151174668\n",
      "Iterations: 36800. Loss: 0.4086948335170746. Accuracy: 77.732379979571\n",
      "Iterations: 36900. Loss: 0.9528417587280273. Accuracy: 77.8855975485189\n",
      "Iterations: 37000. Loss: 0.40454599261283875. Accuracy: 77.83452502553627\n",
      "Iterations: 37100. Loss: 0.5020156502723694. Accuracy: 78.06435137895812\n",
      "Iterations: 37200. Loss: 1.42262864112854. Accuracy: 77.70684371807967\n",
      "Iterations: 37300. Loss: 1.1776618957519531. Accuracy: 77.60469867211441\n",
      "Iterations: 37400. Loss: 0.45081281661987305. Accuracy: 77.732379979571\n",
      "Iterations: 37500. Loss: 0.05095737800002098. Accuracy: 77.7579162410623\n",
      "Iterations: 37600. Loss: 0.014902809634804726. Accuracy: 77.50255362614914\n",
      "Iterations: 37700. Loss: 0.31692805886268616. Accuracy: 77.50255362614914\n",
      "Iterations: 37800. Loss: 0.47258085012435913. Accuracy: 77.60469867211441\n",
      "Iterations: 37900. Loss: 0.018349887803196907. Accuracy: 77.86006128702758\n",
      "Iterations: 38000. Loss: 0.5741850733757019. Accuracy: 77.96220633299285\n",
      "Iterations: 38100. Loss: 0.8050670623779297. Accuracy: 77.96220633299285\n",
      "Iterations: 38200. Loss: 0.39863625168800354. Accuracy: 78.14096016343207\n",
      "Iterations: 38300. Loss: 0.014367230236530304. Accuracy: 78.08988764044943\n",
      "Iterations: 38400. Loss: 0.25722256302833557. Accuracy: 77.83452502553627\n",
      "Iterations: 38500. Loss: 0.35395142436027527. Accuracy: 77.80898876404494\n",
      "Iterations: 38600. Loss: 0.6205273270606995. Accuracy: 78.06435137895812\n",
      "Iterations: 38700. Loss: 0.4747755825519562. Accuracy: 77.91113381001021\n",
      "Iterations: 38800. Loss: 0.5314617156982422. Accuracy: 77.52808988764045\n",
      "Iterations: 38900. Loss: 0.8927552700042725. Accuracy: 77.7579162410623\n",
      "Iterations: 39000. Loss: 0.2619142532348633. Accuracy: 77.63023493360572\n",
      "Iterations: 39100. Loss: 0.5075413584709167. Accuracy: 77.27272727272727\n",
      "Iterations: 39200. Loss: 0.7111849784851074. Accuracy: 77.78345250255363\n",
      "Iterations: 39300. Loss: 0.4932500720024109. Accuracy: 77.68130745658836\n",
      "Iterations: 39400. Loss: 0.2034280002117157. Accuracy: 77.70684371807967\n",
      "Iterations: 39500. Loss: 0.365592896938324. Accuracy: 77.732379979571\n",
      "Iterations: 39600. Loss: 1.6651127338409424. Accuracy: 77.93667007150154\n",
      "Iterations: 39700. Loss: 0.26933979988098145. Accuracy: 78.24310520939734\n",
      "Iterations: 39800. Loss: 0.7044371962547302. Accuracy: 77.91113381001021\n",
      "Iterations: 39900. Loss: 0.011781752109527588. Accuracy: 77.60469867211441\n",
      "Iterations: 40000. Loss: 0.08160672336816788. Accuracy: 77.96220633299285\n",
      "Iterations: 40100. Loss: 0.718504011631012. Accuracy: 78.14096016343207\n",
      "Iterations: 40200. Loss: 0.6356254816055298. Accuracy: 78.3197139938713\n",
      "Iterations: 40300. Loss: 0.7967195510864258. Accuracy: 78.3197139938713\n",
      "Iterations: 40400. Loss: 0.2664529085159302. Accuracy: 78.0388151174668\n",
      "Iterations: 40500. Loss: 0.061660222709178925. Accuracy: 78.11542390194076\n",
      "Iterations: 40600. Loss: 0.628143846988678. Accuracy: 77.57916241062308\n",
      "Iterations: 40700. Loss: 0.3961780071258545. Accuracy: 77.80898876404494\n",
      "Iterations: 40800. Loss: 0.5071783661842346. Accuracy: 77.80898876404494\n",
      "Iterations: 40900. Loss: 0.19442999362945557. Accuracy: 77.57916241062308\n",
      "Iterations: 41000. Loss: 0.14064067602157593. Accuracy: 77.57916241062308\n",
      "Iterations: 41100. Loss: 0.14050240814685822. Accuracy: 77.91113381001021\n",
      "Iterations: 41200. Loss: 0.05478209629654884. Accuracy: 77.50255362614914\n",
      "Iterations: 41300. Loss: 0.5175991058349609. Accuracy: 77.83452502553627\n",
      "Iterations: 41400. Loss: 0.04002959653735161. Accuracy: 77.52808988764045\n",
      "Iterations: 41500. Loss: 0.49523675441741943. Accuracy: 76.86414708886619\n",
      "Iterations: 41600. Loss: 0.007777409162372351. Accuracy: 77.80898876404494\n",
      "Iterations: 41700. Loss: 1.1897237300872803. Accuracy: 77.80898876404494\n",
      "Iterations: 41800. Loss: 0.563377857208252. Accuracy: 77.55362614913177\n",
      "Iterations: 41900. Loss: 0.529550313949585. Accuracy: 77.96220633299285\n",
      "Iterations: 42000. Loss: 0.6633098125457764. Accuracy: 77.732379979571\n",
      "Iterations: 42100. Loss: 0.01528361439704895. Accuracy: 77.732379979571\n",
      "Iterations: 42200. Loss: 0.4509454369544983. Accuracy: 77.68130745658836\n",
      "Iterations: 42300. Loss: 0.14582514762878418. Accuracy: 77.60469867211441\n",
      "Iterations: 42400. Loss: 1.129861831665039. Accuracy: 77.40040858018386\n",
      "Iterations: 42500. Loss: 1.7049345970153809. Accuracy: 77.34933605720123\n",
      "Iterations: 42600. Loss: 1.260338544845581. Accuracy: 77.70684371807967\n",
      "Iterations: 42700. Loss: 0.3620845079421997. Accuracy: 78.01327885597549\n",
      "Iterations: 42800. Loss: 1.856079339981079. Accuracy: 78.14096016343207\n",
      "Iterations: 42900. Loss: 0.6331592202186584. Accuracy: 78.88151174668029\n",
      "Iterations: 43000. Loss: 0.5607945322990417. Accuracy: 78.62614913176711\n",
      "Iterations: 43100. Loss: 0.3927195072174072. Accuracy: 78.75383043922369\n",
      "Iterations: 43200. Loss: 0.3452652394771576. Accuracy: 78.34525025536261\n",
      "Iterations: 43300. Loss: 0.5289804935455322. Accuracy: 77.91113381001021\n",
      "Iterations: 43400. Loss: 0.26845356822013855. Accuracy: 78.1664964249234\n",
      "Iterations: 43500. Loss: 0.09389287978410721. Accuracy: 77.65577119509703\n",
      "Iterations: 43600. Loss: 0.9781652092933655. Accuracy: 78.01327885597549\n",
      "Iterations: 43700. Loss: 0.8565444946289062. Accuracy: 77.93667007150154\n",
      "Iterations: 43800. Loss: 0.194291889667511. Accuracy: 77.68130745658836\n",
      "Iterations: 43900. Loss: 0.5441389083862305. Accuracy: 77.98774259448416\n",
      "Iterations: 44000. Loss: 0.16319146752357483. Accuracy: 78.06435137895812\n",
      "Iterations: 44100. Loss: 0.2731938660144806. Accuracy: 77.68130745658836\n",
      "Iterations: 44200. Loss: 0.08099314570426941. Accuracy: 77.86006128702758\n",
      "Iterations: 44300. Loss: 0.6642006635665894. Accuracy: 77.60469867211441\n",
      "Iterations: 44400. Loss: 0.003316618502140045. Accuracy: 78.26864147088867\n",
      "Iterations: 44500. Loss: 1.1108686923980713. Accuracy: 78.01327885597549\n",
      "Iterations: 44600. Loss: 0.24774423241615295. Accuracy: 78.06435137895812\n",
      "Iterations: 44700. Loss: 0.028076471760869026. Accuracy: 77.86006128702758\n",
      "Iterations: 44800. Loss: 0.29974666237831116. Accuracy: 78.52400408580183\n",
      "Iterations: 44900. Loss: 0.26444894075393677. Accuracy: 78.49846782431052\n",
      "Iterations: 45000. Loss: 0.5218403339385986. Accuracy: 78.6006128702758\n",
      "Iterations: 45100. Loss: 0.4085575342178345. Accuracy: 78.24310520939734\n",
      "Iterations: 45200. Loss: 0.9417815804481506. Accuracy: 78.37078651685393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 45300. Loss: 1.397005319595337. Accuracy: 78.4729315628192\n",
      "Iterations: 45400. Loss: 1.0767698287963867. Accuracy: 78.72829417773238\n",
      "Iterations: 45500. Loss: 0.3772626221179962. Accuracy: 78.75383043922369\n",
      "Iterations: 45600. Loss: 0.07551827281713486. Accuracy: 78.57507660878447\n",
      "Iterations: 45700. Loss: 0.1961425393819809. Accuracy: 78.24310520939734\n",
      "Iterations: 45800. Loss: 0.5706614851951599. Accuracy: 78.62614913176711\n",
      "Iterations: 45900. Loss: 0.06385918706655502. Accuracy: 78.70275791624107\n",
      "Iterations: 46000. Loss: 1.094172716140747. Accuracy: 78.83043922369765\n",
      "Iterations: 46100. Loss: 0.17372111976146698. Accuracy: 79.16241062308478\n",
      "Iterations: 46200. Loss: 0.7532579302787781. Accuracy: 79.11133810010215\n",
      "Iterations: 46300. Loss: 0.8604118824005127. Accuracy: 79.06026557711951\n",
      "Iterations: 46400. Loss: 0.0690145343542099. Accuracy: 78.65168539325843\n",
      "Iterations: 46500. Loss: 0.04409441351890564. Accuracy: 78.54954034729316\n",
      "Iterations: 46600. Loss: 0.7188194990158081. Accuracy: 78.49846782431052\n",
      "Iterations: 46700. Loss: 0.4061286449432373. Accuracy: 78.9070480081716\n",
      "Iterations: 46800. Loss: 0.8582392930984497. Accuracy: 78.75383043922369\n",
      "Iterations: 46900. Loss: 0.9361322522163391. Accuracy: 78.54954034729316\n",
      "Iterations: 47000. Loss: 0.29943081736564636. Accuracy: 78.65168539325843\n",
      "Iterations: 47100. Loss: 0.17013096809387207. Accuracy: 78.37078651685393\n",
      "Iterations: 47200. Loss: 1.4400815963745117. Accuracy: 78.44739530132789\n",
      "Iterations: 47300. Loss: 0.03426409140229225. Accuracy: 78.62614913176711\n",
      "Iterations: 47400. Loss: 0.10051216185092926. Accuracy: 78.70275791624107\n",
      "Iterations: 47500. Loss: 0.8619918823242188. Accuracy: 78.54954034729316\n",
      "Iterations: 47600. Loss: 0.4141117036342621. Accuracy: 78.88151174668029\n",
      "Iterations: 47700. Loss: 0.38146549463272095. Accuracy: 78.44739530132789\n",
      "Iterations: 47800. Loss: 0.44480934739112854. Accuracy: 78.39632277834525\n",
      "Iterations: 47900. Loss: 0.40427860617637634. Accuracy: 78.65168539325843\n",
      "Iterations: 48000. Loss: 0.47521448135375977. Accuracy: 78.67722165474974\n",
      "Iterations: 48100. Loss: 0.021509584039449692. Accuracy: 78.39632277834525\n",
      "Iterations: 48200. Loss: 0.25374189019203186. Accuracy: 78.52400408580183\n",
      "Iterations: 48300. Loss: 0.4946850538253784. Accuracy: 78.39632277834525\n",
      "Iterations: 48400. Loss: 1.1262686252593994. Accuracy: 78.39632277834525\n",
      "Iterations: 48500. Loss: 0.2448514997959137. Accuracy: 78.29417773237998\n",
      "Iterations: 48600. Loss: 0.24728241562843323. Accuracy: 78.49846782431052\n",
      "Iterations: 48700. Loss: 0.016935843974351883. Accuracy: 78.72829417773238\n",
      "Iterations: 48800. Loss: 0.5105267763137817. Accuracy: 78.70275791624107\n",
      "Iterations: 48900. Loss: 0.8698874711990356. Accuracy: 78.1664964249234\n",
      "Iterations: 49000. Loss: 0.5480296611785889. Accuracy: 78.24310520939734\n",
      "Iterations: 49100. Loss: 0.24202263355255127. Accuracy: 78.29417773237998\n",
      "Iterations: 49200. Loss: 0.815071165561676. Accuracy: 78.3197139938713\n",
      "Iterations: 49300. Loss: 0.929796040058136. Accuracy: 78.49846782431052\n",
      "Iterations: 49400. Loss: 0.22132524847984314. Accuracy: 78.26864147088867\n",
      "Iterations: 49500. Loss: 0.8645830154418945. Accuracy: 78.06435137895812\n",
      "Iterations: 49600. Loss: 0.763666033744812. Accuracy: 78.29417773237998\n",
      "Iterations: 49700. Loss: 1.639737606048584. Accuracy: 78.34525025536261\n",
      "Iterations: 49800. Loss: 0.5453839302062988. Accuracy: 78.44739530132789\n",
      "Iterations: 49900. Loss: 0.4756772518157959. Accuracy: 78.57507660878447\n",
      "Iterations: 50000. Loss: 0.14632514119148254. Accuracy: 78.44739530132789\n",
      "Iterations: 50100. Loss: 0.06362777203321457. Accuracy: 78.1920326864147\n",
      "Iterations: 50200. Loss: 0.2294739931821823. Accuracy: 78.14096016343207\n",
      "Iterations: 50300. Loss: 0.42045342922210693. Accuracy: 78.1920326864147\n",
      "Iterations: 50400. Loss: 0.03671758994460106. Accuracy: 78.11542390194076\n",
      "Iterations: 50500. Loss: 0.7442255020141602. Accuracy: 78.24310520939734\n",
      "Iterations: 50600. Loss: 0.39916184544563293. Accuracy: 78.21756894790603\n",
      "Iterations: 50700. Loss: 0.31336379051208496. Accuracy: 78.26864147088867\n",
      "Iterations: 50800. Loss: 0.5587632656097412. Accuracy: 78.21756894790603\n",
      "Iterations: 50900. Loss: 0.3364482820034027. Accuracy: 78.24310520939734\n",
      "Iterations: 51000. Loss: 0.7476564645767212. Accuracy: 78.44739530132789\n",
      "Iterations: 51100. Loss: 0.3517003059387207. Accuracy: 78.77936670071502\n",
      "Iterations: 51200. Loss: 0.34307777881622314. Accuracy: 78.14096016343207\n",
      "Iterations: 51300. Loss: 0.7006056308746338. Accuracy: 78.44739530132789\n",
      "Iterations: 51400. Loss: 0.013282270170748234. Accuracy: 78.06435137895812\n",
      "Iterations: 51500. Loss: 0.8341687321662903. Accuracy: 78.3197139938713\n",
      "Iterations: 51600. Loss: 0.5978430509567261. Accuracy: 78.4729315628192\n",
      "Iterations: 51700. Loss: 0.05335233733057976. Accuracy: 78.70275791624107\n",
      "Iterations: 51800. Loss: 1.5333514213562012. Accuracy: 78.95812053115424\n",
      "Iterations: 51900. Loss: 1.2376691102981567. Accuracy: 78.9070480081716\n",
      "Iterations: 52000. Loss: 0.7169813513755798. Accuracy: 78.65168539325843\n",
      "Iterations: 52100. Loss: 0.160817950963974. Accuracy: 78.98365679264556\n",
      "Iterations: 52200. Loss: 0.6989333033561707. Accuracy: 79.21348314606742\n",
      "Iterations: 52300. Loss: 0.16732171177864075. Accuracy: 79.08580183861083\n",
      "Iterations: 52400. Loss: 0.23663540184497833. Accuracy: 78.77936670071502\n",
      "Iterations: 52500. Loss: 0.0003178806509822607. Accuracy: 78.77936670071502\n",
      "Iterations: 52600. Loss: 0.02149931713938713. Accuracy: 78.85597548518896\n",
      "Iterations: 52700. Loss: 0.3872668743133545. Accuracy: 78.85597548518896\n",
      "Iterations: 52800. Loss: 0.08898373693227768. Accuracy: 78.85597548518896\n",
      "Iterations: 52900. Loss: 0.0038592161145061255. Accuracy: 78.77936670071502\n",
      "Iterations: 53000. Loss: 0.36677008867263794. Accuracy: 78.75383043922369\n",
      "Iterations: 53100. Loss: 0.006690126843750477. Accuracy: 78.80490296220633\n",
      "Iterations: 53200. Loss: 0.8799651861190796. Accuracy: 78.77936670071502\n",
      "Iterations: 53300. Loss: 0.04679528996348381. Accuracy: 78.67722165474974\n",
      "Iterations: 53400. Loss: 0.3791831135749817. Accuracy: 78.34525025536261\n",
      "Iterations: 53500. Loss: 0.23326368629932404. Accuracy: 78.57507660878447\n",
      "Iterations: 53600. Loss: 0.8369855880737305. Accuracy: 78.67722165474974\n",
      "Iterations: 53700. Loss: 0.05918443575501442. Accuracy: 78.72829417773238\n",
      "Iterations: 53800. Loss: 1.0897825956344604. Accuracy: 78.80490296220633\n",
      "Iterations: 53900. Loss: 0.03274133801460266. Accuracy: 78.77936670071502\n",
      "Iterations: 54000. Loss: 0.5124509334564209. Accuracy: 78.72829417773238\n",
      "Iterations: 54100. Loss: 0.06660564988851547. Accuracy: 78.67722165474974\n",
      "Iterations: 54200. Loss: 0.45716220140457153. Accuracy: 78.77936670071502\n",
      "Iterations: 54300. Loss: 0.29301732778549194. Accuracy: 78.62614913176711\n",
      "Iterations: 54400. Loss: 0.3679697513580322. Accuracy: 78.77936670071502\n",
      "Iterations: 54500. Loss: 0.8580620884895325. Accuracy: 78.4729315628192\n",
      "Iterations: 54600. Loss: 0.018607230857014656. Accuracy: 78.57507660878447\n",
      "Iterations: 54700. Loss: 0.030304307118058205. Accuracy: 78.54954034729316\n",
      "Iterations: 54800. Loss: 1.1605018377304077. Accuracy: 78.77936670071502\n",
      "Iterations: 54900. Loss: 1.4470442533493042. Accuracy: 78.95812053115424\n",
      "Iterations: 55000. Loss: 0.23444949090480804. Accuracy: 78.4729315628192\n",
      "Iterations: 55100. Loss: 0.4370497763156891. Accuracy: 78.67722165474974\n",
      "Iterations: 55200. Loss: 0.09805712848901749. Accuracy: 78.80490296220633\n",
      "Iterations: 55300. Loss: 0.7861264944076538. Accuracy: 78.93258426966293\n",
      "Iterations: 55400. Loss: 0.6744676232337952. Accuracy: 78.83043922369765\n",
      "Iterations: 55500. Loss: 0.3890683352947235. Accuracy: 78.93258426966293\n",
      "Iterations: 55600. Loss: 0.3323855698108673. Accuracy: 79.00919305413687\n",
      "Iterations: 55700. Loss: 0.611107587814331. Accuracy: 78.9070480081716\n",
      "Iterations: 55800. Loss: 1.0209572315216064. Accuracy: 78.85597548518896\n",
      "Iterations: 55900. Loss: 0.8921328783035278. Accuracy: 78.77936670071502\n",
      "Iterations: 56000. Loss: 0.30059078335762024. Accuracy: 78.9070480081716\n",
      "Iterations: 56100. Loss: 5.125986263010418e-06. Accuracy: 78.98365679264556\n",
      "Iterations: 56200. Loss: 0.8589801788330078. Accuracy: 78.80490296220633\n",
      "Iterations: 56300. Loss: 0.739508867263794. Accuracy: 78.49846782431052\n",
      "Iterations: 56400. Loss: 0.29529067873954773. Accuracy: 78.6006128702758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 56500. Loss: 0.627971351146698. Accuracy: 79.00919305413687\n",
      "Iterations: 56600. Loss: 0.5657660961151123. Accuracy: 78.77936670071502\n",
      "Iterations: 56700. Loss: 0.5492665767669678. Accuracy: 78.75383043922369\n",
      "Iterations: 56800. Loss: 0.9710679650306702. Accuracy: 78.57507660878447\n",
      "Iterations: 56900. Loss: 0.9073539972305298. Accuracy: 78.49846782431052\n",
      "Iterations: 57000. Loss: 1.0832033157348633. Accuracy: 78.57507660878447\n",
      "Iterations: 57100. Loss: 0.2338031679391861. Accuracy: 78.39632277834525\n",
      "Iterations: 57200. Loss: 0.09776128083467484. Accuracy: 78.4729315628192\n",
      "Iterations: 57300. Loss: 0.892398476600647. Accuracy: 78.77936670071502\n",
      "Iterations: 57400. Loss: 0.1207452043890953. Accuracy: 78.98365679264556\n",
      "Iterations: 57500. Loss: 0.11471226066350937. Accuracy: 78.62614913176711\n",
      "Iterations: 57600. Loss: 1.2504477500915527. Accuracy: 78.65168539325843\n",
      "Iterations: 57700. Loss: 0.646189272403717. Accuracy: 78.83043922369765\n",
      "Iterations: 57800. Loss: 0.11183533072471619. Accuracy: 78.42185903983656\n",
      "Iterations: 57900. Loss: 0.04734994098544121. Accuracy: 78.21756894790603\n",
      "Iterations: 58000. Loss: 0.7898244261741638. Accuracy: 78.24310520939734\n",
      "Iterations: 58100. Loss: 0.7570990920066833. Accuracy: 78.1920326864147\n",
      "Iterations: 58200. Loss: 1.1342240571975708. Accuracy: 78.34525025536261\n",
      "Iterations: 58300. Loss: 0.1804419904947281. Accuracy: 78.29417773237998\n",
      "Iterations: 58400. Loss: 0.14096179604530334. Accuracy: 79.00919305413687\n",
      "Iterations: 58500. Loss: 0.057058822363615036. Accuracy: 79.18794688457609\n",
      "Iterations: 58600. Loss: 1.080845594406128. Accuracy: 79.16241062308478\n",
      "Iterations: 58700. Loss: 0.9256231188774109. Accuracy: 79.21348314606742\n",
      "Iterations: 58800. Loss: 1.064232587814331. Accuracy: 79.08580183861083\n",
      "Iterations: 58900. Loss: 0.7371148467063904. Accuracy: 79.16241062308478\n",
      "Iterations: 59000. Loss: 0.3921021819114685. Accuracy: 79.06026557711951\n",
      "Iterations: 59100. Loss: 0.21858663856983185. Accuracy: 78.95812053115424\n",
      "Iterations: 59200. Loss: 0.9126962423324585. Accuracy: 79.06026557711951\n",
      "Iterations: 59300. Loss: 0.0036109976936131716. Accuracy: 79.29009193054137\n",
      "Iterations: 59400. Loss: 0.06776107847690582. Accuracy: 78.95812053115424\n",
      "Iterations: 59500. Loss: 0.21077489852905273. Accuracy: 78.85597548518896\n",
      "Iterations: 59600. Loss: 0.13084502518177032. Accuracy: 78.9070480081716\n",
      "Iterations: 59700. Loss: 1.074655532836914. Accuracy: 78.98365679264556\n",
      "Iterations: 59800. Loss: 0.8765566349029541. Accuracy: 79.08580183861083\n",
      "Iterations: 59900. Loss: 0.07179338485002518. Accuracy: 78.83043922369765\n",
      "Iterations: 60000. Loss: 0.08002965152263641. Accuracy: 78.98365679264556\n",
      "Iterations: 60100. Loss: 0.46209925413131714. Accuracy: 79.11133810010215\n",
      "Iterations: 60200. Loss: 1.1712841987609863. Accuracy: 78.93258426966293\n",
      "Iterations: 60300. Loss: 0.796295166015625. Accuracy: 78.93258426966293\n",
      "Iterations: 60400. Loss: 0.7513933181762695. Accuracy: 79.31562819203269\n",
      "Iterations: 60500. Loss: 0.3516080379486084. Accuracy: 79.21348314606742\n",
      "Iterations: 60600. Loss: 0.22946034371852875. Accuracy: 79.26455566905005\n",
      "Iterations: 60700. Loss: 0.2141822725534439. Accuracy: 79.57099080694586\n",
      "Iterations: 60800. Loss: 0.9114373326301575. Accuracy: 79.18794688457609\n",
      "Iterations: 60900. Loss: 0.023592934012413025. Accuracy: 79.13687436159346\n",
      "Iterations: 61000. Loss: 1.100975513458252. Accuracy: 79.6220633299285\n",
      "Iterations: 61100. Loss: 0.6707227826118469. Accuracy: 79.29009193054137\n",
      "Iterations: 61200. Loss: 0.15762920677661896. Accuracy: 78.95812053115424\n",
      "Iterations: 61300. Loss: 0.9161654114723206. Accuracy: 79.11133810010215\n",
      "Iterations: 61400. Loss: 0.4217721223831177. Accuracy: 79.29009193054137\n",
      "Iterations: 61500. Loss: 0.4662904739379883. Accuracy: 79.341164453524\n",
      "Iterations: 61600. Loss: 0.7704443335533142. Accuracy: 79.4688457609806\n",
      "Iterations: 61700. Loss: 0.549614667892456. Accuracy: 79.57099080694586\n",
      "Iterations: 61800. Loss: 0.7054924964904785. Accuracy: 79.7752808988764\n",
      "Iterations: 61900. Loss: 1.5959959030151367. Accuracy: 79.69867211440246\n",
      "Iterations: 62000. Loss: 0.297268271446228. Accuracy: 79.49438202247191\n",
      "Iterations: 62100. Loss: 0.3883204460144043. Accuracy: 79.31562819203269\n",
      "Iterations: 62200. Loss: 0.02562745101749897. Accuracy: 79.23901940755873\n",
      "Iterations: 62300. Loss: 0.5543627142906189. Accuracy: 79.341164453524\n",
      "Iterations: 62400. Loss: 0.6298442482948303. Accuracy: 79.36670071501533\n",
      "Iterations: 62500. Loss: 0.03198515251278877. Accuracy: 79.41777323799796\n",
      "Iterations: 62600. Loss: 0.5477646589279175. Accuracy: 79.29009193054137\n",
      "Iterations: 62700. Loss: 0.7805321216583252. Accuracy: 79.41777323799796\n",
      "Iterations: 62800. Loss: 0.09726711362600327. Accuracy: 79.36670071501533\n",
      "Iterations: 62900. Loss: 0.4907363951206207. Accuracy: 79.341164453524\n",
      "Iterations: 63000. Loss: 1.0977036952972412. Accuracy: 79.36670071501533\n",
      "Iterations: 63100. Loss: 0.015683520585298538. Accuracy: 79.26455566905005\n",
      "Iterations: 63200. Loss: 0.059515051543712616. Accuracy: 79.341164453524\n",
      "Iterations: 63300. Loss: 0.8181799650192261. Accuracy: 79.36670071501533\n",
      "Iterations: 63400. Loss: 0.36994826793670654. Accuracy: 79.341164453524\n",
      "Iterations: 63500. Loss: 0.46785372495651245. Accuracy: 79.41777323799796\n",
      "Iterations: 63600. Loss: 0.03201736509799957. Accuracy: 79.39223697650664\n",
      "Iterations: 63700. Loss: 0.034531883895397186. Accuracy: 79.31562819203269\n",
      "Iterations: 63800. Loss: 0.18517358601093292. Accuracy: 79.41777323799796\n",
      "Iterations: 63900. Loss: 0.27549365162849426. Accuracy: 79.41777323799796\n",
      "Iterations: 64000. Loss: 0.44060173630714417. Accuracy: 79.23901940755873\n",
      "Iterations: 64100. Loss: 0.2524975538253784. Accuracy: 79.21348314606742\n",
      "Iterations: 64200. Loss: 0.09168802946805954. Accuracy: 79.00919305413687\n",
      "Iterations: 64300. Loss: 0.302994042634964. Accuracy: 79.41777323799796\n",
      "Iterations: 64400. Loss: 0.6815589070320129. Accuracy: 79.39223697650664\n",
      "Iterations: 64500. Loss: 0.5219271183013916. Accuracy: 79.341164453524\n",
      "Iterations: 64600. Loss: 0.5157873034477234. Accuracy: 79.06026557711951\n",
      "Iterations: 64700. Loss: 0.17737621068954468. Accuracy: 79.00919305413687\n",
      "Iterations: 64800. Loss: 0.04160888493061066. Accuracy: 79.08580183861083\n",
      "Iterations: 64900. Loss: 0.16445539891719818. Accuracy: 79.31562819203269\n",
      "Iterations: 65000. Loss: 0.4355345368385315. Accuracy: 79.0347293156282\n",
      "Iterations: 65100. Loss: 0.6546881198883057. Accuracy: 78.83043922369765\n",
      "Iterations: 65200. Loss: 0.02779952809214592. Accuracy: 78.88151174668029\n",
      "Iterations: 65300. Loss: 1.2091295719146729. Accuracy: 79.00919305413687\n",
      "Iterations: 65400. Loss: 0.6333327293395996. Accuracy: 79.11133810010215\n",
      "Iterations: 65500. Loss: 0.6806476712226868. Accuracy: 79.11133810010215\n",
      "Iterations: 65600. Loss: 0.8593794107437134. Accuracy: 79.29009193054137\n",
      "Iterations: 65700. Loss: 1.2702572345733643. Accuracy: 79.26455566905005\n",
      "Iterations: 65800. Loss: 0.22824089229106903. Accuracy: 79.31562819203269\n",
      "Iterations: 65900. Loss: 0.23208516836166382. Accuracy: 78.77936670071502\n",
      "Iterations: 66000. Loss: 0.23309317231178284. Accuracy: 78.93258426966293\n",
      "Iterations: 66100. Loss: 0.3267100155353546. Accuracy: 78.88151174668029\n",
      "Iterations: 66200. Loss: 0.013230626471340656. Accuracy: 78.77936670071502\n",
      "Iterations: 66300. Loss: 0.6891800165176392. Accuracy: 78.57507660878447\n",
      "Iterations: 66400. Loss: 0.3119775652885437. Accuracy: 79.00919305413687\n",
      "Iterations: 66500. Loss: 0.000577402301132679. Accuracy: 79.00919305413687\n",
      "Iterations: 66600. Loss: 0.7635660767555237. Accuracy: 79.11133810010215\n",
      "Iterations: 66700. Loss: 1.9220094680786133. Accuracy: 78.93258426966293\n",
      "Iterations: 66800. Loss: 0.4167133867740631. Accuracy: 79.39223697650664\n",
      "Iterations: 66900. Loss: 0.2897575795650482. Accuracy: 79.00919305413687\n",
      "Iterations: 67000. Loss: 0.5463221669197083. Accuracy: 79.44330949948927\n",
      "Iterations: 67100. Loss: 0.8135631084442139. Accuracy: 78.95812053115424\n",
      "Iterations: 67200. Loss: 0.889076292514801. Accuracy: 79.57099080694586\n",
      "Iterations: 67300. Loss: 0.03127807751297951. Accuracy: 79.41777323799796\n",
      "Iterations: 67400. Loss: 0.04747375100851059. Accuracy: 79.4688457609806\n",
      "Iterations: 67500. Loss: 0.04830567166209221. Accuracy: 79.59652706843718\n",
      "Iterations: 67600. Loss: 0.11275408416986465. Accuracy: 79.54545454545455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 67700. Loss: 0.903321385383606. Accuracy: 79.41777323799796\n",
      "Iterations: 67800. Loss: 0.6091587543487549. Accuracy: 79.54545454545455\n",
      "Iterations: 67900. Loss: 0.35062333941459656. Accuracy: 79.64759959141982\n",
      "Iterations: 68000. Loss: 0.1939026117324829. Accuracy: 79.67313585291113\n",
      "Iterations: 68100. Loss: 0.22905077040195465. Accuracy: 79.67313585291113\n",
      "Iterations: 68200. Loss: 0.947113037109375. Accuracy: 79.69867211440246\n",
      "Iterations: 68300. Loss: 1.0327365398406982. Accuracy: 79.72420837589377\n",
      "Iterations: 68400. Loss: 0.10101097822189331. Accuracy: 79.67313585291113\n",
      "Iterations: 68500. Loss: 0.010985961183905602. Accuracy: 79.72420837589377\n",
      "Iterations: 68600. Loss: 0.6440916061401367. Accuracy: 79.80081716036773\n",
      "Iterations: 68700. Loss: 0.09878183156251907. Accuracy: 79.67313585291113\n",
      "Iterations: 68800. Loss: 0.4615565836429596. Accuracy: 79.57099080694586\n",
      "Iterations: 68900. Loss: 0.5988982319831848. Accuracy: 79.41777323799796\n",
      "Iterations: 69000. Loss: 0.2642790973186493. Accuracy: 79.31562819203269\n",
      "Iterations: 69100. Loss: 0.42799949645996094. Accuracy: 79.36670071501533\n",
      "Iterations: 69200. Loss: 0.30177319049835205. Accuracy: 79.44330949948927\n",
      "Iterations: 69300. Loss: 0.43074294924736023. Accuracy: 79.29009193054137\n",
      "Iterations: 69400. Loss: 0.06848101317882538. Accuracy: 79.341164453524\n",
      "Iterations: 69500. Loss: 0.8160887956619263. Accuracy: 79.36670071501533\n",
      "Iterations: 69600. Loss: 0.10180924087762833. Accuracy: 79.36670071501533\n",
      "Iterations: 69700. Loss: 0.13610464334487915. Accuracy: 79.54545454545455\n",
      "Iterations: 69800. Loss: 0.6290132999420166. Accuracy: 79.341164453524\n",
      "Iterations: 69900. Loss: 0.24106068909168243. Accuracy: 79.44330949948927\n",
      "Iterations: 70000. Loss: 0.48170650005340576. Accuracy: 79.29009193054137\n",
      "Iterations: 70100. Loss: 0.15297091007232666. Accuracy: 79.51991828396322\n",
      "Iterations: 70200. Loss: 0.029371263459324837. Accuracy: 79.39223697650664\n",
      "Iterations: 70300. Loss: 0.00798426941037178. Accuracy: 79.39223697650664\n",
      "Iterations: 70400. Loss: 1.45786452293396. Accuracy: 79.06026557711951\n",
      "Iterations: 70500. Loss: 0.6885501146316528. Accuracy: 79.6220633299285\n",
      "Iterations: 70600. Loss: 0.33868953585624695. Accuracy: 79.72420837589377\n",
      "Iterations: 70700. Loss: 0.10897521674633026. Accuracy: 79.74974463738509\n",
      "Iterations: 70800. Loss: 0.15800701081752777. Accuracy: 79.49438202247191\n",
      "Iterations: 70900. Loss: 0.7746368646621704. Accuracy: 79.72420837589377\n",
      "Iterations: 71000. Loss: 0.06137269735336304. Accuracy: 79.6220633299285\n",
      "Iterations: 71100. Loss: 0.5490640997886658. Accuracy: 79.80081716036773\n",
      "Iterations: 71200. Loss: 0.05201604962348938. Accuracy: 79.54545454545455\n",
      "Iterations: 71300. Loss: 0.8344464898109436. Accuracy: 79.6220633299285\n",
      "Iterations: 71400. Loss: 0.4284607768058777. Accuracy: 79.67313585291113\n",
      "Iterations: 71500. Loss: 0.11497306078672409. Accuracy: 79.72420837589377\n",
      "Iterations: 71600. Loss: 0.01319968607276678. Accuracy: 79.82635342185904\n",
      "Iterations: 71700. Loss: 0.19685114920139313. Accuracy: 79.54545454545455\n",
      "Iterations: 71800. Loss: 0.21580170094966888. Accuracy: 79.69867211440246\n",
      "Iterations: 71900. Loss: 0.387287974357605. Accuracy: 79.4688457609806\n",
      "Iterations: 72000. Loss: 0.21173091232776642. Accuracy: 79.41777323799796\n",
      "Iterations: 72100. Loss: 0.2435159534215927. Accuracy: 79.4688457609806\n",
      "Iterations: 72200. Loss: 1.0351659059524536. Accuracy: 79.4688457609806\n",
      "Iterations: 72300. Loss: 0.08987817168235779. Accuracy: 79.59652706843718\n",
      "Iterations: 72400. Loss: 0.7200959324836731. Accuracy: 79.97957099080695\n",
      "Iterations: 72500. Loss: 0.3828432857990265. Accuracy: 79.21348314606742\n",
      "Iterations: 72600. Loss: 0.6741912961006165. Accuracy: 79.82635342185904\n",
      "Iterations: 72700. Loss: 1.2090427875518799. Accuracy: 79.4688457609806\n",
      "Iterations: 72800. Loss: 0.09301669895648956. Accuracy: 79.0347293156282\n",
      "Iterations: 72900. Loss: 0.29821932315826416. Accuracy: 79.26455566905005\n",
      "Iterations: 73000. Loss: 0.7638108730316162. Accuracy: 79.59652706843718\n",
      "Iterations: 73100. Loss: 0.5508551597595215. Accuracy: 79.41777323799796\n",
      "Iterations: 73200. Loss: 1.559037446975708. Accuracy: 79.26455566905005\n",
      "Iterations: 73300. Loss: 0.48316696286201477. Accuracy: 79.21348314606742\n",
      "Iterations: 73400. Loss: 0.9772806167602539. Accuracy: 79.36670071501533\n",
      "Iterations: 73500. Loss: 0.14149683713912964. Accuracy: 79.23901940755873\n",
      "Iterations: 73600. Loss: 0.05703585222363472. Accuracy: 79.23901940755873\n",
      "Iterations: 73700. Loss: 0.1571449190378189. Accuracy: 79.23901940755873\n",
      "Iterations: 73800. Loss: 0.5402213931083679. Accuracy: 79.13687436159346\n",
      "Iterations: 73900. Loss: 0.19221238791942596. Accuracy: 79.0347293156282\n",
      "Iterations: 74000. Loss: 0.225237637758255. Accuracy: 79.49438202247191\n",
      "Iterations: 74100. Loss: 0.09618199616670609. Accuracy: 79.59652706843718\n",
      "Iterations: 74200. Loss: 0.07044653594493866. Accuracy: 80.08171603677222\n",
      "Iterations: 74300. Loss: 0.43822067975997925. Accuracy: 79.90296220633299\n",
      "Iterations: 74400. Loss: 0.018994346261024475. Accuracy: 80.0561797752809\n",
      "Iterations: 74500. Loss: 0.9102733135223389. Accuracy: 79.92849846782431\n",
      "Iterations: 74600. Loss: 0.11745110154151917. Accuracy: 79.80081716036773\n",
      "Iterations: 74700. Loss: 1.237540602684021. Accuracy: 79.69867211440246\n",
      "Iterations: 74800. Loss: 1.3359630107879639. Accuracy: 79.57099080694586\n",
      "Iterations: 74900. Loss: 0.5909322500228882. Accuracy: 79.54545454545455\n",
      "Iterations: 75000. Loss: 0.0006719953380525112. Accuracy: 79.87742594484168\n",
      "Iterations: 75100. Loss: 1.3508243560791016. Accuracy: 79.74974463738509\n",
      "Iterations: 75200. Loss: 0.4312652349472046. Accuracy: 79.90296220633299\n",
      "Iterations: 75300. Loss: 0.38102802634239197. Accuracy: 79.7752808988764\n",
      "Iterations: 75400. Loss: 0.004973065573722124. Accuracy: 79.49438202247191\n",
      "Iterations: 75500. Loss: 0.1432027965784073. Accuracy: 79.4688457609806\n",
      "Iterations: 75600. Loss: 0.4075757563114166. Accuracy: 79.29009193054137\n",
      "Iterations: 75700. Loss: 0.34209439158439636. Accuracy: 79.72420837589377\n",
      "Iterations: 75800. Loss: 0.004796546418219805. Accuracy: 79.87742594484168\n",
      "Iterations: 75900. Loss: 1.277888298034668. Accuracy: 79.72420837589377\n",
      "Iterations: 76000. Loss: 0.7573697566986084. Accuracy: 79.57099080694586\n",
      "Iterations: 76100. Loss: 0.9533620476722717. Accuracy: 79.69867211440246\n",
      "Iterations: 76200. Loss: 0.7564506530761719. Accuracy: 79.87742594484168\n",
      "Iterations: 76300. Loss: 0.1977846622467041. Accuracy: 79.74974463738509\n",
      "Iterations: 76400. Loss: 0.001057304092682898. Accuracy: 79.82635342185904\n",
      "Iterations: 76500. Loss: 0.7316493391990662. Accuracy: 79.74974463738509\n",
      "Iterations: 76600. Loss: 0.2429976761341095. Accuracy: 79.59652706843718\n",
      "Iterations: 76700. Loss: 0.7398197054862976. Accuracy: 79.87742594484168\n",
      "Iterations: 76800. Loss: 0.09479768574237823. Accuracy: 79.80081716036773\n",
      "Iterations: 76900. Loss: 1.0278418064117432. Accuracy: 79.87742594484168\n",
      "Iterations: 77000. Loss: 0.35382580757141113. Accuracy: 79.7752808988764\n",
      "Iterations: 77100. Loss: 1.3736780881881714. Accuracy: 79.87742594484168\n",
      "Iterations: 77200. Loss: 0.27932673692703247. Accuracy: 79.92849846782431\n",
      "Iterations: 77300. Loss: 1.2018829584121704. Accuracy: 80.1838610827375\n",
      "Iterations: 77400. Loss: 0.5682369470596313. Accuracy: 80.15832482124617\n",
      "Iterations: 77500. Loss: 0.9372066259384155. Accuracy: 80.13278855975486\n",
      "Iterations: 77600. Loss: 0.13801631331443787. Accuracy: 80.1838610827375\n",
      "Iterations: 77700. Loss: 0.3046214282512665. Accuracy: 80.13278855975486\n",
      "Iterations: 77800. Loss: 0.29652121663093567. Accuracy: 79.74974463738509\n",
      "Iterations: 77900. Loss: 0.06161348521709442. Accuracy: 79.87742594484168\n",
      "Iterations: 78000. Loss: 0.3897971510887146. Accuracy: 79.7752808988764\n",
      "Iterations: 78100. Loss: 1.4467675685882568. Accuracy: 79.69867211440246\n",
      "Iterations: 78200. Loss: 0.04124918580055237. Accuracy: 80.0561797752809\n",
      "Iterations: 78300. Loss: 1.8047504425048828. Accuracy: 79.87742594484168\n",
      "Iterations: 78400. Loss: 0.009537134319543839. Accuracy: 79.85188968335035\n",
      "Iterations: 78500. Loss: 0.6204960346221924. Accuracy: 79.82635342185904\n",
      "Iterations: 78600. Loss: 0.17323464155197144. Accuracy: 79.69867211440246\n",
      "Iterations: 78700. Loss: 1.4667184352874756. Accuracy: 79.7752808988764\n",
      "Iterations: 78800. Loss: 0.7795585989952087. Accuracy: 79.72420837589377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 78900. Loss: 0.069785937666893. Accuracy: 79.95403472931562\n",
      "Iterations: 79000. Loss: 0.04743032157421112. Accuracy: 79.97957099080695\n",
      "Iterations: 79100. Loss: 0.5923871397972107. Accuracy: 79.90296220633299\n",
      "Iterations: 79200. Loss: 0.6699829697608948. Accuracy: 79.92849846782431\n",
      "Iterations: 79300. Loss: 0.6128202676773071. Accuracy: 79.72420837589377\n",
      "Iterations: 79400. Loss: 0.4848283529281616. Accuracy: 79.7752808988764\n",
      "Iterations: 79500. Loss: 0.4096032679080963. Accuracy: 80.08171603677222\n",
      "Iterations: 79600. Loss: 0.5159483551979065. Accuracy: 79.92849846782431\n",
      "Iterations: 79700. Loss: 0.6278679370880127. Accuracy: 79.80081716036773\n",
      "Iterations: 79800. Loss: 0.5300508737564087. Accuracy: 79.7752808988764\n",
      "Iterations: 79900. Loss: 0.5431957244873047. Accuracy: 79.87742594484168\n",
      "Iterations: 80000. Loss: 0.35971346497535706. Accuracy: 80.03064351378958\n",
      "Iterations: 80100. Loss: 0.513616144657135. Accuracy: 79.97957099080695\n",
      "Iterations: 80200. Loss: 1.6058317422866821. Accuracy: 79.64759959141982\n",
      "Iterations: 80300. Loss: 0.2969415485858917. Accuracy: 79.57099080694586\n",
      "Iterations: 80400. Loss: 0.501131534576416. Accuracy: 79.6220633299285\n",
      "Iterations: 80500. Loss: 0.24208121001720428. Accuracy: 79.59652706843718\n",
      "Iterations: 80600. Loss: 0.0652288943529129. Accuracy: 79.6220633299285\n",
      "Iterations: 80700. Loss: 0.05661632865667343. Accuracy: 79.67313585291113\n",
      "Iterations: 80800. Loss: 0.03426605090498924. Accuracy: 79.41777323799796\n",
      "Iterations: 80900. Loss: 0.6621516942977905. Accuracy: 79.36670071501533\n",
      "Iterations: 81000. Loss: 0.25693824887275696. Accuracy: 79.54545454545455\n",
      "Iterations: 81100. Loss: 0.4757854640483856. Accuracy: 79.6220633299285\n",
      "Iterations: 81200. Loss: 0.946312427520752. Accuracy: 79.82635342185904\n",
      "Iterations: 81300. Loss: 0.11715956032276154. Accuracy: 79.74974463738509\n",
      "Iterations: 81400. Loss: 0.36813732981681824. Accuracy: 79.80081716036773\n",
      "Iterations: 81500. Loss: 1.3871939182281494. Accuracy: 79.7752808988764\n",
      "Iterations: 81600. Loss: 0.7071899175643921. Accuracy: 79.51991828396322\n",
      "Iterations: 81700. Loss: 1.3690423965454102. Accuracy: 79.36670071501533\n",
      "Iterations: 81800. Loss: 0.46865373849868774. Accuracy: 79.64759959141982\n",
      "Iterations: 81900. Loss: 0.8858430981636047. Accuracy: 79.29009193054137\n",
      "Iterations: 82000. Loss: 0.6771133542060852. Accuracy: 79.49438202247191\n",
      "Iterations: 82100. Loss: 0.4225776195526123. Accuracy: 79.67313585291113\n",
      "Iterations: 82200. Loss: 0.09508931636810303. Accuracy: 79.7752808988764\n",
      "Iterations: 82300. Loss: 0.08336557447910309. Accuracy: 79.82635342185904\n",
      "Iterations: 82400. Loss: 0.43597131967544556. Accuracy: 79.95403472931562\n",
      "Iterations: 82500. Loss: 0.4872143268585205. Accuracy: 79.82635342185904\n",
      "Iterations: 82600. Loss: 0.3801322877407074. Accuracy: 79.80081716036773\n",
      "Iterations: 82700. Loss: 0.6377503871917725. Accuracy: 79.87742594484168\n",
      "Iterations: 82800. Loss: 1.1225121021270752. Accuracy: 79.72420837589377\n",
      "Iterations: 82900. Loss: 0.06600075960159302. Accuracy: 80.00510725229826\n",
      "Iterations: 83000. Loss: 0.38365018367767334. Accuracy: 79.92849846782431\n",
      "Iterations: 83100. Loss: 0.4628429412841797. Accuracy: 79.92849846782431\n",
      "Iterations: 83200. Loss: 0.06645630300045013. Accuracy: 79.92849846782431\n",
      "Iterations: 83300. Loss: 0.009986319579184055. Accuracy: 80.00510725229826\n",
      "Iterations: 83400. Loss: 0.1791311502456665. Accuracy: 80.13278855975486\n",
      "Iterations: 83500. Loss: 1.14639151096344. Accuracy: 80.13278855975486\n",
      "Iterations: 83600. Loss: 0.5475317239761353. Accuracy: 80.26046986721144\n",
      "Iterations: 83700. Loss: 1.4326555728912354. Accuracy: 80.2093973442288\n",
      "Iterations: 83800. Loss: 1.540551781654358. Accuracy: 80.33707865168539\n",
      "Iterations: 83900. Loss: 0.4482385516166687. Accuracy: 80.26046986721144\n",
      "Iterations: 84000. Loss: 0.03441832587122917. Accuracy: 80.28600612870275\n",
      "Iterations: 84100. Loss: 0.04710375890135765. Accuracy: 80.28600612870275\n",
      "Iterations: 84200. Loss: 0.13271552324295044. Accuracy: 80.13278855975486\n",
      "Iterations: 84300. Loss: 0.47316810488700867. Accuracy: 80.13278855975486\n",
      "Iterations: 84400. Loss: 0.13623011112213135. Accuracy: 80.08171603677222\n",
      "Iterations: 84500. Loss: 0.350305438041687. Accuracy: 79.97957099080695\n",
      "Iterations: 84600. Loss: 0.08657727390527725. Accuracy: 79.95403472931562\n",
      "Iterations: 84700. Loss: 0.07885581254959106. Accuracy: 80.10725229826353\n",
      "Iterations: 84800. Loss: 0.06212088093161583. Accuracy: 79.95403472931562\n",
      "Iterations: 84900. Loss: 0.3888564705848694. Accuracy: 79.95403472931562\n",
      "Iterations: 85000. Loss: 1.3759043216705322. Accuracy: 80.0561797752809\n",
      "Iterations: 85100. Loss: 0.11711332947015762. Accuracy: 79.97957099080695\n",
      "Iterations: 85200. Loss: 0.45119965076446533. Accuracy: 80.03064351378958\n",
      "Iterations: 85300. Loss: 0.0068067582324147224. Accuracy: 79.92849846782431\n",
      "Iterations: 85400. Loss: 0.2517867982387543. Accuracy: 80.03064351378958\n",
      "Iterations: 85500. Loss: 0.01582280918955803. Accuracy: 80.00510725229826\n",
      "Iterations: 85600. Loss: 0.5079656839370728. Accuracy: 79.87742594484168\n",
      "Iterations: 85700. Loss: 1.2063462734222412. Accuracy: 80.10725229826353\n",
      "Iterations: 85800. Loss: 0.15668943524360657. Accuracy: 80.26046986721144\n",
      "Iterations: 85900. Loss: 0.6971897482872009. Accuracy: 80.23493360572012\n",
      "Iterations: 86000. Loss: 0.24355997145175934. Accuracy: 79.92849846782431\n",
      "Iterations: 86100. Loss: 0.20109213888645172. Accuracy: 79.85188968335035\n",
      "Iterations: 86200. Loss: 0.1549876630306244. Accuracy: 80.15832482124617\n",
      "Iterations: 86300. Loss: 0.3160865008831024. Accuracy: 80.2093973442288\n",
      "Iterations: 86400. Loss: 0.2498197853565216. Accuracy: 80.31154239019408\n",
      "Iterations: 86500. Loss: 0.516441822052002. Accuracy: 80.00510725229826\n",
      "Iterations: 86600. Loss: 0.3475896418094635. Accuracy: 80.33707865168539\n",
      "Iterations: 86700. Loss: 0.21827426552772522. Accuracy: 80.15832482124617\n",
      "Iterations: 86800. Loss: 0.2912500500679016. Accuracy: 80.15832482124617\n",
      "Iterations: 86900. Loss: 0.03098745457828045. Accuracy: 80.0561797752809\n",
      "Iterations: 87000. Loss: 0.40008673071861267. Accuracy: 80.26046986721144\n",
      "Iterations: 87100. Loss: 0.42224380373954773. Accuracy: 80.10725229826353\n",
      "Iterations: 87200. Loss: 0.006294307764619589. Accuracy: 80.31154239019408\n",
      "Iterations: 87300. Loss: 1.1500805616378784. Accuracy: 80.23493360572012\n",
      "Iterations: 87400. Loss: 1.113770604133606. Accuracy: 80.26046986721144\n",
      "Iterations: 87500. Loss: 0.025722259655594826. Accuracy: 80.28600612870275\n",
      "Iterations: 87600. Loss: 0.01236616913229227. Accuracy: 79.82635342185904\n",
      "Iterations: 87700. Loss: 0.034576449543237686. Accuracy: 80.03064351378958\n",
      "Iterations: 87800. Loss: 0.1730407327413559. Accuracy: 79.82635342185904\n",
      "Iterations: 87900. Loss: 0.5738794803619385. Accuracy: 79.87742594484168\n",
      "Iterations: 88000. Loss: 0.5347484946250916. Accuracy: 80.0561797752809\n",
      "Iterations: 88100. Loss: 0.14958210289478302. Accuracy: 80.13278855975486\n",
      "Iterations: 88200. Loss: 0.0032342765480279922. Accuracy: 80.03064351378958\n",
      "Iterations: 88300. Loss: 0.03372357040643692. Accuracy: 80.15832482124617\n",
      "Iterations: 88400. Loss: 0.1606142222881317. Accuracy: 79.87742594484168\n",
      "Iterations: 88500. Loss: 0.05835229530930519. Accuracy: 79.49438202247191\n",
      "Iterations: 88600. Loss: 0.5643899440765381. Accuracy: 80.08171603677222\n",
      "Iterations: 88700. Loss: 0.7294761538505554. Accuracy: 80.1838610827375\n",
      "Iterations: 88800. Loss: 0.3423636257648468. Accuracy: 79.82635342185904\n",
      "Iterations: 88900. Loss: 0.014944031834602356. Accuracy: 79.97957099080695\n",
      "Iterations: 89000. Loss: 0.11798519641160965. Accuracy: 79.85188968335035\n",
      "Iterations: 89100. Loss: 0.6824706196784973. Accuracy: 79.7752808988764\n",
      "Iterations: 89200. Loss: 0.036403488367795944. Accuracy: 79.72420837589377\n",
      "Iterations: 89300. Loss: 0.0013940150383859873. Accuracy: 79.57099080694586\n",
      "Iterations: 89400. Loss: 0.007889656350016594. Accuracy: 79.57099080694586\n",
      "Iterations: 89500. Loss: 0.5995882749557495. Accuracy: 79.7752808988764\n",
      "Iterations: 89600. Loss: 1.9614858627319336. Accuracy: 79.6220633299285\n",
      "Iterations: 89700. Loss: 0.6399927735328674. Accuracy: 80.0561797752809\n",
      "Iterations: 89800. Loss: 1.1572582721710205. Accuracy: 80.1838610827375\n",
      "Iterations: 89900. Loss: 0.13929212093353271. Accuracy: 80.59244126659857\n",
      "Iterations: 90000. Loss: 0.37852299213409424. Accuracy: 80.36261491317671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 90100. Loss: 0.1501089632511139. Accuracy: 80.43922369765066\n",
      "Iterations: 90200. Loss: 0.6971719264984131. Accuracy: 80.15832482124617\n",
      "Iterations: 90300. Loss: 0.007646576501429081. Accuracy: 80.1838610827375\n",
      "Iterations: 90400. Loss: 0.10152721405029297. Accuracy: 80.15832482124617\n",
      "Iterations: 90500. Loss: 0.28267908096313477. Accuracy: 80.13278855975486\n",
      "Iterations: 90600. Loss: 0.0024097710847854614. Accuracy: 80.26046986721144\n",
      "Iterations: 90700. Loss: 0.1164155900478363. Accuracy: 80.28600612870275\n",
      "Iterations: 90800. Loss: 0.08662788569927216. Accuracy: 79.82635342185904\n",
      "Iterations: 90900. Loss: 0.5297797322273254. Accuracy: 80.15832482124617\n",
      "Iterations: 91000. Loss: 0.39254483580589294. Accuracy: 79.95403472931562\n",
      "Iterations: 91100. Loss: 0.21599853038787842. Accuracy: 79.97957099080695\n",
      "Iterations: 91200. Loss: 0.07648103684186935. Accuracy: 79.90296220633299\n",
      "Iterations: 91300. Loss: 0.10194629430770874. Accuracy: 79.82635342185904\n",
      "Iterations: 91400. Loss: 0.07263980060815811. Accuracy: 80.36261491317671\n",
      "Iterations: 91500. Loss: 0.45378780364990234. Accuracy: 80.26046986721144\n",
      "Iterations: 91600. Loss: 0.041650280356407166. Accuracy: 79.95403472931562\n",
      "Iterations: 91700. Loss: 0.02570936270058155. Accuracy: 80.15832482124617\n",
      "Iterations: 91800. Loss: 0.19819453358650208. Accuracy: 80.2093973442288\n",
      "Iterations: 91900. Loss: 0.4991028308868408. Accuracy: 80.26046986721144\n",
      "Iterations: 92000. Loss: 0.9243761897087097. Accuracy: 80.51583248212462\n",
      "Iterations: 92100. Loss: 0.43924736976623535. Accuracy: 80.08171603677222\n",
      "Iterations: 92200. Loss: 0.8378066420555115. Accuracy: 80.10725229826353\n",
      "Iterations: 92300. Loss: 0.553449273109436. Accuracy: 80.33707865168539\n",
      "Iterations: 92400. Loss: 0.0007956438348628581. Accuracy: 80.46475995914199\n",
      "Iterations: 92500. Loss: 0.8542912602424622. Accuracy: 79.92849846782431\n",
      "Iterations: 92600. Loss: 0.2409227043390274. Accuracy: 80.46475995914199\n",
      "Iterations: 92700. Loss: 0.00472678430378437. Accuracy: 80.2093973442288\n",
      "Iterations: 92800. Loss: 0.4480343163013458. Accuracy: 80.41368743615935\n",
      "Iterations: 92900. Loss: 0.014496599324047565. Accuracy: 80.46475995914199\n",
      "Iterations: 93000. Loss: 0.38750842213630676. Accuracy: 80.56690500510726\n",
      "Iterations: 93100. Loss: 0.6382911205291748. Accuracy: 80.51583248212462\n",
      "Iterations: 93200. Loss: 0.22841404378414154. Accuracy: 80.43922369765066\n",
      "Iterations: 93300. Loss: 0.517676591873169. Accuracy: 80.56690500510726\n",
      "Iterations: 93400. Loss: 0.225203275680542. Accuracy: 80.54136874361593\n",
      "Iterations: 93500. Loss: 9.30981186684221e-05. Accuracy: 80.43922369765066\n",
      "Iterations: 93600. Loss: 0.6143456101417542. Accuracy: 80.33707865168539\n",
      "Iterations: 93700. Loss: 0.7666279077529907. Accuracy: 80.36261491317671\n",
      "Iterations: 93800. Loss: 4.768370445162873e-07. Accuracy: 80.56690500510726\n",
      "Iterations: 93900. Loss: 0.5684900283813477. Accuracy: 80.4902962206333\n",
      "Iterations: 94000. Loss: 0.034437328577041626. Accuracy: 80.38815117466802\n",
      "Iterations: 94100. Loss: 0.4504966735839844. Accuracy: 80.43922369765066\n",
      "Iterations: 94200. Loss: 0.3064621388912201. Accuracy: 80.46475995914199\n",
      "Iterations: 94300. Loss: 0.31430584192276. Accuracy: 80.36261491317671\n",
      "Iterations: 94400. Loss: 0.4906347393989563. Accuracy: 80.46475995914199\n",
      "Iterations: 94500. Loss: 0.12728247046470642. Accuracy: 80.54136874361593\n",
      "Iterations: 94600. Loss: 0.7524391412734985. Accuracy: 80.51583248212462\n",
      "Iterations: 94700. Loss: 0.3956804573535919. Accuracy: 80.51583248212462\n",
      "Iterations: 94800. Loss: 0.7121070027351379. Accuracy: 80.23493360572012\n",
      "Iterations: 94900. Loss: 0.4130580425262451. Accuracy: 80.31154239019408\n",
      "Iterations: 95000. Loss: 0.4339772164821625. Accuracy: 80.13278855975486\n",
      "Iterations: 95100. Loss: 0.11602567136287689. Accuracy: 80.31154239019408\n",
      "Iterations: 95200. Loss: 0.2024097740650177. Accuracy: 80.46475995914199\n",
      "Iterations: 95300. Loss: 1.2224878072738647. Accuracy: 80.1838610827375\n",
      "Iterations: 95400. Loss: 0.07452934980392456. Accuracy: 80.10725229826353\n",
      "Iterations: 95500. Loss: 0.2255208045244217. Accuracy: 80.1838610827375\n",
      "Iterations: 95600. Loss: 0.18086528778076172. Accuracy: 80.43922369765066\n",
      "Iterations: 95700. Loss: 0.9572071433067322. Accuracy: 80.23493360572012\n",
      "Iterations: 95800. Loss: 0.009682241827249527. Accuracy: 80.08171603677222\n",
      "Iterations: 95900. Loss: 0.025468602776527405. Accuracy: 80.03064351378958\n",
      "Iterations: 96000. Loss: 0.009582593105733395. Accuracy: 80.10725229826353\n",
      "Iterations: 96100. Loss: 0.0029490573797374964. Accuracy: 80.23493360572012\n",
      "Iterations: 96200. Loss: 0.2601945698261261. Accuracy: 80.08171603677222\n",
      "Iterations: 96300. Loss: 0.47989964485168457. Accuracy: 80.10725229826353\n",
      "Iterations: 96400. Loss: 0.25728079676628113. Accuracy: 79.95403472931562\n",
      "Iterations: 96500. Loss: 1.5740901231765747. Accuracy: 80.00510725229826\n",
      "Iterations: 96600. Loss: 0.7248955965042114. Accuracy: 80.00510725229826\n",
      "Iterations: 96700. Loss: 0.16423986852169037. Accuracy: 79.97957099080695\n",
      "Iterations: 96800. Loss: 0.6298694014549255. Accuracy: 79.90296220633299\n",
      "Iterations: 96900. Loss: 0.05545967072248459. Accuracy: 80.33707865168539\n",
      "Iterations: 97000. Loss: 0.37284955382347107. Accuracy: 80.31154239019408\n",
      "Iterations: 97100. Loss: 0.49544858932495117. Accuracy: 80.10725229826353\n",
      "Iterations: 97200. Loss: 0.6142135858535767. Accuracy: 80.03064351378958\n",
      "Iterations: 97300. Loss: 0.23574219644069672. Accuracy: 80.0561797752809\n",
      "Iterations: 97400. Loss: 0.07754470407962799. Accuracy: 80.23493360572012\n",
      "Iterations: 97500. Loss: 1.5902960300445557. Accuracy: 80.08171603677222\n",
      "Iterations: 97600. Loss: 2.042332887649536. Accuracy: 79.82635342185904\n",
      "Iterations: 97700. Loss: 0.4602143168449402. Accuracy: 80.0561797752809\n",
      "Iterations: 97800. Loss: 0.29137101769447327. Accuracy: 80.23493360572012\n",
      "Iterations: 97900. Loss: 0.036259908229112625. Accuracy: 80.0561797752809\n",
      "Iterations: 98000. Loss: 0.7916404008865356. Accuracy: 80.23493360572012\n",
      "Iterations: 98100. Loss: 0.9777674674987793. Accuracy: 80.13278855975486\n",
      "Iterations: 98200. Loss: 0.6772511005401611. Accuracy: 79.85188968335035\n",
      "Iterations: 98300. Loss: 0.30329203605651855. Accuracy: 80.26046986721144\n",
      "Iterations: 98400. Loss: 2.2031402587890625. Accuracy: 80.13278855975486\n",
      "Iterations: 98500. Loss: 0.25652918219566345. Accuracy: 80.23493360572012\n",
      "Iterations: 98600. Loss: 0.6653082966804504. Accuracy: 80.15832482124617\n",
      "Iterations: 98700. Loss: 0.08417639881372452. Accuracy: 80.46475995914199\n",
      "Iterations: 98800. Loss: 0.07231327891349792. Accuracy: 80.6435137895812\n",
      "Iterations: 98900. Loss: 0.029175611212849617. Accuracy: 80.4902962206333\n",
      "Iterations: 99000. Loss: 0.21355430781841278. Accuracy: 80.33707865168539\n",
      "Iterations: 99100. Loss: 0.17356771230697632. Accuracy: 80.36261491317671\n",
      "Iterations: 99200. Loss: 0.10607066750526428. Accuracy: 80.6435137895812\n",
      "Iterations: 99300. Loss: 0.35297948122024536. Accuracy: 80.61797752808988\n",
      "Iterations: 99400. Loss: 1.2539093494415283. Accuracy: 80.43922369765066\n",
      "Iterations: 99500. Loss: 0.2679571807384491. Accuracy: 80.56690500510726\n",
      "Iterations: 99600. Loss: 0.0527723990380764. Accuracy: 80.54136874361593\n",
      "Iterations: 99700. Loss: 0.05855918675661087. Accuracy: 80.61797752808988\n",
      "Iterations: 99800. Loss: 0.34598636627197266. Accuracy: 80.59244126659857\n",
      "Iterations: 99900. Loss: 0.08213339745998383. Accuracy: 80.33707865168539\n",
      "Iterations: 100000. Loss: 0.44219839572906494. Accuracy: 80.23493360572012\n",
      "Iterations: 100100. Loss: 0.8461531400680542. Accuracy: 80.36261491317671\n",
      "Iterations: 100200. Loss: 0.1346450299024582. Accuracy: 80.2093973442288\n",
      "Iterations: 100300. Loss: 0.10737480223178864. Accuracy: 80.15832482124617\n",
      "Iterations: 100400. Loss: 1.3441436290740967. Accuracy: 80.28600612870275\n",
      "Iterations: 100500. Loss: 0.08757194131612778. Accuracy: 80.31154239019408\n",
      "Iterations: 100600. Loss: 0.24546723067760468. Accuracy: 80.36261491317671\n",
      "Iterations: 100700. Loss: 0.04586874693632126. Accuracy: 80.41368743615935\n",
      "Iterations: 100800. Loss: 0.048995137214660645. Accuracy: 80.51583248212462\n",
      "Iterations: 100900. Loss: 0.15016897022724152. Accuracy: 80.2093973442288\n",
      "Iterations: 101000. Loss: 1.215524435043335. Accuracy: 80.33707865168539\n",
      "Iterations: 101100. Loss: 0.14203239977359772. Accuracy: 80.28600612870275\n",
      "Iterations: 101200. Loss: 0.14700666069984436. Accuracy: 80.23493360572012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 101300. Loss: 1.8248226642608643. Accuracy: 80.26046986721144\n",
      "Iterations: 101400. Loss: 0.35014134645462036. Accuracy: 80.54136874361593\n",
      "Iterations: 101500. Loss: 0.8813201189041138. Accuracy: 80.46475995914199\n",
      "Iterations: 101600. Loss: 0.5973511338233948. Accuracy: 80.51583248212462\n",
      "Iterations: 101700. Loss: 0.10547460615634918. Accuracy: 80.15832482124617\n",
      "Iterations: 101800. Loss: 0.8265315890312195. Accuracy: 80.54136874361593\n",
      "Iterations: 101900. Loss: 0.043905843049287796. Accuracy: 80.4902962206333\n",
      "Iterations: 102000. Loss: 0.68660569190979. Accuracy: 80.59244126659857\n",
      "Iterations: 102100. Loss: 0.5183790922164917. Accuracy: 80.4902962206333\n",
      "Iterations: 102200. Loss: 2.1698238849639893. Accuracy: 80.36261491317671\n",
      "Iterations: 102300. Loss: 0.2803918123245239. Accuracy: 80.56690500510726\n",
      "Iterations: 102400. Loss: 0.8007376194000244. Accuracy: 80.56690500510726\n",
      "Iterations: 102500. Loss: 1.148036003112793. Accuracy: 80.59244126659857\n",
      "Iterations: 102600. Loss: 0.32918494939804077. Accuracy: 80.59244126659857\n",
      "Iterations: 102700. Loss: 0.48814916610717773. Accuracy: 80.56690500510726\n",
      "Iterations: 102800. Loss: 0.35668447613716125. Accuracy: 80.4902962206333\n",
      "Iterations: 102900. Loss: 0.23090137541294098. Accuracy: 80.4902962206333\n",
      "Iterations: 103000. Loss: 0.8226242065429688. Accuracy: 80.51583248212462\n",
      "Iterations: 103100. Loss: 1.160131812095642. Accuracy: 80.46475995914199\n",
      "Iterations: 103200. Loss: 0.31835681200027466. Accuracy: 80.31154239019408\n",
      "Iterations: 103300. Loss: 1.4348064661026. Accuracy: 80.08171603677222\n",
      "Iterations: 103400. Loss: 0.21956010162830353. Accuracy: 80.10725229826353\n",
      "Iterations: 103500. Loss: 1.2092556953430176. Accuracy: 80.15832482124617\n",
      "Iterations: 103600. Loss: 0.33731213212013245. Accuracy: 80.41368743615935\n",
      "Iterations: 103700. Loss: 0.6285020112991333. Accuracy: 80.38815117466802\n",
      "Iterations: 103800. Loss: 0.5510120391845703. Accuracy: 80.1838610827375\n",
      "Iterations: 103900. Loss: 0.4136110246181488. Accuracy: 80.36261491317671\n",
      "Iterations: 104000. Loss: 0.014587887562811375. Accuracy: 80.31154239019408\n",
      "Iterations: 104100. Loss: 0.0849093645811081. Accuracy: 80.2093973442288\n",
      "Iterations: 104200. Loss: 0.07879268378019333. Accuracy: 80.13278855975486\n",
      "Iterations: 104300. Loss: 0.3799278438091278. Accuracy: 80.15832482124617\n",
      "Iterations: 104400. Loss: 0.056674566119909286. Accuracy: 80.43922369765066\n",
      "Iterations: 104500. Loss: 0.026026958599686623. Accuracy: 80.26046986721144\n",
      "Iterations: 104600. Loss: 0.0652303472161293. Accuracy: 80.2093973442288\n",
      "Iterations: 104700. Loss: 0.22289937734603882. Accuracy: 80.26046986721144\n",
      "Iterations: 104800. Loss: 0.19634483754634857. Accuracy: 80.0561797752809\n",
      "Iterations: 104900. Loss: 0.6378235816955566. Accuracy: 80.10725229826353\n",
      "Iterations: 105000. Loss: 0.3528271019458771. Accuracy: 80.08171603677222\n",
      "Iterations: 105100. Loss: 0.6891577839851379. Accuracy: 80.10725229826353\n",
      "Iterations: 105200. Loss: 0.09195425361394882. Accuracy: 80.1838610827375\n",
      "Iterations: 105300. Loss: 1.2379580736160278. Accuracy: 79.85188968335035\n",
      "Iterations: 105400. Loss: 0.336046040058136. Accuracy: 80.4902962206333\n",
      "Iterations: 105500. Loss: 0.04122241958975792. Accuracy: 80.61797752808988\n",
      "Iterations: 105600. Loss: 0.2880958020687103. Accuracy: 80.6435137895812\n",
      "Iterations: 105700. Loss: 0.002153579378500581. Accuracy: 80.66905005107252\n",
      "Iterations: 105800. Loss: 0.6328151822090149. Accuracy: 80.6435137895812\n",
      "Iterations: 105900. Loss: 0.0012435331009328365. Accuracy: 80.61797752808988\n",
      "Iterations: 106000. Loss: 0.12136750668287277. Accuracy: 80.56690500510726\n",
      "Iterations: 106100. Loss: 0.3934251070022583. Accuracy: 80.38815117466802\n",
      "Iterations: 106200. Loss: 0.12206559628248215. Accuracy: 80.36261491317671\n",
      "Iterations: 106300. Loss: 1.1301722526550293. Accuracy: 80.61797752808988\n",
      "Iterations: 106400. Loss: 1.201837182044983. Accuracy: 80.41368743615935\n",
      "Iterations: 106500. Loss: 0.9456536173820496. Accuracy: 80.59244126659857\n",
      "Iterations: 106600. Loss: 0.13417470455169678. Accuracy: 80.51583248212462\n",
      "Iterations: 106700. Loss: 0.7282536625862122. Accuracy: 80.28600612870275\n",
      "Iterations: 106800. Loss: 0.02387535199522972. Accuracy: 80.36261491317671\n",
      "Iterations: 106900. Loss: 0.1990613341331482. Accuracy: 80.15832482124617\n",
      "Iterations: 107000. Loss: 0.3864450454711914. Accuracy: 80.43922369765066\n",
      "Iterations: 107100. Loss: 0.05562566593289375. Accuracy: 80.51583248212462\n",
      "Iterations: 107200. Loss: 0.7477172017097473. Accuracy: 80.43922369765066\n",
      "Iterations: 107300. Loss: 0.16302964091300964. Accuracy: 80.0561797752809\n",
      "Iterations: 107400. Loss: 0.0020477056968957186. Accuracy: 80.38815117466802\n",
      "Iterations: 107500. Loss: 0.6565247178077698. Accuracy: 80.59244126659857\n",
      "Iterations: 107600. Loss: 0.22158460319042206. Accuracy: 80.79673135852912\n",
      "Iterations: 107700. Loss: 0.10018749535083771. Accuracy: 80.84780388151175\n",
      "Iterations: 107800. Loss: 0.05416842922568321. Accuracy: 80.51583248212462\n",
      "Iterations: 107900. Loss: 0.31375670433044434. Accuracy: 80.36261491317671\n",
      "Iterations: 108000. Loss: 0.4055003821849823. Accuracy: 80.79673135852912\n",
      "Iterations: 108100. Loss: 0.9332835078239441. Accuracy: 80.66905005107252\n",
      "Iterations: 108200. Loss: 0.6077041029930115. Accuracy: 80.56690500510726\n",
      "Iterations: 108300. Loss: 0.284393846988678. Accuracy: 80.84780388151175\n",
      "Iterations: 108400. Loss: 0.01867813616991043. Accuracy: 80.79673135852912\n",
      "Iterations: 108500. Loss: 0.6657189130783081. Accuracy: 80.74565883554648\n",
      "Iterations: 108600. Loss: 0.23715022206306458. Accuracy: 80.74565883554648\n",
      "Iterations: 108700. Loss: 1.138430118560791. Accuracy: 80.84780388151175\n",
      "Iterations: 108800. Loss: 0.03130164369940758. Accuracy: 80.77119509703779\n",
      "Iterations: 108900. Loss: 0.8891952633857727. Accuracy: 80.82226762002043\n",
      "Iterations: 109000. Loss: 0.17531903088092804. Accuracy: 80.89887640449439\n",
      "Iterations: 109100. Loss: 0.0686013400554657. Accuracy: 80.72012257405515\n",
      "Iterations: 109200. Loss: 0.0023983544670045376. Accuracy: 80.82226762002043\n",
      "Iterations: 109300. Loss: 0.05425266921520233. Accuracy: 80.79673135852912\n",
      "Iterations: 109400. Loss: 0.5510921478271484. Accuracy: 80.94994892747702\n",
      "Iterations: 109500. Loss: 0.3778907358646393. Accuracy: 80.89887640449439\n",
      "Iterations: 109600. Loss: 0.47736501693725586. Accuracy: 80.77119509703779\n",
      "Iterations: 109700. Loss: 0.0805853083729744. Accuracy: 80.79673135852912\n",
      "Iterations: 109800. Loss: 0.12131281197071075. Accuracy: 80.66905005107252\n",
      "Iterations: 109900. Loss: 0.5938102006912231. Accuracy: 80.84780388151175\n",
      "Iterations: 110000. Loss: 0.17072468996047974. Accuracy: 80.61797752808988\n",
      "Iterations: 110100. Loss: 0.0326334610581398. Accuracy: 80.59244126659857\n",
      "Iterations: 110200. Loss: 0.9934834837913513. Accuracy: 80.79673135852912\n",
      "Iterations: 110300. Loss: 0.8605185747146606. Accuracy: 80.84780388151175\n",
      "Iterations: 110400. Loss: 0.04489005729556084. Accuracy: 80.84780388151175\n",
      "Iterations: 110500. Loss: 0.3664468824863434. Accuracy: 80.59244126659857\n",
      "Iterations: 110600. Loss: 0.030050883069634438. Accuracy: 80.69458631256384\n",
      "Iterations: 110700. Loss: 0.08252358436584473. Accuracy: 80.69458631256384\n",
      "Iterations: 110800. Loss: 0.34371522068977356. Accuracy: 80.61797752808988\n",
      "Iterations: 110900. Loss: 0.1373559832572937. Accuracy: 80.51583248212462\n",
      "Iterations: 111000. Loss: 0.30889904499053955. Accuracy: 80.51583248212462\n",
      "Iterations: 111100. Loss: 1.646945595741272. Accuracy: 80.56690500510726\n",
      "Iterations: 111200. Loss: 0.2669215500354767. Accuracy: 80.82226762002043\n",
      "Iterations: 111300. Loss: 0.42964276671409607. Accuracy: 80.4902962206333\n",
      "Iterations: 111400. Loss: 0.32566648721694946. Accuracy: 80.69458631256384\n",
      "Iterations: 111500. Loss: 0.34956926107406616. Accuracy: 80.51583248212462\n",
      "Iterations: 111600. Loss: 0.0871330201625824. Accuracy: 80.46475995914199\n",
      "Iterations: 111700. Loss: 0.12450635433197021. Accuracy: 80.36261491317671\n",
      "Iterations: 111800. Loss: 0.8811671137809753. Accuracy: 80.51583248212462\n",
      "Iterations: 111900. Loss: 1.1136376857757568. Accuracy: 80.43922369765066\n",
      "Iterations: 112000. Loss: 1.177176594734192. Accuracy: 80.26046986721144\n",
      "Iterations: 112100. Loss: 0.01422432903200388. Accuracy: 80.41368743615935\n",
      "Iterations: 112200. Loss: 0.8728240132331848. Accuracy: 80.31154239019408\n",
      "Iterations: 112300. Loss: 0.09158513695001602. Accuracy: 80.33707865168539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 112400. Loss: 0.017694825306534767. Accuracy: 80.36261491317671\n",
      "Iterations: 112500. Loss: 0.004854203201830387. Accuracy: 80.31154239019408\n",
      "Iterations: 112600. Loss: 0.018152184784412384. Accuracy: 80.6435137895812\n",
      "Iterations: 112700. Loss: 0.10087509453296661. Accuracy: 80.54136874361593\n",
      "Iterations: 112800. Loss: 0.1386578530073166. Accuracy: 80.38815117466802\n",
      "Iterations: 112900. Loss: 0.07147546112537384. Accuracy: 80.43922369765066\n",
      "Iterations: 113000. Loss: 0.1946001648902893. Accuracy: 80.38815117466802\n",
      "Iterations: 113100. Loss: 0.4194938838481903. Accuracy: 80.4902962206333\n",
      "Iterations: 113200. Loss: 0.05008877068758011. Accuracy: 80.46475995914199\n",
      "Iterations: 113300. Loss: 0.23806820809841156. Accuracy: 80.36261491317671\n",
      "Iterations: 113400. Loss: 0.6461167931556702. Accuracy: 80.31154239019408\n",
      "Iterations: 113500. Loss: 0.0892098993062973. Accuracy: 80.41368743615935\n",
      "Iterations: 113600. Loss: 0.2098618447780609. Accuracy: 80.31154239019408\n",
      "Iterations: 113700. Loss: 1.1613965034484863. Accuracy: 80.46475995914199\n",
      "Iterations: 113800. Loss: 0.15538789331912994. Accuracy: 80.43922369765066\n",
      "Iterations: 113900. Loss: 0.48430612683296204. Accuracy: 80.41368743615935\n",
      "Iterations: 114000. Loss: 0.18931138515472412. Accuracy: 80.31154239019408\n",
      "Iterations: 114100. Loss: 0.10486101359128952. Accuracy: 80.33707865168539\n",
      "Iterations: 114200. Loss: 0.25384196639060974. Accuracy: 80.74565883554648\n",
      "Iterations: 114300. Loss: 0.0013860390754416585. Accuracy: 80.36261491317671\n",
      "Iterations: 114400. Loss: 0.1696847826242447. Accuracy: 80.72012257405515\n",
      "Iterations: 114500. Loss: 0.5612714886665344. Accuracy: 80.74565883554648\n",
      "Iterations: 114600. Loss: 0.3723936676979065. Accuracy: 80.74565883554648\n",
      "Iterations: 114700. Loss: 0.29864177107810974. Accuracy: 80.69458631256384\n",
      "Iterations: 114800. Loss: 0.45371270179748535. Accuracy: 80.87334014300306\n",
      "Iterations: 114900. Loss: 0.27476274967193604. Accuracy: 80.77119509703779\n",
      "Iterations: 115000. Loss: 0.19850844144821167. Accuracy: 80.59244126659857\n",
      "Iterations: 115100. Loss: 0.06514356285333633. Accuracy: 80.61797752808988\n",
      "Iterations: 115200. Loss: 0.028319386765360832. Accuracy: 80.66905005107252\n",
      "Iterations: 115300. Loss: 0.16704516112804413. Accuracy: 80.74565883554648\n",
      "Iterations: 115400. Loss: 0.12632569670677185. Accuracy: 80.77119509703779\n",
      "Iterations: 115500. Loss: 0.8560329675674438. Accuracy: 80.59244126659857\n",
      "Iterations: 115600. Loss: 0.21329988539218903. Accuracy: 80.61797752808988\n",
      "Iterations: 115700. Loss: 1.0770535469055176. Accuracy: 80.56690500510726\n",
      "Iterations: 115800. Loss: 0.016418591141700745. Accuracy: 80.61797752808988\n",
      "Iterations: 115900. Loss: 0.21402455866336823. Accuracy: 80.46475995914199\n",
      "Iterations: 116000. Loss: 0.07548322528600693. Accuracy: 80.72012257405515\n",
      "Iterations: 116100. Loss: 0.006914970930665731. Accuracy: 80.69458631256384\n",
      "Iterations: 116200. Loss: 0.13748565316200256. Accuracy: 80.61797752808988\n",
      "Iterations: 116300. Loss: 0.08775737136602402. Accuracy: 80.72012257405515\n",
      "Iterations: 116400. Loss: 1.4814345836639404. Accuracy: 80.77119509703779\n",
      "Iterations: 116500. Loss: 0.9481470584869385. Accuracy: 80.59244126659857\n",
      "Iterations: 116600. Loss: 0.16256284713745117. Accuracy: 80.79673135852912\n",
      "Iterations: 116700. Loss: 0.11136918514966965. Accuracy: 80.56690500510726\n",
      "Iterations: 116800. Loss: 0.032923951745033264. Accuracy: 80.51583248212462\n",
      "Iterations: 116900. Loss: 0.22106428444385529. Accuracy: 80.46475995914199\n",
      "Iterations: 117000. Loss: 0.5386567115783691. Accuracy: 80.56690500510726\n",
      "Iterations: 117100. Loss: 0.039299074560403824. Accuracy: 80.6435137895812\n",
      "Iterations: 117200. Loss: 0.4658111333847046. Accuracy: 80.69458631256384\n",
      "Iterations: 117300. Loss: 0.035017408430576324. Accuracy: 80.72012257405515\n",
      "Iterations: 117400. Loss: 0.03298427537083626. Accuracy: 80.38815117466802\n",
      "Iterations: 117500. Loss: 0.1549350768327713. Accuracy: 80.77119509703779\n",
      "Iterations: 117600. Loss: 0.3040376603603363. Accuracy: 80.79673135852912\n",
      "Iterations: 117700. Loss: 2.130608558654785. Accuracy: 80.89887640449439\n",
      "Iterations: 117800. Loss: 0.10651560872793198. Accuracy: 80.61797752808988\n",
      "Iterations: 117900. Loss: 0.21384947001934052. Accuracy: 80.84780388151175\n",
      "Iterations: 118000. Loss: 1.217208981513977. Accuracy: 80.9244126659857\n",
      "Iterations: 118100. Loss: 0.3983279764652252. Accuracy: 80.77119509703779\n",
      "Iterations: 118200. Loss: 0.16685490310192108. Accuracy: 80.66905005107252\n",
      "Iterations: 118300. Loss: 0.021619834005832672. Accuracy: 80.79673135852912\n",
      "Iterations: 118400. Loss: 0.206674724817276. Accuracy: 80.74565883554648\n",
      "Iterations: 118500. Loss: 0.03568572551012039. Accuracy: 80.94994892747702\n",
      "Iterations: 118600. Loss: 0.3631340265274048. Accuracy: 80.77119509703779\n",
      "Iterations: 118700. Loss: 0.20428289473056793. Accuracy: 80.69458631256384\n",
      "Iterations: 118800. Loss: 0.01764809340238571. Accuracy: 80.66905005107252\n",
      "Iterations: 118900. Loss: 0.20111896097660065. Accuracy: 80.56690500510726\n",
      "Iterations: 119000. Loss: 1.6101562976837158. Accuracy: 80.56690500510726\n",
      "Iterations: 119100. Loss: 2.437605857849121. Accuracy: 80.51583248212462\n",
      "Iterations: 119200. Loss: 0.5598774552345276. Accuracy: 80.46475995914199\n",
      "Iterations: 119300. Loss: 0.03478186950087547. Accuracy: 80.51583248212462\n",
      "Iterations: 119400. Loss: 0.672530472278595. Accuracy: 80.69458631256384\n",
      "Iterations: 119500. Loss: 0.08817614614963531. Accuracy: 80.36261491317671\n",
      "Iterations: 119600. Loss: 0.7037601470947266. Accuracy: 80.77119509703779\n",
      "Iterations: 119700. Loss: 0.5748345851898193. Accuracy: 80.43922369765066\n",
      "Iterations: 119800. Loss: 0.38021111488342285. Accuracy: 80.2093973442288\n",
      "Iterations: 119900. Loss: 0.6057170629501343. Accuracy: 80.43922369765066\n",
      "Iterations: 120000. Loss: 0.33269158005714417. Accuracy: 80.74565883554648\n",
      "Iterations: 120100. Loss: 0.1735757291316986. Accuracy: 80.66905005107252\n",
      "Iterations: 120200. Loss: 1.7573548555374146. Accuracy: 80.77119509703779\n",
      "Iterations: 120300. Loss: 1.4418023824691772. Accuracy: 80.54136874361593\n",
      "Iterations: 120400. Loss: 0.11682360619306564. Accuracy: 80.59244126659857\n",
      "Iterations: 120500. Loss: 0.33624884486198425. Accuracy: 80.4902962206333\n",
      "Iterations: 120600. Loss: 0.07177440822124481. Accuracy: 80.23493360572012\n",
      "Iterations: 120700. Loss: 0.04847978428006172. Accuracy: 80.2093973442288\n",
      "Iterations: 120800. Loss: 0.536087155342102. Accuracy: 80.23493360572012\n",
      "Iterations: 120900. Loss: 0.23755142092704773. Accuracy: 80.26046986721144\n",
      "Iterations: 121000. Loss: 1.9004313945770264. Accuracy: 80.46475995914199\n",
      "Iterations: 121100. Loss: 0.12571078538894653. Accuracy: 80.6435137895812\n",
      "Iterations: 121200. Loss: 0.8591227531433105. Accuracy: 80.9244126659857\n",
      "Iterations: 121300. Loss: 0.7128939032554626. Accuracy: 80.84780388151175\n",
      "Iterations: 121400. Loss: 0.08490005880594254. Accuracy: 80.97548518896834\n",
      "Iterations: 121500. Loss: 0.25279349088668823. Accuracy: 80.79673135852912\n",
      "Iterations: 121600. Loss: 0.017459506168961525. Accuracy: 80.87334014300306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f4b512999a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mbow_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_bow_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for (sent,label) in train_data:\n",
    "        # Step 1 - clear the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Step 2- Prepare input and label\n",
    "        bow_vec = Variable(make_bow_vector(sent, word_to_ix)).cuda()\n",
    "        target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "        \n",
    "        # Step 3 - Run forward pass\n",
    "        output = model(bow_vec)\n",
    "        #print(\"Log probabilities - {}\".format(log_probs))\n",
    "        \n",
    "        # Step 4 - Compute loss, gradients, update parameters\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1      \n",
    "        ## Calculate final accuracy\n",
    "        if iter % 100 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (sent,label) in valid_data:\n",
    "                bow_vec = Variable(make_bow_vector(sent, word_to_ix)).cuda()\n",
    "                target = Variable(make_target(label, label_to_ix)).cuda()\n",
    "                output = model(bow_vec)\n",
    "                _,predicted = torch.max(output.data,1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted[0] == make_target(label, label_to_ix)).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print('Iterations: {}. Loss: {}. Accuracy: {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_loss(valid_data, model, label_to_ix, word_to_ix):\n",
    "    true_label = np.zeros((len(valid_data),1))\n",
    "    results_valid = np.zeros((len(valid_data),len(label_to_ix)))\n",
    "    for i in range(len(valid_data)):\n",
    "        bow_vec = Variable(make_bow_vector(valid_data[i][0], word_to_ix)).cuda()\n",
    "        log_probs = model(bow_vec)\n",
    "        pred = F.softmax(log_probs,dim=1).data.cpu().numpy()\n",
    "        results_valid[i]=pred\n",
    "        true_label[i]=label_to_ix[valid_data[i][1]]\n",
    "    return log_loss(true_label,results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51034577431219419"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_loss(valid_data, model, label_to_ix, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model,test):\n",
    "    my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "    my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "    for i in range(len(test['phrase_preprocessed'])):\n",
    "        sample=test['phrase_preprocessed'][i]\n",
    "        #print(sample)\n",
    "        sample_context=Variable(make_bow_vector(sample,word_to_ix)).cuda()\n",
    "        log_prob=model(sample_context)\n",
    "        probs=F.softmax(log_prob)\n",
    "        my_sub.loc[i] = [test['id'][i], probs.data[0][0],probs.data[0][1],probs.data[0][2]]\n",
    "    return my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, EAP, HPL, MWS]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/Envs/nlp36/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "preds=make_preds(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>0.606491</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.256408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>0.235632</td>\n",
       "      <td>0.120189</td>\n",
       "      <td>0.644178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>0.515651</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.427889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>0.199650</td>\n",
       "      <td>0.051406</td>\n",
       "      <td>0.748944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>0.444649</td>\n",
       "      <td>0.529615</td>\n",
       "      <td>0.025737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       EAP       HPL       MWS\n",
       "8387  id11749  0.606491  0.137100  0.256408\n",
       "8388  id10526  0.235632  0.120189  0.644178\n",
       "8389  id13477  0.515651  0.056460  0.427889\n",
       "8390  id13761  0.199650  0.051406  0.748944\n",
       "8391  id04282  0.444649  0.529615  0.025737"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('roberto_new_13.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
