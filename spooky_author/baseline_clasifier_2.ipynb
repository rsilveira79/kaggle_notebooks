{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL\n",
       "5  id22965  A youth passed in solitude, my best years spen...    MWS\n",
       "6  id09674  The astronomer, perhaps, at this point, took r...    EAP\n",
       "7  id13515        The surcingle hung in ribands from my body.    EAP\n",
       "8  id19322  I knew that you could not say to yourself 'ste...    EAP\n",
       "9  id00912  I confess that neither the structure of langua...    MWS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(len(train))\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id27337</td>\n",
       "      <td>\"The thick and peculiar mist, or smoke, which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id24265</td>\n",
       "      <td>That which is not matter, is not at all unless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id25917</td>\n",
       "      <td>I sought for repose although I did not hope fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id04951</td>\n",
       "      <td>Upon the fourth day of the assassination, a pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id14549</td>\n",
       "      <td>\"The tone metaphysical is also a good one.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ...\n",
       "5  id27337  \"The thick and peculiar mist, or smoke, which ...\n",
       "6  id24265  That which is not matter, is not at all unless...\n",
       "7  id25917  I sought for repose although I did not hope fo...\n",
       "8  id04951  Upon the fourth day of the assassination, a pa...\n",
       "9  id14549         \"The tone metaphysical is also a good one."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(len(test))\n",
    "test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "5  id22965  A youth passed in solitude, my best years spen...    MWS   \n",
       "6  id09674  The astronomer, perhaps, at this point, took r...    EAP   \n",
       "7  id13515        The surcingle hung in ribands from my body.    EAP   \n",
       "8  id19322  I knew that you could not say to yourself 'ste...    EAP   \n",
       "9  id00912  I confess that neither the structure of langua...    MWS   \n",
       "\n",
       "   label_encoded  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              2  \n",
       "4              1  \n",
       "5              2  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enconder = preprocessing.LabelEncoder()\n",
    "label_enconder.fit(train['author'])\n",
    "train['label_encoded'] = label_enconder.transform(train['author'])\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "   # filtered_words = [word for word in text.split()]\n",
    "\n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=3)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Stemming\n",
    "    text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>process howev afford mean ascertain dimens dun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>never occur fumbl might mere mistak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>left hand gold snuff box which caper hill cut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>love spring look windsor terrac sixteen fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>find noth els even gold superintend abandon at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>youth pass solitud best year spent gentl femin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>astronom perhap point took refug suggest non l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>surcingl hung riband bodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>knew could sai stereotomi without brought thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>confess neither structur languag code govern p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id16737</td>\n",
       "      <td>He shall find that I can feel my injuries; he ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>shall find feel injuri shall learn dread reven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id16607</td>\n",
       "      <td>Here we barricaded ourselves, and, for the pre...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>barricad ourselv and present secur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id19764</td>\n",
       "      <td>Herbert West needed fresh bodies because his l...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>herbert west need fresh bodi life work reanim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id18886</td>\n",
       "      <td>The farm like grounds extended back very deepl...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>farm like ground extend back deepli hill almos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id17189</td>\n",
       "      <td>But a glance will show the fallacy of this idea.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>glanc show fallaci idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id12799</td>\n",
       "      <td>He had escaped me, and I must commence a destr...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>escap me must commenc destruct almost endless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id08441</td>\n",
       "      <td>To these speeches they gave, of course, their ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>speech gave cours interpret fanci doubt event ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id13117</td>\n",
       "      <td>Her native sprightliness needed no undue excit...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>nativ sprightli need undu excit placid heart r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id14862</td>\n",
       "      <td>I even went so far as to speak of a slightly h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>even went far speak slightli hectic cough whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id20836</td>\n",
       "      <td>His facial aspect, too, was remarkable for its...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>facial aspect too remark matur though share mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id11411</td>\n",
       "      <td>Now the net work was not permanently fastened ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>net work perman fasten hoop attach seri run lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id08075</td>\n",
       "      <td>It was not that the sounds were hideous, for t...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>sound hideou not held vibrat suggest noth glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id18925</td>\n",
       "      <td>On every hand was a wilderness of balconies, o...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>everi hand wilder balconi veranda minaret shri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id19925</td>\n",
       "      <td>With how deep a spirit of wonder and perplexit...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>deep spirit wonder perplex wont regard remot p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id01704</td>\n",
       "      <td>These bizarre attempts at explanation were fol...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>bizarr attempt explan follow other equal bizarr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id10125</td>\n",
       "      <td>For many prodigies and signs had taken place, ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>mani prodigi sign taken place far wide sea lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id02448</td>\n",
       "      <td>All that as yet can fairly be said to be known...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>yet fairli said known is pure gold made will r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id23451</td>\n",
       "      <td>I seemed to be upon the verge of comprehension...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>seem upon verg comprehens without power compre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id27907</td>\n",
       "      <td>Our compasses, depth gauges, and other delicat...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>compass depth gaug delic instrument ruin hence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id08121</td>\n",
       "      <td>This the young warriors took back with them to...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>young warrior took back sarnath symbol conques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19549</th>\n",
       "      <td>id20955</td>\n",
       "      <td>But it was not so; I was the same in strength,...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>so strength earnest crave sympathi yearn activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>id01270</td>\n",
       "      <td>He then took the book himself, and read me a c...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>took book himself read chapter aloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19551</th>\n",
       "      <td>id22290</td>\n",
       "      <td>\"Adolphe Le Bon, clerk to Mignaud et Fils, dep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>adolph bon clerk mignaud fil depos dai questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19552</th>\n",
       "      <td>id20272</td>\n",
       "      <td>But of the character of his remarks at the per...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>charact remark period question exampl best con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19553</th>\n",
       "      <td>id18082</td>\n",
       "      <td>He notes every variation of face as the play p...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>note everi variat face plai progress gather fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>id07976</td>\n",
       "      <td>They admitted they had been drunk, but both vo...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>admit drunk vow seen crazili dress trio furtiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>id26741</td>\n",
       "      <td>The rays of the newly risen sun poured in upon...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>rai newli risen sun pour upon whole window for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>id26698</td>\n",
       "      <td>To the north on the craggy precipice a few pac...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>north craggi precipic pace verg sprang magnifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19557</th>\n",
       "      <td>id22265</td>\n",
       "      <td>The frauds of the banks of course I couldn't h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>fraud bank cours couldn t help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>id14778</td>\n",
       "      <td>He was attired, as I had expected, in a costum...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>attir expect costum altogeth similar own wear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>id18823</td>\n",
       "      <td>When a fumbling came in the nearer casements h...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>fumbl came nearer casement crept around west a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>id00893</td>\n",
       "      <td>But then there is the tone laconic, or curt, w...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>tone lacon curt late come much us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>id08678</td>\n",
       "      <td>Average people in society and business New Eng...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>averag peopl societi busi new england s tradit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>id10857</td>\n",
       "      <td>The modes and sources of this kind of error ar...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>mode sourc kind error well typifi contempl hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>id10563</td>\n",
       "      <td>Yet from whom has not that rude hand rent away...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>yet rude hand rent awai dear connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>id11752</td>\n",
       "      <td>Almighty God no, no They heard they suspected ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>almighti god no heard suspect knew make mocker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>id26214</td>\n",
       "      <td>I hope you have not been so foolish as to take...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>hope foolish take offenc littl brusqueri mine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>id00832</td>\n",
       "      <td>These reflections made our legislators pause, ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>reflect made legisl paus could decid law put forc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19567</th>\n",
       "      <td>id04187</td>\n",
       "      <td>Because there were some considerations of deep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>consider deep interest beyond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>id22378</td>\n",
       "      <td>Before going in we walked up the street, turne...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>go walk street turn allei then turn pass rear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>id26790</td>\n",
       "      <td>Once my fancy was soothed with dreams of virtu...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>fanci sooth dream virtu fame enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>id14263</td>\n",
       "      <td>Nay, you may have met with another whom you ma...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>nai mai met anoth mai love consid bound honour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>id14420</td>\n",
       "      <td>My watch was still going, and told me that the...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>watch still go told hour past noon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>id03325</td>\n",
       "      <td>But these and other difficulties attending res...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>difficulti attend respir mean great put peril ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>id07567</td>\n",
       "      <td>Stress of weather drove us up the Adriatic Gul...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "      <td>stress weather drove adriat gulph and vessel h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>could fanci look it emin landscap painter buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>lid clench togeth spasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>mai faut agir sai frenchman never faint outright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "      <td>item new like thi strike coolli receiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "      <td>laid gnarl claw shoulder seem shake altogeth m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "5      id22965  A youth passed in solitude, my best years spen...    MWS   \n",
       "6      id09674  The astronomer, perhaps, at this point, took r...    EAP   \n",
       "7      id13515        The surcingle hung in ribands from my body.    EAP   \n",
       "8      id19322  I knew that you could not say to yourself 'ste...    EAP   \n",
       "9      id00912  I confess that neither the structure of langua...    MWS   \n",
       "10     id16737  He shall find that I can feel my injuries; he ...    MWS   \n",
       "11     id16607  Here we barricaded ourselves, and, for the pre...    EAP   \n",
       "12     id19764  Herbert West needed fresh bodies because his l...    HPL   \n",
       "13     id18886  The farm like grounds extended back very deepl...    HPL   \n",
       "14     id17189   But a glance will show the fallacy of this idea.    EAP   \n",
       "15     id12799  He had escaped me, and I must commence a destr...    MWS   \n",
       "16     id08441  To these speeches they gave, of course, their ...    EAP   \n",
       "17     id13117  Her native sprightliness needed no undue excit...    MWS   \n",
       "18     id14862  I even went so far as to speak of a slightly h...    EAP   \n",
       "19     id20836  His facial aspect, too, was remarkable for its...    HPL   \n",
       "20     id11411  Now the net work was not permanently fastened ...    EAP   \n",
       "21     id08075  It was not that the sounds were hideous, for t...    HPL   \n",
       "22     id18925  On every hand was a wilderness of balconies, o...    EAP   \n",
       "23     id19925  With how deep a spirit of wonder and perplexit...    EAP   \n",
       "24     id01704  These bizarre attempts at explanation were fol...    EAP   \n",
       "25     id10125  For many prodigies and signs had taken place, ...    EAP   \n",
       "26     id02448  All that as yet can fairly be said to be known...    EAP   \n",
       "27     id23451  I seemed to be upon the verge of comprehension...    EAP   \n",
       "28     id27907  Our compasses, depth gauges, and other delicat...    HPL   \n",
       "29     id08121  This the young warriors took back with them to...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19549  id20955  But it was not so; I was the same in strength,...    MWS   \n",
       "19550  id01270  He then took the book himself, and read me a c...    EAP   \n",
       "19551  id22290  \"Adolphe Le Bon, clerk to Mignaud et Fils, dep...    EAP   \n",
       "19552  id20272  But of the character of his remarks at the per...    EAP   \n",
       "19553  id18082  He notes every variation of face as the play p...    EAP   \n",
       "19554  id07976  They admitted they had been drunk, but both vo...    HPL   \n",
       "19555  id26741  The rays of the newly risen sun poured in upon...    EAP   \n",
       "19556  id26698  To the north on the craggy precipice a few pac...    EAP   \n",
       "19557  id22265  The frauds of the banks of course I couldn't h...    EAP   \n",
       "19558  id14778  He was attired, as I had expected, in a costum...    EAP   \n",
       "19559  id18823  When a fumbling came in the nearer casements h...    HPL   \n",
       "19560  id00893  But then there is the tone laconic, or curt, w...    EAP   \n",
       "19561  id08678  Average people in society and business New Eng...    HPL   \n",
       "19562  id10857  The modes and sources of this kind of error ar...    EAP   \n",
       "19563  id10563  Yet from whom has not that rude hand rent away...    MWS   \n",
       "19564  id11752  Almighty God no, no They heard they suspected ...    EAP   \n",
       "19565  id26214  I hope you have not been so foolish as to take...    EAP   \n",
       "19566  id00832  These reflections made our legislators pause, ...    MWS   \n",
       "19567  id04187  Because there were some considerations of deep...    EAP   \n",
       "19568  id22378  Before going in we walked up the street, turne...    EAP   \n",
       "19569  id26790  Once my fancy was soothed with dreams of virtu...    MWS   \n",
       "19570  id14263  Nay, you may have met with another whom you ma...    MWS   \n",
       "19571  id14420  My watch was still going, and told me that the...    HPL   \n",
       "19572  id03325  But these and other difficulties attending res...    EAP   \n",
       "19573  id07567  Stress of weather drove us up the Adriatic Gul...    MWS   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "       label_encoded                                     text_processed  \n",
       "0                  0  process howev afford mean ascertain dimens dun...  \n",
       "1                  1                never occur fumbl might mere mistak  \n",
       "2                  0  left hand gold snuff box which caper hill cut ...  \n",
       "3                  2  love spring look windsor terrac sixteen fertil...  \n",
       "4                  1  find noth els even gold superintend abandon at...  \n",
       "5                  2  youth pass solitud best year spent gentl femin...  \n",
       "6                  0  astronom perhap point took refug suggest non l...  \n",
       "7                  0                          surcingl hung riband bodi  \n",
       "8                  0  knew could sai stereotomi without brought thin...  \n",
       "9                  2  confess neither structur languag code govern p...  \n",
       "10                 2  shall find feel injuri shall learn dread reven...  \n",
       "11                 0                 barricad ourselv and present secur  \n",
       "12                 1  herbert west need fresh bodi life work reanim ...  \n",
       "13                 1  farm like ground extend back deepli hill almos...  \n",
       "14                 0                            glanc show fallaci idea  \n",
       "15                 2  escap me must commenc destruct almost endless ...  \n",
       "16                 0  speech gave cours interpret fanci doubt event ...  \n",
       "17                 2  nativ sprightli need undu excit placid heart r...  \n",
       "18                 0  even went far speak slightli hectic cough whic...  \n",
       "19                 1  facial aspect too remark matur though share mo...  \n",
       "20                 0  net work perman fasten hoop attach seri run lo...  \n",
       "21                 1  sound hideou not held vibrat suggest noth glob...  \n",
       "22                 0  everi hand wilder balconi veranda minaret shri...  \n",
       "23                 0  deep spirit wonder perplex wont regard remot p...  \n",
       "24                 0    bizarr attempt explan follow other equal bizarr  \n",
       "25                 0  mani prodigi sign taken place far wide sea lan...  \n",
       "26                 0  yet fairli said known is pure gold made will r...  \n",
       "27                 0  seem upon verg comprehens without power compre...  \n",
       "28                 1  compass depth gaug delic instrument ruin hence...  \n",
       "29                 1  young warrior took back sarnath symbol conques...  \n",
       "...              ...                                                ...  \n",
       "19549              2  so strength earnest crave sympathi yearn activ...  \n",
       "19550              0               took book himself read chapter aloud  \n",
       "19551              0  adolph bon clerk mignaud fil depos dai questio...  \n",
       "19552              0  charact remark period question exampl best con...  \n",
       "19553              0  note everi variat face plai progress gather fu...  \n",
       "19554              1  admit drunk vow seen crazili dress trio furtiv...  \n",
       "19555              0  rai newli risen sun pour upon whole window for...  \n",
       "19556              0  north craggi precipic pace verg sprang magnifi...  \n",
       "19557              0                     fraud bank cours couldn t help  \n",
       "19558              0  attir expect costum altogeth similar own wear ...  \n",
       "19559              1  fumbl came nearer casement crept around west a...  \n",
       "19560              0                  tone lacon curt late come much us  \n",
       "19561              1  averag peopl societi busi new england s tradit...  \n",
       "19562              0  mode sourc kind error well typifi contempl hea...  \n",
       "19563              2               yet rude hand rent awai dear connect  \n",
       "19564              0  almighti god no heard suspect knew make mocker...  \n",
       "19565              0  hope foolish take offenc littl brusqueri mine ...  \n",
       "19566              2  reflect made legisl paus could decid law put forc  \n",
       "19567              0                      consider deep interest beyond  \n",
       "19568              0  go walk street turn allei then turn pass rear ...  \n",
       "19569              2                 fanci sooth dream virtu fame enjoy  \n",
       "19570              2  nai mai met anoth mai love consid bound honour...  \n",
       "19571              1                 watch still go told hour past noon  \n",
       "19572              0  difficulti attend respir mean great put peril ...  \n",
       "19573              2  stress weather drove adriat gulph and vessel h...  \n",
       "19574              0  could fanci look it emin landscap painter buil...  \n",
       "19575              0                            lid clench togeth spasm  \n",
       "19576              0   mai faut agir sai frenchman never faint outright  \n",
       "19577              0             item new like thi strike coolli receiv  \n",
       "19578              1  laid gnarl claw shoulder seem shake altogeth m...  \n",
       "\n",
       "[19579 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_processed']=train['text'].apply(lambda x: transformText(x))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Some stats ####################\n",
      "Dataset training: 15663 uterances\n",
      "Dataset testing: 3916 uterances\n",
      "Different classes: 3\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train['text_processed'], train['label_encoded'], test_size = 0.2, random_state = 4)\n",
    "true_label = np.array(y_test)\n",
    "print(\"#\" * 20 + \" Some stats \" + \"#\"*20)\n",
    "print(\"Dataset training: {} uterances\".format(x_train.shape[0]))\n",
    "print(\"Dataset testing: {} uterances\".format(x_test.shape[0]))\n",
    "print(\"Different classes: {}\".format(len(y_train.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_2 = TfidfVectorizer(max_df = 0.9, ngram_range = (1,2), norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_features_2 = features_2.fit_transform(x_train)\n",
    "x_test_features_2 = features_2.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', max_iter=5,\n",
       "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd_2 = SGDClassifier(loss = 'modified_huber', penalty = 'l2',)\n",
    "model_sgd_2.fit(x_train_features_2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.836\n",
      "Log loss for this classifier 0.6697427187866234\n"
     ]
    }
   ],
   "source": [
    "preds_sgd_2 = model_sgd_2.predict(x_test_features_2)\n",
    "preds_sgd_2_proba = model_sgd_2.predict_proba(x_test_features_2)\n",
    "\n",
    "print(\"Current Accuracy: {0:.3f}\".format(accuracy_score(preds_sgd_2,true_label)))\n",
    "print(\"Log loss for this classifier {}\".format(log_loss(true_label,preds_sgd_2_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66974271878662339"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(true_label,preds_sgd_2_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9493    twice upon ventur express total incredul respe...\n",
       "1919                      fire among crowd women children\n",
       "1692    thought heard rat partit even paid littl atten...\n",
       "2714                              it mere typograph error\n",
       "9863    uttermost step led dread chamber larg fragment...\n",
       "Name: text_processed, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model 3\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.598 \n"
     ]
    }
   ],
   "source": [
    "tfv.fit(list(x_train) + list(x_test))\n",
    "x_train_tfv =  tfv.transform(x_train) \n",
    "x_test_tfv = tfv.transform(x_test)\n",
    "# -----\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "predictions = clf.predict_proba(x_test_tfv)\n",
    "print(\"logloss: %0.3f \" % multiclass_logloss(true_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Envs/nlp/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Model 4 - testing with XGBoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.748 \n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train_tfv.tocsc(), y_train)\n",
    "predictions = clf.predict_proba(x_test_tfv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(true_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917495it [03:08, 10189.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917495 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Loading Glove vectors\n",
    "embeddings_index = {}\n",
    "f = open('../../vectors/glove.42B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.90770000e-01,   6.50600016e-01,  -3.05849999e-01,\n",
       "         3.18800002e-01,  -7.07940012e-02,   2.48410001e-01,\n",
       "        -2.73169994e+00,  -4.37580012e-02,  -5.26859999e-01,\n",
       "        -7.58560002e-01,  -1.15719996e-02,  -8.15320015e-01,\n",
       "         6.35939986e-02,  -6.97100013e-02,  -1.55300006e-01,\n",
       "        -3.90240014e-01,   6.99109972e-01,  -1.29740000e-01,\n",
       "        -1.41599998e-01,   1.02559999e-01,   1.41190004e-03,\n",
       "        -5.15209995e-02,   3.72379988e-01,  -6.20259997e-03,\n",
       "         1.69630006e-01,   3.92159998e-01,  -3.15310001e-01,\n",
       "        -4.25500005e-01,  -4.13399994e-01,  -8.79890025e-02,\n",
       "        -4.49970007e-01,   3.94419990e-02,   5.83199978e-01,\n",
       "         4.32000011e-01,   1.85460001e-01,   6.25000000e-01,\n",
       "         4.14629988e-02,   5.63820004e-01,  -1.52940005e-01,\n",
       "        -5.30759990e-02,   2.59259999e-01,   2.45179996e-01,\n",
       "         1.74899995e-01,  -5.71019985e-02,  -1.26440004e-02,\n",
       "         2.52829999e-01,   1.42220005e-01,  -1.61740005e-01,\n",
       "        -1.93450004e-01,   3.79889995e-01], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['woman'][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stops]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15663 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 359/15663 [00:00<00:04, 3582.33it/s]\u001b[A\n",
      "  5%|▍         | 732/15663 [00:00<00:04, 3624.10it/s]\u001b[A\n",
      "  7%|▋         | 1094/15663 [00:00<00:04, 3622.08it/s]\u001b[A\n",
      "  9%|▉         | 1466/15663 [00:00<00:03, 3650.32it/s]\u001b[A\n",
      " 12%|█▏        | 1833/15663 [00:00<00:03, 3654.75it/s]\u001b[A\n",
      " 14%|█▍        | 2200/15663 [00:00<00:03, 3658.31it/s]\u001b[A\n",
      " 16%|█▋        | 2552/15663 [00:00<00:03, 3610.72it/s]\u001b[A\n",
      " 19%|█▊        | 2914/15663 [00:00<00:03, 3611.09it/s]\u001b[A\n",
      " 21%|██        | 3283/15663 [00:00<00:03, 3633.00it/s]\u001b[A\n",
      " 23%|██▎       | 3649/15663 [00:01<00:03, 3639.15it/s]\u001b[A\n",
      " 26%|██▌       | 4019/15663 [00:01<00:03, 3655.67it/s]\u001b[A\n",
      " 28%|██▊       | 4379/15663 [00:01<00:03, 3638.58it/s]\u001b[A\n",
      " 30%|███       | 4742/15663 [00:01<00:03, 3633.67it/s]\u001b[A\n",
      " 33%|███▎      | 5114/15663 [00:01<00:02, 3656.59it/s]\u001b[A\n",
      " 35%|███▍      | 5478/15663 [00:01<00:02, 3640.57it/s]\u001b[A\n",
      " 37%|███▋      | 5845/15663 [00:01<00:02, 3648.62it/s]\u001b[A\n",
      " 40%|███▉      | 6209/15663 [00:01<00:02, 3622.52it/s]\u001b[A\n",
      " 42%|████▏     | 6571/15663 [00:01<00:02, 3612.41it/s]\u001b[A\n",
      " 44%|████▍     | 6938/15663 [00:01<00:02, 3620.37it/s]\u001b[A\n",
      " 47%|████▋     | 7306/15663 [00:02<00:02, 3636.39it/s]\u001b[A\n",
      " 49%|████▉     | 7674/15663 [00:02<00:02, 3648.58it/s]\u001b[A\n",
      " 51%|█████▏    | 8039/15663 [00:02<00:02, 3628.37it/s]\u001b[A\n",
      " 54%|█████▎    | 8402/15663 [00:02<00:02, 3621.24it/s]\u001b[A\n",
      " 56%|█████▌    | 8766/15663 [00:02<00:01, 3618.10it/s]\u001b[A\n",
      " 58%|█████▊    | 9130/15663 [00:02<00:01, 3623.63it/s]\u001b[A\n",
      " 61%|██████    | 9496/15663 [00:02<00:01, 3626.51it/s]\u001b[A\n",
      " 63%|██████▎   | 9863/15663 [00:02<00:01, 3638.64it/s]\u001b[A\n",
      " 65%|██████▌   | 10230/15663 [00:02<00:01, 3646.42it/s]\u001b[A\n",
      " 68%|██████▊   | 10597/15663 [00:02<00:01, 3651.95it/s]\u001b[A\n",
      " 70%|███████   | 10971/15663 [00:03<00:01, 3674.70it/s]\u001b[A\n",
      " 72%|███████▏  | 11339/15663 [00:03<00:01, 3654.35it/s]\u001b[A\n",
      " 75%|███████▍  | 11705/15663 [00:03<00:01, 3648.22it/s]\u001b[A\n",
      " 77%|███████▋  | 12070/15663 [00:03<00:00, 3626.36it/s]\u001b[A\n",
      " 79%|███████▉  | 12433/15663 [00:03<00:00, 3614.48it/s]\u001b[A\n",
      " 82%|████████▏ | 12803/15663 [00:03<00:00, 3637.25it/s]\u001b[A\n",
      " 84%|████████▍ | 13167/15663 [00:03<00:00, 3593.64it/s]\u001b[A\n",
      " 86%|████████▋ | 13527/15663 [00:03<00:00, 3593.72it/s]\u001b[A\n",
      " 89%|████████▊ | 13888/15663 [00:03<00:00, 3591.89it/s]\u001b[A\n",
      " 91%|█████████ | 14253/15663 [00:03<00:00, 3608.02it/s]\u001b[A\n",
      " 93%|█████████▎| 14630/15663 [00:04<00:00, 3652.04it/s]\u001b[A\n",
      " 96%|█████████▌| 14996/15663 [00:04<00:00, 3614.76it/s]\u001b[A\n",
      " 98%|█████████▊| 15359/15663 [00:04<00:00, 3618.02it/s]\u001b[A\n",
      "100%|██████████| 15663/15663 [00:04<00:00, 3632.23it/s]\u001b[A\n",
      "  0%|          | 0/3916 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 361/3916 [00:00<00:00, 3605.13it/s]\u001b[A\n",
      " 18%|█▊        | 722/3916 [00:00<00:00, 3604.90it/s]\u001b[A\n",
      " 28%|██▊       | 1084/3916 [00:00<00:00, 3607.07it/s]\u001b[A\n",
      " 37%|███▋      | 1442/3916 [00:00<00:00, 3596.71it/s]\u001b[A\n",
      " 46%|████▌     | 1806/3916 [00:00<00:00, 3605.38it/s]\u001b[A\n",
      " 55%|█████▌    | 2172/3916 [00:00<00:00, 3619.49it/s]\u001b[A\n",
      " 65%|██████▍   | 2541/3916 [00:00<00:00, 3638.89it/s]\u001b[A\n",
      " 74%|███████▍  | 2912/3916 [00:00<00:00, 3659.40it/s]\u001b[A\n",
      " 84%|████████▎ | 3279/3916 [00:00<00:00, 3662.17it/s]\u001b[A\n",
      " 93%|█████████▎| 3636/3916 [00:01<00:00, 3630.49it/s]\u001b[A\n",
      "100%|██████████| 3916/3916 [00:01<00:00, 3614.86it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(x_train)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(x_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Testing XGBoost with Glove Features\n",
    "classi = xgb.XGBClassifier(nthread=10, silent=False)\n",
    "classi.fit(xtrain_glove,y_train)\n",
    "preds_proba = classi.predict_proba(xvalid_glove)\n",
    "preds = classi.predict(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.8641022256384314\n",
      "Current Accuracy: 0.620\n"
     ]
    }
   ],
   "source": [
    "print(\"logloss: {}\".format(multiclass_logloss(true_label, preds_proba)))\n",
    "print(\"Current Accuracy: {0:.3f}\".format(accuracy_score(preds,true_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Testing XGBoost with Glove Features\n",
    "classi = xgb.XGBClassifier(max_depth=10, n_estimators=400, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n",
    "classi.fit(xtrain_glove,y_train)\n",
    "preds_proba = classi.predict_proba(xvalid_glove)\n",
    "preds = classi.predict(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 0.831\n",
      "Current Accuracy: 0.671\n"
     ]
    }
   ],
   "source": [
    "print(\"Log-loss: {0:.3f}\".format(multiclass_logloss(true_label, preds_proba)))\n",
    "print(\"Current Accuracy: {0:.3f}\".format(accuracy_score(preds,true_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM classifier\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(y_train)\n",
    "yvalid_enc = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 layer neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/20\n",
      "15663/15663 [==============================] - 6s 372us/step - loss: 1.2212 - val_loss: 0.8811\n",
      "Epoch 2/20\n",
      "15663/15663 [==============================] - 5s 318us/step - loss: 0.9627 - val_loss: 0.8417\n",
      "Epoch 3/20\n",
      "15663/15663 [==============================] - 5s 316us/step - loss: 0.8813 - val_loss: 0.8172\n",
      "Epoch 4/20\n",
      "15663/15663 [==============================] - 5s 305us/step - loss: 0.8414 - val_loss: 0.7959\n",
      "Epoch 5/20\n",
      "15663/15663 [==============================] - 5s 309us/step - loss: 0.8138 - val_loss: 0.7771\n",
      "Epoch 6/20\n",
      "15663/15663 [==============================] - 5s 308us/step - loss: 0.7971 - val_loss: 0.7708\n",
      "Epoch 7/20\n",
      "15663/15663 [==============================] - 5s 315us/step - loss: 0.7841 - val_loss: 0.7657\n",
      "Epoch 8/20\n",
      "15663/15663 [==============================] - 5s 312us/step - loss: 0.7653 - val_loss: 0.7525\n",
      "Epoch 9/20\n",
      "15663/15663 [==============================] - 5s 312us/step - loss: 0.7539 - val_loss: 0.7485\n",
      "Epoch 10/20\n",
      "15663/15663 [==============================] - 5s 307us/step - loss: 0.7415 - val_loss: 0.7459\n",
      "Epoch 11/20\n",
      "15663/15663 [==============================] - 5s 310us/step - loss: 0.7217 - val_loss: 0.7428\n",
      "Epoch 12/20\n",
      "15663/15663 [==============================] - 5s 309us/step - loss: 0.7107 - val_loss: 0.7384\n",
      "Epoch 13/20\n",
      "15663/15663 [==============================] - 5s 313us/step - loss: 0.7008 - val_loss: 0.7334\n",
      "Epoch 14/20\n",
      "15663/15663 [==============================] - 5s 317us/step - loss: 0.6927 - val_loss: 0.7347\n",
      "Epoch 15/20\n",
      "15663/15663 [==============================] - 5s 317us/step - loss: 0.6777 - val_loss: 0.7273\n",
      "Epoch 16/20\n",
      "15663/15663 [==============================] - 5s 306us/step - loss: 0.6716 - val_loss: 0.7267\n",
      "Epoch 17/20\n",
      "15663/15663 [==============================] - 5s 307us/step - loss: 0.6637 - val_loss: 0.7247\n",
      "Epoch 18/20\n",
      "15663/15663 [==============================] - 5s 305us/step - loss: 0.6539 - val_loss: 0.7201\n",
      "Epoch 19/20\n",
      "15663/15663 [==============================] - 5s 316us/step - loss: 0.6425 - val_loss: 0.7296\n",
      "Epoch 20/20\n",
      "15663/15663 [==============================] - 5s 315us/step - loss: 0.6339 - val_loss: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa136a22748>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=20, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 1.530\n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict_proba(xvalid_glove)\n",
    "print(\"Log-loss: {0:.3f}\".format(multiclass_logloss(true_label, preds_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3916, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_sub = pd.DataFrame(columns={'id', 'EAP','HPL', 'MWS'})\n",
    "my_sub=my_sub[['id', 'EAP','HPL', 'MWS']]\n",
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_txt_proba_response(msg, vectors, model):\n",
    "    msg_vec = vectors.transform([msg])\n",
    "#    print(msg_vec)\n",
    "    pred_prob=model.predict_proba(msg_vec)\n",
    "    pd_unsorted = pd.DataFrame(\n",
    "        {'label_encode': model.classes_,\n",
    "         'label_decode': label_enconder.inverse_transform(model.classes_),\n",
    "         'pred_proba':  pred_prob[0]})\n",
    "    \n",
    "    probas = {\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[0][0]:\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[0][2],\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[1][0]:\n",
    "        pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[1][2],\n",
    "         pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[2][0]:\n",
    "         pd_unsorted.sort_values(['pred_proba'], ascending=False,axis=0).iloc[2][2]}\n",
    "    \n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    reply=get_txt_proba_response(transformText(test['text'][i]),features_2, model_sgd_2)\n",
    "    my_sub.loc[i] = [test['id'][i], reply['EAP'], reply['HPL'], reply['MWS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_sub.to_csv('roberto.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing text classification with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text,self).__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num\n",
    "        D = args.embed_dim\n",
    "        C = args.class_num\n",
    "        Ci = 1\n",
    "        Co = args.kernel_num\n",
    "        Ks = args.kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3) #(N,Co,W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x) # (N,W,D)\n",
    "        if self.args.static:\n",
    "            x = Variable(x)\n",
    "        x = x.unsqueeze(1) \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x) # (N,len(Ks)*Co)\n",
    "        logit = self.fc1(x) # (N,C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
